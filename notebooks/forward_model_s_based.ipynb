{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting a Forward Model (Saturation & Concentration Based)\n",
    "Can we find a forward ML model that can essentially do the simulations for us given the TMPs?\n",
    "\n",
    "The ultimate goal is to use this forward model as a loss function in inverse modelling. This gives us 2 benefits.\n",
    "1. Adds an additional loss term to the current inverse model training. This should improve **validation loss/overfitting issues** while making training even better. It can be thought of as a feedback loop.\n",
    "2. During actual experimentation, we can keep an internal state between different timeframes. A forward model will allow us to generate predictions from this internal state. The goal would be to tie in value consistency within the prediction system. (Think of a Kalman Filter/RNN)\n",
    "\n",
    "# Things to Try\n",
    "## 1. Learning the curve-fitting parameters\n",
    "Curve fitting paramters hold enough information about the entire spatial intensity curve, given the fit is actually good. The hope is that it should be easier for a model to learn 3 x 2 fitting parameters compared to 40 spatial intensity outputs. \n",
    "\n",
    "This actually works pretty well. Here are some results\n",
    "    Model Properties:\n",
    "        PerceptronBD(\n",
    "  (model): Sequential(\n",
    "    (0): Linear(in_features=5, out_features=4, bias=True)\n",
    "    (1): BatchNorm1d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (2): Dropout1d(p=0.2, inplace=False)\n",
    "    (3): ReLU()\n",
    "    (4): Linear(in_features=4, out_features=6, bias=True)\n",
    "    (5): BatchNorm1d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (6): Dropout1d(p=0.2, inplace=False)\n",
    "    (7): ReLU()\n",
    "    (8): Linear(in_features=6, out_features=8, bias=True)\n",
    "    (9): Flatten(start_dim=1, end_dim=-1)\n",
    "  )\n",
    ")\n",
    "        Optimizer Properties\"\n",
    "        SGD (\n",
    "Parameter Group 0\n",
    "    dampening: 0\n",
    "    differentiable: False\n",
    "    foreach: None\n",
    "    lr: 0.002\n",
    "    maximize: False\n",
    "    momentum: 0.9\n",
    "...\n",
    "            Validation Method: Holds out fMaternal Wall Thickness columns 0.2182178902359924 for validation. The rest are used for training\n",
    "        Loss:\n",
    "            Train Loss: 0.005227597474215039\n",
    "            Val. Loss: 0.03782471343874931\n",
    "\n",
    "\n",
    "(PS: The loss is calclated as the MSE over all 6 output parameters, fitting done with weights 1.0, 0.8)\n",
    "\n",
    "This does not work. The model does learn the curve-fitting paramters pretty well. however, the way those pramters are defined, even a small change actually impacts the output greatly. So, the error curve-fitting domain might not be large but in Spatial intensity doman, the curves are usually absurd. Usually rising exponential curves. This method **DOES NOT** work.\n",
    "\n",
    "## 2. Learning SI itself(20 pts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from torch.optim import Adam, SGD\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn import preprocessing\n",
    "from inverse_modelling_tfo.data import (\n",
    "    generate_data_loaders,\n",
    "    equidistance_detector_normalization,\n",
    "    constant_detector_count_normalization,\n",
    ")\n",
    "from inverse_modelling_tfo.data.intensity_interpolation import (\n",
    "    interpolate_exp,\n",
    "    get_interpolate_fit_params,\n",
    "    exp_piecewise_affine,\n",
    ")\n",
    "from inverse_modelling_tfo.data.interpolation_function_zoo import *\n",
    "from inverse_modelling_tfo.models import RandomSplit, ValidationMethod, HoldOneOut, CVSplit, CombineMethods\n",
    "from inverse_modelling_tfo.models.custom_models import (\n",
    "    SplitChannelCNN,\n",
    "    PerceptronReLU,\n",
    "    PerceptronBN,\n",
    "    PerceptronDO,\n",
    "    PerceptronBD,\n",
    "    FeatureResidualNetwork\n",
    ")\n",
    "from inverse_modelling_tfo.features.build_features import (\n",
    "    FetalACFeatureBuilder,\n",
    "    RowCombinationFeatureBuilder,\n",
    "    TwoColumnOperationFeatureBuilder,\n",
    "    FetalACbyDCFeatureBuilder,\n",
    "    LogTransformFeatureBuilder,\n",
    "    ConcatenateFeatureBuilder,\n",
    ")\n",
    "from inverse_modelling_tfo.features.data_transformations import (\n",
    "    LongToWideIntensityTransformation,\n",
    "    ToFittingParameterTransformation,\n",
    ")\n",
    "from inverse_modelling_tfo.data import config_based_normalization\n",
    "from inverse_modelling_tfo.data_pipelines.fetal_conc_groups import generate_grouping_from_config\n",
    "from ray import tune\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "import torchinfo\n",
    "from inverse_modelling_tfo.misc.misc_training import set_seed\n",
    "\n",
    "# Set my GPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with 604800 data points\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "in_src = Path(r\"/home/rraiyan/simulations/tfo_sim/data/compiled_intensity/dan_iccps_pencil.pkl\")\n",
    "data = pd.read_pickle(in_src)\n",
    "\n",
    "# Drop Uterus Thickness for now\n",
    "data = data.drop(columns='Uterus Thickness')\n",
    "\n",
    "# Normalize data\n",
    "config_src = in_src.with_suffix(\".json\")\n",
    "config_based_normalization(data, config_src)\n",
    "\n",
    "# Filter a small subset of data for use\n",
    "## Keep only the first memeber of each Fetal Concentration group\n",
    "fconc_rounding = 2\n",
    "grouping_map = generate_grouping_from_config(config_src, fconc_rounding)\n",
    "groups_to_keep = list(grouping_map.keys())[::3]\n",
    "\n",
    "data = data[\n",
    "    (data[\"Maternal Wall Thickness\"] >= 2.0)\n",
    "    & (data[\"Maternal Wall Thickness\"] <= 12.0)\n",
    "    & (data[\"Wave Int\"] == 2)\n",
    "    & (np.round(data[\"Fetal Hb Concentration\"], fconc_rounding).isin(groups_to_keep))\n",
    "    & (data[\"Fetal Saturation\"] > 0.3)\n",
    "    & (data[\"Maternal Saturation\"] > 0.95)\n",
    "]\n",
    "print(\"Working with\", len(data), \"data points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wave Int</th>\n",
       "      <th>SDD</th>\n",
       "      <th>Maternal Wall Thickness</th>\n",
       "      <th>Maternal Hb Concentration</th>\n",
       "      <th>Maternal Saturation</th>\n",
       "      <th>Fetal Hb Concentration</th>\n",
       "      <th>Fetal Saturation</th>\n",
       "      <th>Intensity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>604800.0</td>\n",
       "      <td>604800.000000</td>\n",
       "      <td>604800.000000</td>\n",
       "      <td>604800.000000</td>\n",
       "      <td>604800.000000</td>\n",
       "      <td>604800.000000</td>\n",
       "      <td>604800.000000</td>\n",
       "      <td>6.048000e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.0</td>\n",
       "      <td>52.450000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>13.500000</td>\n",
       "      <td>0.977273</td>\n",
       "      <td>13.284848</td>\n",
       "      <td>0.463636</td>\n",
       "      <td>4.955081e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>25.507814</td>\n",
       "      <td>2.828429</td>\n",
       "      <td>1.569116</td>\n",
       "      <td>0.015526</td>\n",
       "      <td>1.634534</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>2.070789e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>10.450000</td>\n",
       "      <td>0.327273</td>\n",
       "      <td>1.932688e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.0</td>\n",
       "      <td>31.750000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>12.250000</td>\n",
       "      <td>0.963636</td>\n",
       "      <td>12.069318</td>\n",
       "      <td>0.372727</td>\n",
       "      <td>3.822405e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.0</td>\n",
       "      <td>52.500000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>13.500000</td>\n",
       "      <td>0.977273</td>\n",
       "      <td>13.256818</td>\n",
       "      <td>0.463636</td>\n",
       "      <td>2.272987e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.0</td>\n",
       "      <td>73.250000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>14.750000</td>\n",
       "      <td>0.990909</td>\n",
       "      <td>14.532955</td>\n",
       "      <td>0.554545</td>\n",
       "      <td>2.436315e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.0</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.357343e-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Wave Int            SDD  Maternal Wall Thickness  \\\n",
       "count  604800.0  604800.000000            604800.000000   \n",
       "mean        2.0      52.450000                 8.000000   \n",
       "std         0.0      25.507814                 2.828429   \n",
       "min         2.0      10.000000                 4.000000   \n",
       "25%         2.0      31.750000                 6.000000   \n",
       "50%         2.0      52.500000                 8.000000   \n",
       "75%         2.0      73.250000                10.000000   \n",
       "max         2.0      94.000000                12.000000   \n",
       "\n",
       "       Maternal Hb Concentration  Maternal Saturation  Fetal Hb Concentration  \\\n",
       "count              604800.000000        604800.000000           604800.000000   \n",
       "mean                   13.500000             0.977273               13.284848   \n",
       "std                     1.569116             0.015526                1.634534   \n",
       "min                    11.000000             0.954545               10.450000   \n",
       "25%                    12.250000             0.963636               12.069318   \n",
       "50%                    13.500000             0.977273               13.256818   \n",
       "75%                    14.750000             0.990909               14.532955   \n",
       "max                    16.000000             1.000000               16.000000   \n",
       "\n",
       "       Fetal Saturation     Intensity  \n",
       "count     604800.000000  6.048000e+05  \n",
       "mean           0.463636  4.955081e-07  \n",
       "std            0.090909  2.070789e-06  \n",
       "min            0.327273  1.932688e-18  \n",
       "25%            0.372727  3.822405e-15  \n",
       "50%            0.463636  2.272987e-13  \n",
       "75%            0.554545  2.436315e-10  \n",
       "max            0.600000  1.357343e-05  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transofrm to a useable format\n",
    "# Define data transformers\n",
    "data_transformer = LongToWideIntensityTransformation()\n",
    "data = data_transformer.transform(data)\n",
    "\n",
    "labels = data_transformer.get_label_names()\n",
    "intensity_columns = data_transformer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Maternal Wall Thickness</th>\n",
       "      <th>Maternal Hb Concentration</th>\n",
       "      <th>Maternal Saturation</th>\n",
       "      <th>Fetal Hb Concentration</th>\n",
       "      <th>Fetal Saturation</th>\n",
       "      <th>10_2.0</th>\n",
       "      <th>15_2.0</th>\n",
       "      <th>19_2.0</th>\n",
       "      <th>24_2.0</th>\n",
       "      <th>28_2.0</th>\n",
       "      <th>...</th>\n",
       "      <th>55_2.0</th>\n",
       "      <th>59_2.0</th>\n",
       "      <th>64_2.0</th>\n",
       "      <th>68_2.0</th>\n",
       "      <th>72_2.0</th>\n",
       "      <th>77_2.0</th>\n",
       "      <th>81_2.0</th>\n",
       "      <th>86_2.0</th>\n",
       "      <th>90_2.0</th>\n",
       "      <th>94_2.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>30240.000000</td>\n",
       "      <td>30240.000000</td>\n",
       "      <td>30240.000000</td>\n",
       "      <td>30240.000000</td>\n",
       "      <td>30240.000000</td>\n",
       "      <td>30240.000000</td>\n",
       "      <td>3.024000e+04</td>\n",
       "      <td>3.024000e+04</td>\n",
       "      <td>3.024000e+04</td>\n",
       "      <td>3.024000e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>3.024000e+04</td>\n",
       "      <td>3.024000e+04</td>\n",
       "      <td>3.024000e+04</td>\n",
       "      <td>3.024000e+04</td>\n",
       "      <td>3.024000e+04</td>\n",
       "      <td>3.024000e+04</td>\n",
       "      <td>3.024000e+04</td>\n",
       "      <td>3.024000e+04</td>\n",
       "      <td>3.024000e+04</td>\n",
       "      <td>3.024000e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>13.500000</td>\n",
       "      <td>0.977273</td>\n",
       "      <td>13.284848</td>\n",
       "      <td>0.463636</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>5.473996e-07</td>\n",
       "      <td>6.236490e-08</td>\n",
       "      <td>5.535108e-09</td>\n",
       "      <td>6.929092e-10</td>\n",
       "      <td>...</td>\n",
       "      <td>3.982063e-13</td>\n",
       "      <td>2.051438e-13</td>\n",
       "      <td>1.064627e-13</td>\n",
       "      <td>5.115061e-14</td>\n",
       "      <td>2.831951e-14</td>\n",
       "      <td>1.323152e-14</td>\n",
       "      <td>7.599449e-15</td>\n",
       "      <td>4.114782e-15</td>\n",
       "      <td>1.774952e-15</td>\n",
       "      <td>1.081346e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.828474</td>\n",
       "      <td>1.569141</td>\n",
       "      <td>0.015526</td>\n",
       "      <td>1.634559</td>\n",
       "      <td>0.090911</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>1.870178e-07</td>\n",
       "      <td>2.767251e-08</td>\n",
       "      <td>3.000303e-09</td>\n",
       "      <td>4.033080e-10</td>\n",
       "      <td>...</td>\n",
       "      <td>6.141087e-13</td>\n",
       "      <td>3.118305e-13</td>\n",
       "      <td>1.610203e-13</td>\n",
       "      <td>7.591788e-14</td>\n",
       "      <td>4.416839e-14</td>\n",
       "      <td>2.017060e-14</td>\n",
       "      <td>1.187189e-14</td>\n",
       "      <td>5.872393e-15</td>\n",
       "      <td>2.720421e-15</td>\n",
       "      <td>1.495773e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>10.450000</td>\n",
       "      <td>0.327273</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>2.644472e-07</td>\n",
       "      <td>2.520209e-08</td>\n",
       "      <td>2.113300e-09</td>\n",
       "      <td>2.294026e-10</td>\n",
       "      <td>...</td>\n",
       "      <td>1.709206e-15</td>\n",
       "      <td>3.691207e-16</td>\n",
       "      <td>1.278690e-16</td>\n",
       "      <td>1.429473e-16</td>\n",
       "      <td>1.671112e-16</td>\n",
       "      <td>2.422271e-17</td>\n",
       "      <td>2.029375e-17</td>\n",
       "      <td>4.175189e-18</td>\n",
       "      <td>4.546107e-18</td>\n",
       "      <td>1.932688e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>12.250000</td>\n",
       "      <td>0.963636</td>\n",
       "      <td>12.069318</td>\n",
       "      <td>0.372727</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>3.926288e-07</td>\n",
       "      <td>4.046853e-08</td>\n",
       "      <td>3.196902e-09</td>\n",
       "      <td>3.952050e-10</td>\n",
       "      <td>...</td>\n",
       "      <td>1.413759e-14</td>\n",
       "      <td>6.544954e-15</td>\n",
       "      <td>2.375212e-15</td>\n",
       "      <td>1.156580e-15</td>\n",
       "      <td>7.956711e-16</td>\n",
       "      <td>2.867783e-16</td>\n",
       "      <td>1.503143e-16</td>\n",
       "      <td>7.537629e-17</td>\n",
       "      <td>2.246308e-17</td>\n",
       "      <td>2.449400e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>13.500000</td>\n",
       "      <td>0.977273</td>\n",
       "      <td>13.256818</td>\n",
       "      <td>0.463636</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>5.055990e-07</td>\n",
       "      <td>5.399260e-08</td>\n",
       "      <td>4.517729e-09</td>\n",
       "      <td>5.678995e-10</td>\n",
       "      <td>...</td>\n",
       "      <td>6.402735e-14</td>\n",
       "      <td>3.734626e-14</td>\n",
       "      <td>2.395785e-14</td>\n",
       "      <td>7.655293e-15</td>\n",
       "      <td>4.054667e-15</td>\n",
       "      <td>2.671577e-15</td>\n",
       "      <td>9.202662e-16</td>\n",
       "      <td>9.097205e-16</td>\n",
       "      <td>2.868739e-16</td>\n",
       "      <td>8.057970e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>14.750000</td>\n",
       "      <td>0.990909</td>\n",
       "      <td>14.532955</td>\n",
       "      <td>0.554545</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>6.720246e-07</td>\n",
       "      <td>8.111028e-08</td>\n",
       "      <td>7.204038e-09</td>\n",
       "      <td>8.612506e-10</td>\n",
       "      <td>...</td>\n",
       "      <td>3.825071e-13</td>\n",
       "      <td>2.046775e-13</td>\n",
       "      <td>1.056455e-13</td>\n",
       "      <td>6.041965e-14</td>\n",
       "      <td>2.690837e-14</td>\n",
       "      <td>1.305206e-14</td>\n",
       "      <td>7.582434e-15</td>\n",
       "      <td>5.185808e-15</td>\n",
       "      <td>1.859058e-15</td>\n",
       "      <td>1.817525e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>1.002851e-06</td>\n",
       "      <td>1.370502e-07</td>\n",
       "      <td>1.463137e-08</td>\n",
       "      <td>2.047246e-09</td>\n",
       "      <td>...</td>\n",
       "      <td>2.279593e-12</td>\n",
       "      <td>1.156356e-12</td>\n",
       "      <td>5.966464e-13</td>\n",
       "      <td>2.827272e-13</td>\n",
       "      <td>1.606921e-13</td>\n",
       "      <td>7.394739e-14</td>\n",
       "      <td>4.294191e-14</td>\n",
       "      <td>2.154562e-14</td>\n",
       "      <td>9.878602e-15</td>\n",
       "      <td>5.503227e-15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Maternal Wall Thickness  Maternal Hb Concentration  \\\n",
       "count             30240.000000               30240.000000   \n",
       "mean                  8.000000                  13.500000   \n",
       "std                   2.828474                   1.569141   \n",
       "min                   4.000000                  11.000000   \n",
       "25%                   6.000000                  12.250000   \n",
       "50%                   8.000000                  13.500000   \n",
       "75%                  10.000000                  14.750000   \n",
       "max                  12.000000                  16.000000   \n",
       "\n",
       "       Maternal Saturation  Fetal Hb Concentration  Fetal Saturation  \\\n",
       "count         30240.000000            30240.000000      30240.000000   \n",
       "mean              0.977273               13.284848          0.463636   \n",
       "std               0.015526                1.634559          0.090911   \n",
       "min               0.954545               10.450000          0.327273   \n",
       "25%               0.963636               12.069318          0.372727   \n",
       "50%               0.977273               13.256818          0.463636   \n",
       "75%               0.990909               14.532955          0.554545   \n",
       "max               1.000000               16.000000          0.600000   \n",
       "\n",
       "             10_2.0        15_2.0        19_2.0        24_2.0        28_2.0  \\\n",
       "count  30240.000000  3.024000e+04  3.024000e+04  3.024000e+04  3.024000e+04   \n",
       "mean       0.000009  5.473996e-07  6.236490e-08  5.535108e-09  6.929092e-10   \n",
       "std        0.000002  1.870178e-07  2.767251e-08  3.000303e-09  4.033080e-10   \n",
       "min        0.000006  2.644472e-07  2.520209e-08  2.113300e-09  2.294026e-10   \n",
       "25%        0.000008  3.926288e-07  4.046853e-08  3.196902e-09  3.952050e-10   \n",
       "50%        0.000009  5.055990e-07  5.399260e-08  4.517729e-09  5.678995e-10   \n",
       "75%        0.000011  6.720246e-07  8.111028e-08  7.204038e-09  8.612506e-10   \n",
       "max        0.000014  1.002851e-06  1.370502e-07  1.463137e-08  2.047246e-09   \n",
       "\n",
       "       ...        55_2.0        59_2.0        64_2.0        68_2.0  \\\n",
       "count  ...  3.024000e+04  3.024000e+04  3.024000e+04  3.024000e+04   \n",
       "mean   ...  3.982063e-13  2.051438e-13  1.064627e-13  5.115061e-14   \n",
       "std    ...  6.141087e-13  3.118305e-13  1.610203e-13  7.591788e-14   \n",
       "min    ...  1.709206e-15  3.691207e-16  1.278690e-16  1.429473e-16   \n",
       "25%    ...  1.413759e-14  6.544954e-15  2.375212e-15  1.156580e-15   \n",
       "50%    ...  6.402735e-14  3.734626e-14  2.395785e-14  7.655293e-15   \n",
       "75%    ...  3.825071e-13  2.046775e-13  1.056455e-13  6.041965e-14   \n",
       "max    ...  2.279593e-12  1.156356e-12  5.966464e-13  2.827272e-13   \n",
       "\n",
       "             72_2.0        77_2.0        81_2.0        86_2.0        90_2.0  \\\n",
       "count  3.024000e+04  3.024000e+04  3.024000e+04  3.024000e+04  3.024000e+04   \n",
       "mean   2.831951e-14  1.323152e-14  7.599449e-15  4.114782e-15  1.774952e-15   \n",
       "std    4.416839e-14  2.017060e-14  1.187189e-14  5.872393e-15  2.720421e-15   \n",
       "min    1.671112e-16  2.422271e-17  2.029375e-17  4.175189e-18  4.546107e-18   \n",
       "25%    7.956711e-16  2.867783e-16  1.503143e-16  7.537629e-17  2.246308e-17   \n",
       "50%    4.054667e-15  2.671577e-15  9.202662e-16  9.097205e-16  2.868739e-16   \n",
       "75%    2.690837e-14  1.305206e-14  7.582434e-15  5.185808e-15  1.859058e-15   \n",
       "max    1.606921e-13  7.394739e-14  4.294191e-14  2.154562e-14  9.878602e-15   \n",
       "\n",
       "             94_2.0  \n",
       "count  3.024000e+04  \n",
       "mean   1.081346e-15  \n",
       "std    1.495773e-15  \n",
       "min    1.932688e-18  \n",
       "25%    2.449400e-17  \n",
       "50%    8.057970e-17  \n",
       "75%    1.817525e-15  \n",
       "max    5.503227e-15  \n",
       "\n",
       "[8 rows x 25 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing Features\n",
    "x_columns will be the input features and y_columns are the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Y -> Target\n",
    "# y_columns = list(filter(lambda X: 'alpha' in X, data.columns))\n",
    "y_columns = intensity_columns\n",
    "\n",
    "## X -> Predictors\n",
    "x_columns = labels\n",
    "\n",
    "## Scale y\n",
    "y_scaler = preprocessing.StandardScaler()\n",
    "data[y_columns] = y_scaler.fit_transform(data[y_columns])\n",
    "\n",
    "## Scale x\n",
    "x_scaler = preprocessing.StandardScaler()\n",
    "data[x_columns] = x_scaler.fit_transform(data[x_columns])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "IN_FEATURES = len(x_columns)\n",
    "OUT_FEATURES = len(y_columns)\n",
    "\n",
    "from inverse_modelling_tfo.models.train_model import ModelTrainerFactory\n",
    "datagen_kw = {\n",
    "    'table' : data,\n",
    "    'data_loader_params' : \n",
    "        {\n",
    "            'batch_size': 64, 'shuffle': True, 'num_workers': 2\n",
    "        }, \n",
    "    'x_columns': x_columns,\n",
    "    'y_columns': y_columns,\n",
    "    # Standard Scaling w.r.t. Maternal Wall thickness : The original values are gone. Hold one out for some value\n",
    "    # in the middle of the pack\n",
    "    'validation_method' : HoldOneOut('Maternal Wall Thickness', data[\"Maternal Wall Thickness\"].unique()[4])\n",
    "    # 'validation_method' : HoldOneOut('Maternal Hb Concentration', 13.0)\n",
    "    # 'validation_method' : HoldOneOut('Maternal Saturation', 1.0)\n",
    "}\n",
    "\n",
    "# trainer_factory = ModelTrainerFactory(PerceptronReLU, {'node_counts' : [IN_FEATURES, 8, 2, OUT_FEATURES]}, generate_data_loaders, datagen_kw, 100, nn.MSELoss())\n",
    "# trainer_factory = ModelTrainerFactory(PerceptronBN, {'node_counts' : [IN_FEATURES, 8, 2, OUT_FEATURES]}, generate_data_loaders, datagen_kw, 100, nn.MSELoss())\n",
    "# trainer_factory = ModelTrainerFactory(PerceptronDO, {'node_counts' : [IN_FEATURES, 8, 2, OUT_FEATURES]}, generate_data_loaders, datagen_kw, 100, nn.MSELoss())\n",
    "trainer_factory = ModelTrainerFactory(PerceptronBD, {'node_counts' : [IN_FEATURES, 4, 8, 16, OUT_FEATURES], 'dropout_rates': [0.01, 0.01, 0.01]}, generate_data_loaders, datagen_kw, 100, nn.MSELoss())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Train Function \n",
    "def train_with_tuning(iteration_config):\n",
    "    set_seed(42)\n",
    "    trainer_tuning = trainer_factory.create()\n",
    "    trainer_tuning.reporting = True     # Report at each epoch to Ray Tune\n",
    "    if 'batch_size' in iteration_config:\n",
    "        trainer_tuning.change_batch_size(iteration_config['batch_size'])    # If batch_size needs tuning\n",
    "    trainer_tuning.set_optimizer(SGD, {'lr': iteration_config[\"lr\"], 'momentum': iteration_config[\"momentum\"]})\n",
    "    trainer_tuning.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-02 16:13:57,387\tINFO tune.py:645 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n",
      "2023-11-02 16:14:01,182\tWARNING worker.py:2058 -- Warning: The actor ImplicitFunc is very large (19 MiB). Check that its definition is not implicitly capturing a large array or other object in scope. Tip: use ray.put() to put large objects in the Ray object store.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-11-02 16:14:01 (running for 00:00:03.94)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: None | Iter 5.000: None\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 70/80 (70 PENDING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th style=\"text-align: right;\">  combined_loss</th><th style=\"text-align: right;\">  train_loss</th><th style=\"text-align: right;\">  val_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_with_tuning_7fcaa_00000</td><td style=\"text-align: right;\">    0.0042998  </td><td style=\"text-align: right;\">  0.0593873 </td><td style=\"text-align: right;\"> 0.0724027</td></tr>\n",
       "<tr><td>train_with_tuning_7fcaa_00001</td><td style=\"text-align: right;\">    0.78627    </td><td style=\"text-align: right;\">  1.00633   </td><td style=\"text-align: right;\"> 0.781322 </td></tr>\n",
       "<tr><td>train_with_tuning_7fcaa_00002</td><td style=\"text-align: right;\">    0.916355   </td><td style=\"text-align: right;\">  1.08623   </td><td style=\"text-align: right;\"> 0.843608 </td></tr>\n",
       "<tr><td>train_with_tuning_7fcaa_00003</td><td style=\"text-align: right;\">    0.000785426</td><td style=\"text-align: right;\">  0.0250048 </td><td style=\"text-align: right;\"> 0.0314111</td></tr>\n",
       "<tr><td>train_with_tuning_7fcaa_00004</td><td style=\"text-align: right;\">    1.05334    </td><td style=\"text-align: right;\">  1.19612   </td><td style=\"text-align: right;\"> 0.88063  </td></tr>\n",
       "<tr><td>train_with_tuning_7fcaa_00005</td><td style=\"text-align: right;\">    0.00503051 </td><td style=\"text-align: right;\">  0.0705591 </td><td style=\"text-align: right;\"> 0.071295 </td></tr>\n",
       "<tr><td>train_with_tuning_7fcaa_00006</td><td style=\"text-align: right;\">    0.000776379</td><td style=\"text-align: right;\">  0.0237362 </td><td style=\"text-align: right;\"> 0.0327086</td></tr>\n",
       "<tr><td>train_with_tuning_7fcaa_00007</td><td style=\"text-align: right;\">    0.875322   </td><td style=\"text-align: right;\">  1.05849   </td><td style=\"text-align: right;\"> 0.826952 </td></tr>\n",
       "<tr><td>train_with_tuning_7fcaa_00008</td><td style=\"text-align: right;\">    0.96395    </td><td style=\"text-align: right;\">  1.12874   </td><td style=\"text-align: right;\"> 0.854004 </td></tr>\n",
       "<tr><td>train_with_tuning_7fcaa_00009</td><td style=\"text-align: right;\">    1.03872    </td><td style=\"text-align: right;\">  1.1864    </td><td style=\"text-align: right;\"> 0.875525 </td></tr>\n",
       "<tr><td>train_with_tuning_7fcaa_00010</td><td style=\"text-align: right;\">    2.749e-05  </td><td style=\"text-align: right;\">  0.00192802</td><td style=\"text-align: right;\"> 0.0142582</td></tr>\n",
       "<tr><td>train_with_tuning_7fcaa_00011</td><td style=\"text-align: right;\">    0.9885     </td><td style=\"text-align: right;\">  1.14923   </td><td style=\"text-align: right;\"> 0.86014  </td></tr>\n",
       "<tr><td>train_with_tuning_7fcaa_00012</td><td style=\"text-align: right;\">    0.00352952 </td><td style=\"text-align: right;\">  0.051156  </td><td style=\"text-align: right;\"> 0.0689953</td></tr>\n",
       "<tr><td>train_with_tuning_7fcaa_00013</td><td style=\"text-align: right;\">    0.0114765  </td><td style=\"text-align: right;\">  0.159146  </td><td style=\"text-align: right;\"> 0.0721131</td></tr>\n",
       "<tr><td>train_with_tuning_7fcaa_00014</td><td style=\"text-align: right;\">    0.0112613  </td><td style=\"text-align: right;\">  0.155933  </td><td style=\"text-align: right;\"> 0.0722189</td></tr>\n",
       "<tr><td>train_with_tuning_7fcaa_00015</td><td style=\"text-align: right;\">    0.00117479 </td><td style=\"text-align: right;\">  0.0310353 </td><td style=\"text-align: right;\"> 0.0378534</td></tr>\n",
       "<tr><td>train_with_tuning_7fcaa_00016</td><td style=\"text-align: right;\">    0.91651    </td><td style=\"text-align: right;\">  1.08664   </td><td style=\"text-align: right;\"> 0.843436 </td></tr>\n",
       "<tr><td>train_with_tuning_7fcaa_00017</td><td style=\"text-align: right;\">    0.00111617 </td><td style=\"text-align: right;\">  0.0303273 </td><td style=\"text-align: right;\"> 0.0368042</td></tr>\n",
       "<tr><td>train_with_tuning_7fcaa_00018</td><td style=\"text-align: right;\">    0.00040345 </td><td style=\"text-align: right;\">  0.0160555 </td><td style=\"text-align: right;\"> 0.0251284</td></tr>\n",
       "<tr><td>train_with_tuning_7fcaa_00019</td><td style=\"text-align: right;\">    0.0336488  </td><td style=\"text-align: right;\">  0.429848  </td><td style=\"text-align: right;\"> 0.0782808</td></tr>\n",
       "<tr><td>train_with_tuning_7fcaa_00020</td><td style=\"text-align: right;\">    0.000483827</td><td style=\"text-align: right;\">  0.0177826 </td><td style=\"text-align: right;\"> 0.0272079</td></tr>\n",
       "<tr><td>train_with_tuning_7fcaa_00021</td><td style=\"text-align: right;\">    0.000786289</td><td style=\"text-align: right;\">  0.025054  </td><td style=\"text-align: right;\"> 0.0313837</td></tr>\n",
       "<tr><td>train_with_tuning_7fcaa_00022</td><td style=\"text-align: right;\">    0.00841793 </td><td style=\"text-align: right;\">  0.114264  </td><td style=\"text-align: right;\"> 0.0736707</td></tr>\n",
       "<tr><td>train_with_tuning_7fcaa_00023</td><td style=\"text-align: right;\">    0.000230605</td><td style=\"text-align: right;\">  0.0108813 </td><td style=\"text-align: right;\"> 0.0211929</td></tr>\n",
       "<tr><td>train_with_tuning_7fcaa_00024</td><td style=\"text-align: right;\">    0.980791   </td><td style=\"text-align: right;\">  1.14297   </td><td style=\"text-align: right;\"> 0.858111 </td></tr>\n",
       "<tr><td>train_with_tuning_7fcaa_00025</td><td style=\"text-align: right;\">    1.06147    </td><td style=\"text-align: right;\">  1.20141   </td><td style=\"text-align: right;\"> 0.883517 </td></tr>\n",
       "<tr><td>train_with_tuning_7fcaa_00026</td><td style=\"text-align: right;\">    0.957889   </td><td style=\"text-align: right;\">  1.12339   </td><td style=\"text-align: right;\"> 0.85268  </td></tr>\n",
       "<tr><td>train_with_tuning_7fcaa_00027</td><td style=\"text-align: right;\">    0.991001   </td><td style=\"text-align: right;\">  1.15137   </td><td style=\"text-align: right;\"> 0.860712 </td></tr>\n",
       "<tr><td>train_with_tuning_7fcaa_00028</td><td style=\"text-align: right;\">    1.02279    </td><td style=\"text-align: right;\">  1.17526   </td><td style=\"text-align: right;\"> 0.870268 </td></tr>\n",
       "<tr><td>train_with_tuning_7fcaa_00029</td><td style=\"text-align: right;\">    0.976035   </td><td style=\"text-align: right;\">  1.13907   </td><td style=\"text-align: right;\"> 0.856873 </td></tr>\n",
       "<tr><td>train_with_tuning_7fcaa_00030</td><td style=\"text-align: right;\">    1.04759    </td><td style=\"text-align: right;\">  1.19235   </td><td style=\"text-align: right;\"> 0.878594 </td></tr>\n",
       "<tr><td>train_with_tuning_7fcaa_00031</td><td style=\"text-align: right;\">    0.0139447  </td><td style=\"text-align: right;\">  0.193154  </td><td style=\"text-align: right;\"> 0.0721945</td></tr>\n",
       "<tr><td>train_with_tuning_7fcaa_00032</td><td style=\"text-align: right;\">    0.914845   </td><td style=\"text-align: right;\">  1.08524   </td><td style=\"text-align: right;\"> 0.842992 </td></tr>\n",
       "<tr><td>train_with_tuning_7fcaa_00033</td><td style=\"text-align: right;\">    0.983569   </td><td style=\"text-align: right;\">  1.14527   </td><td style=\"text-align: right;\"> 0.85881  </td></tr>\n",
       "<tr><td>train_with_tuning_7fcaa_00034</td><td style=\"text-align: right;\">    0.929685   </td><td style=\"text-align: right;\">  1.0974    </td><td style=\"text-align: right;\"> 0.84717  </td></tr>\n",
       "<tr><td>train_with_tuning_7fcaa_00035</td><td style=\"text-align: right;\">    0.0306125  </td><td style=\"text-align: right;\">  0.403719  </td><td style=\"text-align: right;\"> 0.0758263</td></tr>\n",
       "<tr><td>train_with_tuning_7fcaa_00036</td><td style=\"text-align: right;\">    1.04368    </td><td style=\"text-align: right;\">  1.18972   </td><td style=\"text-align: right;\"> 0.87725  </td></tr>\n",
       "<tr><td>train_with_tuning_7fcaa_00037</td><td style=\"text-align: right;\">    0.0113063  </td><td style=\"text-align: right;\">  0.157304  </td><td style=\"text-align: right;\"> 0.0718758</td></tr>\n",
       "<tr><td>train_with_tuning_7fcaa_00038</td><td style=\"text-align: right;\">    0.000195706</td><td style=\"text-align: right;\">  0.00981792</td><td style=\"text-align: right;\"> 0.0199336</td></tr>\n",
       "<tr><td>train_with_tuning_7fcaa_00039</td><td style=\"text-align: right;\">    0.823174   </td><td style=\"text-align: right;\">  1.03467   </td><td style=\"text-align: right;\"> 0.795594 </td></tr>\n",
       "<tr><td>train_with_tuning_7fcaa_00040</td><td style=\"text-align: right;\">    0.900753   </td><td style=\"text-align: right;\">  1.07409   </td><td style=\"text-align: right;\"> 0.838616 </td></tr>\n",
       "<tr><td>train_with_tuning_7fcaa_00041</td><td style=\"text-align: right;\">    1.07325    </td><td style=\"text-align: right;\">  1.20891   </td><td style=\"text-align: right;\"> 0.887786 </td></tr>\n",
       "<tr><td>train_with_tuning_7fcaa_00042</td><td style=\"text-align: right;\">    0.000739922</td><td style=\"text-align: right;\">  0.0230197 </td><td style=\"text-align: right;\"> 0.0321429</td></tr>\n",
       "<tr><td>train_with_tuning_7fcaa_00043</td><td style=\"text-align: right;\">    1.03723    </td><td style=\"text-align: right;\">  1.18536   </td><td style=\"text-align: right;\"> 0.875038 </td></tr>\n",
       "<tr><td>train_with_tuning_7fcaa_00044</td><td style=\"text-align: right;\">    1.01829    </td><td style=\"text-align: right;\">  1.172     </td><td style=\"text-align: right;\"> 0.868847 </td></tr>\n",
       "<tr><td>train_with_tuning_7fcaa_00045</td><td style=\"text-align: right;\">    0.027289   </td><td style=\"text-align: right;\">  0.367145  </td><td style=\"text-align: right;\"> 0.0743277</td></tr>\n",
       "<tr><td>train_with_tuning_7fcaa_00046</td><td style=\"text-align: right;\">    0.924066   </td><td style=\"text-align: right;\">  1.09294   </td><td style=\"text-align: right;\"> 0.845489 </td></tr>\n",
       "<tr><td>train_with_tuning_7fcaa_00047</td><td style=\"text-align: right;\">    0.00218075 </td><td style=\"text-align: right;\">  0.0420688 </td><td style=\"text-align: right;\"> 0.0518377</td></tr>\n",
       "<tr><td>train_with_tuning_7fcaa_00048</td><td style=\"text-align: right;\">    1.02314    </td><td style=\"text-align: right;\">  1.17553   </td><td style=\"text-align: right;\"> 0.870363 </td></tr>\n",
       "<tr><td>train_with_tuning_7fcaa_00049</td><td style=\"text-align: right;\">    0.00229741 </td><td style=\"text-align: right;\">  0.0428676 </td><td style=\"text-align: right;\"> 0.0535932</td></tr>\n",
       "<tr><td>train_with_tuning_7fcaa_00050</td><td style=\"text-align: right;\">    0.916178   </td><td style=\"text-align: right;\">  1.0862    </td><td style=\"text-align: right;\"> 0.843472 </td></tr>\n",
       "<tr><td>train_with_tuning_7fcaa_00051</td><td style=\"text-align: right;\">    0.00418614 </td><td style=\"text-align: right;\">  0.0593064 </td><td style=\"text-align: right;\"> 0.0705849</td></tr>\n",
       "<tr><td>train_with_tuning_7fcaa_00052</td><td style=\"text-align: right;\">    5.8091e-05 </td><td style=\"text-align: right;\">  0.0035141 </td><td style=\"text-align: right;\"> 0.0165309</td></tr>\n",
       "<tr><td>train_with_tuning_7fcaa_00053</td><td style=\"text-align: right;\">    1.08392    </td><td style=\"text-align: right;\">  1.21552   </td><td style=\"text-align: right;\"> 0.891737 </td></tr>\n",
       "<tr><td>train_with_tuning_7fcaa_00054</td><td style=\"text-align: right;\">    1.0068     </td><td style=\"text-align: right;\">  1.16353   </td><td style=\"text-align: right;\"> 0.865295 </td></tr>\n",
       "<tr><td>train_with_tuning_7fcaa_00055</td><td style=\"text-align: right;\">    0.880811   </td><td style=\"text-align: right;\">  1.06092   </td><td style=\"text-align: right;\"> 0.830232 </td></tr>\n",
       "<tr><td>train_with_tuning_7fcaa_00056</td><td style=\"text-align: right;\">    0.0146848  </td><td style=\"text-align: right;\">  0.202495  </td><td style=\"text-align: right;\"> 0.0725193</td></tr>\n",
       "<tr><td>train_with_tuning_7fcaa_00057</td><td style=\"text-align: right;\">    0.0135569  </td><td style=\"text-align: right;\">  0.188082  </td><td style=\"text-align: right;\"> 0.0720795</td></tr>\n",
       "<tr><td>train_with_tuning_7fcaa_00058</td><td style=\"text-align: right;\">    0.00407332 </td><td style=\"text-align: right;\">  0.0579233 </td><td style=\"text-align: right;\"> 0.0703226</td></tr>\n",
       "<tr><td>train_with_tuning_7fcaa_00059</td><td style=\"text-align: right;\">    0.963473   </td><td style=\"text-align: right;\">  1.12833   </td><td style=\"text-align: right;\"> 0.853891 </td></tr>\n",
       "<tr><td>train_with_tuning_7fcaa_00060</td><td style=\"text-align: right;\">    0.000724706</td><td style=\"text-align: right;\">  0.0226249 </td><td style=\"text-align: right;\"> 0.0320314</td></tr>\n",
       "<tr><td>train_with_tuning_7fcaa_00061</td><td style=\"text-align: right;\">    0.0176121  </td><td style=\"text-align: right;\">  0.240769  </td><td style=\"text-align: right;\"> 0.0731495</td></tr>\n",
       "<tr><td>train_with_tuning_7fcaa_00062</td><td style=\"text-align: right;\">    0.00976401 </td><td style=\"text-align: right;\">  0.131933  </td><td style=\"text-align: right;\"> 0.0740074</td></tr>\n",
       "<tr><td>train_with_tuning_7fcaa_00063</td><td style=\"text-align: right;\">    0.674815   </td><td style=\"text-align: right;\">  0.97985   </td><td style=\"text-align: right;\"> 0.688692 </td></tr>\n",
       "<tr><td>train_with_tuning_7fcaa_00064</td><td style=\"text-align: right;\">    0.0230505  </td><td style=\"text-align: right;\">  0.311104  </td><td style=\"text-align: right;\"> 0.0740925</td></tr>\n",
       "<tr><td>train_with_tuning_7fcaa_00065</td><td style=\"text-align: right;\">    0.00892409 </td><td style=\"text-align: right;\">  0.119674  </td><td style=\"text-align: right;\"> 0.07457  </td></tr>\n",
       "<tr><td>train_with_tuning_7fcaa_00066</td><td style=\"text-align: right;\">    0.0114313  </td><td style=\"text-align: right;\">  0.158253  </td><td style=\"text-align: right;\"> 0.0722343</td></tr>\n",
       "<tr><td>train_with_tuning_7fcaa_00067</td><td style=\"text-align: right;\">    2.72109e-05</td><td style=\"text-align: right;\">  0.00192101</td><td style=\"text-align: right;\"> 0.0141649</td></tr>\n",
       "<tr><td>train_with_tuning_7fcaa_00068</td><td style=\"text-align: right;\">    0.761788   </td><td style=\"text-align: right;\">  1.01112   </td><td style=\"text-align: right;\"> 0.753406 </td></tr>\n",
       "<tr><td>train_with_tuning_7fcaa_00069</td><td style=\"text-align: right;\">    0.931043   </td><td style=\"text-align: right;\">  1.09911   </td><td style=\"text-align: right;\"> 0.847088 </td></tr>\n",
       "<tr><td>train_with_tuning_7fcaa_00070</td><td style=\"text-align: right;\">    0.000761952</td><td style=\"text-align: right;\">  0.0233467 </td><td style=\"text-align: right;\"> 0.0326364</td></tr>\n",
       "<tr><td>train_with_tuning_7fcaa_00071</td><td style=\"text-align: right;\">    0.944603   </td><td style=\"text-align: right;\">  1.11145   </td><td style=\"text-align: right;\"> 0.849886 </td></tr>\n",
       "<tr><td>train_with_tuning_7fcaa_00072</td><td style=\"text-align: right;\">    0.0226565  </td><td style=\"text-align: right;\">  0.304845  </td><td style=\"text-align: right;\"> 0.0743216</td></tr>\n",
       "<tr><td>train_with_tuning_7fcaa_00073</td><td style=\"text-align: right;\">    1.06592    </td><td style=\"text-align: right;\">  1.20425   </td><td style=\"text-align: right;\"> 0.885128 </td></tr>\n",
       "<tr><td>train_with_tuning_7fcaa_00074</td><td style=\"text-align: right;\">    0.895638   </td><td style=\"text-align: right;\">  1.071     </td><td style=\"text-align: right;\"> 0.836264 </td></tr>\n",
       "<tr><td>train_with_tuning_7fcaa_00075</td><td style=\"text-align: right;\">    0.829919   </td><td style=\"text-align: right;\">  1.03762   </td><td style=\"text-align: right;\"> 0.799826 </td></tr>\n",
       "<tr><td>train_with_tuning_7fcaa_00076</td><td style=\"text-align: right;\">    0.819004   </td><td style=\"text-align: right;\">  1.03313   </td><td style=\"text-align: right;\"> 0.79274  </td></tr>\n",
       "<tr><td>train_with_tuning_7fcaa_00077</td><td style=\"text-align: right;\">    0.00198963 </td><td style=\"text-align: right;\">  0.0413374 </td><td style=\"text-align: right;\"> 0.0481315</td></tr>\n",
       "<tr><td>train_with_tuning_7fcaa_00078</td><td style=\"text-align: right;\">    0.000125821</td><td style=\"text-align: right;\">  0.00703989</td><td style=\"text-align: right;\"> 0.0178725</td></tr>\n",
       "<tr><td>train_with_tuning_7fcaa_00079</td><td style=\"text-align: right;\">    0.0198507  </td><td style=\"text-align: right;\">  0.270004  </td><td style=\"text-align: right;\"> 0.0735199</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-11-02 16:14:06 (running for 00:00:08.97)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: None | Iter 5.000: None\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 72/80 (70 PENDING, 2 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:14:11 (running for 00:00:14.04)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: -0.47201001617545424 | Iter 5.000: -0.8153793250564099\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 72/80 (70 PENDING, 2 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:14:16 (running for 00:00:19.09)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: -0.47201001617545424 | Iter 5.000: -0.8153793250564099\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 72/80 (70 PENDING, 2 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:14:21 (running for 00:00:24.15)\n",
      "Using AsyncHyperBand: num_stopped=1\n",
      "Bracket: Iter 40.000: None | Iter 20.000: -0.39871462159057147 | Iter 10.000: -0.47201001617545424 | Iter 5.000: -0.8153793250564099\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 73/80 (70 PENDING, 2 RUNNING, 1 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:14:26 (running for 00:00:29.16)\n",
      "Using AsyncHyperBand: num_stopped=2\n",
      "Bracket: Iter 40.000: None | Iter 20.000: -0.39871462159057147 | Iter 10.000: -0.47201001617545424 | Iter 5.000: -0.9163545267883212\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 73/80 (70 PENDING, 1 RUNNING, 2 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:14:31 (running for 00:00:34.17)\n",
      "Using AsyncHyperBand: num_stopped=2\n",
      "Bracket: Iter 40.000: None | Iter 20.000: -0.39871462159057147 | Iter 10.000: -0.47201001617545424 | Iter 5.000: -0.9163545267883212\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 74/80 (70 PENDING, 2 RUNNING, 2 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:14:36 (running for 00:00:39.26)\n",
      "Using AsyncHyperBand: num_stopped=2\n",
      "Bracket: Iter 40.000: -0.005465189822380023 | Iter 20.000: -0.39871462159057147 | Iter 10.000: -0.03980847757758455 | Iter 5.000: -0.7951897336653191\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 74/80 (70 PENDING, 2 RUNNING, 2 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:14:41 (running for 00:00:44.26)\n",
      "Using AsyncHyperBand: num_stopped=2\n",
      "Bracket: Iter 40.000: -0.005465189822380023 | Iter 20.000: -0.39871462159057147 | Iter 10.000: -0.03980847757758455 | Iter 5.000: -0.7951897336653191\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 74/80 (70 PENDING, 2 RUNNING, 2 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:14:46 (running for 00:00:49.30)\n",
      "Using AsyncHyperBand: num_stopped=3\n",
      "Bracket: Iter 40.000: -0.005465189822380023 | Iter 20.000: -0.011159142059584883 | Iter 10.000: -0.03980847757758455 | Iter 5.000: -0.7951897336653191\n",
      "Logical resource usage: 0/64 CPUs, 0.5/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 74/80 (70 PENDING, 1 RUNNING, 3 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:14:51 (running for 00:00:54.30)\n",
      "Using AsyncHyperBand: num_stopped=3\n",
      "Bracket: Iter 40.000: -0.005465189822380023 | Iter 20.000: -0.011159142059584883 | Iter 10.000: -0.03980847757758455 | Iter 5.000: -0.7951897336653191\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 75/80 (70 PENDING, 2 RUNNING, 3 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:14:56 (running for 00:00:59.39)\n",
      "Using AsyncHyperBand: num_stopped=4\n",
      "Bracket: Iter 40.000: -0.0038788444424618937 | Iter 20.000: -0.011159142059584883 | Iter 10.000: -0.03980847757758455 | Iter 5.000: -0.9163545267883212\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 76/80 (70 PENDING, 2 RUNNING, 4 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:15:01 (running for 00:01:04.40)\n",
      "Using AsyncHyperBand: num_stopped=4\n",
      "Bracket: Iter 40.000: -0.0038788444424618937 | Iter 20.000: -0.011159142059584883 | Iter 10.000: -0.03980847757758455 | Iter 5.000: -0.7951897336653191\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 76/80 (70 PENDING, 2 RUNNING, 4 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:15:06 (running for 00:01:09.44)\n",
      "Using AsyncHyperBand: num_stopped=4\n",
      "Bracket: Iter 40.000: -0.0038788444424618937 | Iter 20.000: -0.011159142059584883 | Iter 10.000: -0.03768727467713197 | Iter 5.000: -0.7951897336653191\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 76/80 (70 PENDING, 2 RUNNING, 4 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:15:11 (running for 00:01:14.48)\n",
      "Using AsyncHyperBand: num_stopped=5\n",
      "Bracket: Iter 40.000: -0.0038788444424618937 | Iter 20.000: -0.010769011696361939 | Iter 10.000: -0.03768727467713197 | Iter 5.000: -0.7951897336653191\n",
      "Logical resource usage: 0/64 CPUs, 0.5/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 76/80 (70 PENDING, 1 RUNNING, 5 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:15:16 (running for 00:01:19.58)\n",
      "Using AsyncHyperBand: num_stopped=5\n",
      "Bracket: Iter 40.000: -0.0038788444424618937 | Iter 20.000: -0.010769011696361939 | Iter 10.000: -0.03768727467713197 | Iter 5.000: -0.7951897336653191\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 77/80 (70 PENDING, 2 RUNNING, 5 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:15:22 (running for 00:01:24.63)\n",
      "Using AsyncHyperBand: num_stopped=5\n",
      "Bracket: Iter 40.000: -0.0038788444424618937 | Iter 20.000: -0.010769011696361939 | Iter 10.000: -0.03556607177667938 | Iter 5.000: -0.674024940542317\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 77/80 (70 PENDING, 2 RUNNING, 5 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:15:27 (running for 00:01:29.71)\n",
      "Using AsyncHyperBand: num_stopped=6\n",
      "Bracket: Iter 40.000: -0.0050305125901901416 | Iter 20.000: -0.010769011696361939 | Iter 10.000: -0.03556607177667938 | Iter 5.000: -0.674024940542317\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 77/80 (70 PENDING, 1 RUNNING, 6 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:15:32 (running for 00:01:34.75)\n",
      "Using AsyncHyperBand: num_stopped=7\n",
      "Bracket: Iter 40.000: -0.0050305125901901416 | Iter 20.000: -0.010378881333138995 | Iter 10.000: -0.03556607177667938 | Iter 5.000: -0.7746734716772887\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 78/80 (70 PENDING, 1 RUNNING, 7 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:15:37 (running for 00:01:39.77)\n",
      "Using AsyncHyperBand: num_stopped=7\n",
      "Bracket: Iter 40.000: -0.0050305125901901416 | Iter 20.000: -0.010378881333138995 | Iter 10.000: -0.03556607177667938 | Iter 5.000: -0.7746734716772887\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 79/80 (70 PENDING, 2 RUNNING, 7 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:15:42 (running for 00:01:44.87)\n",
      "Using AsyncHyperBand: num_stopped=8\n",
      "Bracket: Iter 40.000: -0.0050305125901901416 | Iter 20.000: -0.010378881333138995 | Iter 10.000: -0.03556607177667938 | Iter 5.000: -0.8753220028122605\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (70 PENDING, 2 RUNNING, 8 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:15:47 (running for 00:01:49.95)\n",
      "Using AsyncHyperBand: num_stopped=9\n",
      "Bracket: Iter 40.000: -0.003661505826366953 | Iter 20.000: -0.010378881333138995 | Iter 10.000: -0.03556607177667938 | Iter 5.000: -0.8958382648002908\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (70 PENDING, 1 RUNNING, 9 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:15:52 (running for 00:01:55.00)\n",
      "Using AsyncHyperBand: num_stopped=9\n",
      "Bracket: Iter 40.000: -0.003661505826366953 | Iter 20.000: -0.010378881333138995 | Iter 10.000: -0.03556607177667938 | Iter 5.000: -0.8958382648002908\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (69 PENDING, 2 RUNNING, 9 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:15:57 (running for 00:02:00.01)\n",
      "Using AsyncHyperBand: num_stopped=10\n",
      "Bracket: Iter 40.000: -0.003661505826366953 | Iter 20.000: -0.010378881333138995 | Iter 10.000: -0.020817727472674838 | Iter 5.000: -0.8753220028122605\n",
      "Logical resource usage: 0/64 CPUs, 0.5/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (69 PENDING, 1 RUNNING, 10 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:16:02 (running for 00:02:05.09)\n",
      "Using AsyncHyperBand: num_stopped=10\n",
      "Bracket: Iter 40.000: -0.003661505826366953 | Iter 20.000: -0.010378881333138995 | Iter 10.000: -0.020817727472674838 | Iter 5.000: -0.8753220028122605\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (68 PENDING, 2 RUNNING, 10 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:16:07 (running for 00:02:10.18)\n",
      "Using AsyncHyperBand: num_stopped=11\n",
      "Bracket: Iter 40.000: -0.003661505826366953 | Iter 20.000: -0.00719191291722604 | Iter 10.000: -0.020817727472674838 | Iter 5.000: -0.8958382648002908\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (67 PENDING, 2 RUNNING, 11 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:16:12 (running for 00:02:15.18)\n",
      "Using AsyncHyperBand: num_stopped=11\n",
      "Bracket: Iter 40.000: -0.003661505826366953 | Iter 20.000: -0.00719191291722604 | Iter 10.000: -0.020817727472674838 | Iter 5.000: -0.8753220028122605\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (67 PENDING, 2 RUNNING, 11 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:16:17 (running for 00:02:20.25)\n",
      "Using AsyncHyperBand: num_stopped=11\n",
      "Bracket: Iter 40.000: -0.003661505826366953 | Iter 20.000: -0.00719191291722604 | Iter 10.000: -0.010167745614658228 | Iter 5.000: -0.8753220028122605\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (67 PENDING, 2 RUNNING, 11 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:16:22 (running for 00:02:25.27)\n",
      "Using AsyncHyperBand: num_stopped=11\n",
      "Bracket: Iter 40.000: -0.002292499062543765 | Iter 20.000: -0.004729229739725935 | Iter 10.000: -0.010167745614658228 | Iter 5.000: -0.8753220028122605\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (67 PENDING, 2 RUNNING, 11 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:16:27 (running for 00:02:30.32)\n",
      "Using AsyncHyperBand: num_stopped=11\n",
      "Bracket: Iter 40.000: -0.002292499062543765 | Iter 20.000: -0.004729229739725935 | Iter 10.000: -0.010167745614658228 | Iter 5.000: -0.8753220028122605\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (67 PENDING, 2 RUNNING, 11 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:16:32 (running for 00:02:35.37)\n",
      "Using AsyncHyperBand: num_stopped=12\n",
      "Bracket: Iter 40.000: -0.002292499062543765 | Iter 20.000: -0.004729229739725935 | Iter 10.000: -0.010167745614658228 | Iter 5.000: -0.8753220028122605\n",
      "Logical resource usage: 0/64 CPUs, 0.5/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (67 PENDING, 1 RUNNING, 12 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:16:37 (running for 00:02:40.40)\n",
      "Using AsyncHyperBand: num_stopped=13\n",
      "Bracket: Iter 40.000: -0.002911009670927149 | Iter 20.000: -0.004729229739725935 | Iter 10.000: -0.010167745614658228 | Iter 5.000: -0.8753220028122605\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (66 PENDING, 1 RUNNING, 13 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:16:42 (running for 00:02:45.47)\n",
      "Using AsyncHyperBand: num_stopped=14\n",
      "Bracket: Iter 40.000: -0.002911009670927149 | Iter 20.000: -0.004729229739725935 | Iter 10.000: -0.010822121712486142 | Iter 5.000: -0.7746734716772887\n",
      "Logical resource usage: 0/64 CPUs, 0.5/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (65 PENDING, 1 RUNNING, 14 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:16:47 (running for 00:02:50.49)\n",
      "Using AsyncHyperBand: num_stopped=15\n",
      "Bracket: Iter 40.000: -0.002911009670927149 | Iter 20.000: -0.004729229739725935 | Iter 10.000: -0.011261345627475954 | Iter 5.000: -0.674024940542317\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (64 PENDING, 1 RUNNING, 15 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:16:52 (running for 00:02:55.49)\n",
      "Using AsyncHyperBand: num_stopped=15\n",
      "Bracket: Iter 40.000: -0.002911009670927149 | Iter 20.000: -0.004729229739725935 | Iter 10.000: -0.01071454562106709 | Iter 5.000: -0.6733185695200521\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (63 PENDING, 2 RUNNING, 15 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:16:57 (running for 00:03:00.56)\n",
      "Using AsyncHyperBand: num_stopped=16\n",
      "Bracket: Iter 40.000: -0.002911009670927149 | Iter 20.000: -0.004729229739725935 | Iter 10.000: -0.01071454562106709 | Iter 5.000: -0.674024940542317\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (62 PENDING, 2 RUNNING, 16 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:17:02 (running for 00:03:05.57)\n",
      "Using AsyncHyperBand: num_stopped=16\n",
      "Bracket: Iter 40.000: -0.002911009670927149 | Iter 20.000: -0.004455528519165426 | Iter 10.000: -0.01071454562106709 | Iter 5.000: -0.6733185695200521\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (62 PENDING, 2 RUNNING, 16 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:17:08 (running for 00:03:10.64)\n",
      "Using AsyncHyperBand: num_stopped=16\n",
      "Bracket: Iter 40.000: -0.002911009670927149 | Iter 20.000: -0.004455528519165426 | Iter 10.000: -0.010167745614658228 | Iter 5.000: -0.6733185695200521\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (62 PENDING, 2 RUNNING, 16 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:17:13 (running for 00:03:15.70)\n",
      "Using AsyncHyperBand: num_stopped=16\n",
      "Bracket: Iter 40.000: -0.002911009670927149 | Iter 20.000: -0.004243346497682835 | Iter 10.000: -0.010167745614658228 | Iter 5.000: -0.6733185695200521\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (62 PENDING, 2 RUNNING, 16 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:17:18 (running for 00:03:20.78)\n",
      "Using AsyncHyperBand: num_stopped=16\n",
      "Bracket: Iter 40.000: -0.0028868668832675833 | Iter 20.000: -0.004243346497682835 | Iter 10.000: -0.010167745614658228 | Iter 5.000: -0.6733185695200521\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (62 PENDING, 2 RUNNING, 16 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:17:23 (running for 00:03:25.84)\n",
      "Using AsyncHyperBand: num_stopped=16\n",
      "Bracket: Iter 40.000: -0.0028868668832675833 | Iter 20.000: -0.004243346497682835 | Iter 10.000: -0.010167745614658228 | Iter 5.000: -0.6733185695200521\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (62 PENDING, 2 RUNNING, 16 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:17:28 (running for 00:03:30.93)\n",
      "Using AsyncHyperBand: num_stopped=16\n",
      "Bracket: Iter 40.000: -0.002854230701449029 | Iter 20.000: -0.004243346497682835 | Iter 10.000: -0.010167745614658228 | Iter 5.000: -0.6733185695200521\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (62 PENDING, 2 RUNNING, 16 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:17:33 (running for 00:03:36.02)\n",
      "Using AsyncHyperBand: num_stopped=17\n",
      "Bracket: Iter 40.000: -0.002854230701449029 | Iter 20.000: -0.004243346497682835 | Iter 10.000: -0.010167745614658228 | Iter 5.000: -0.6733185695200521\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (61 PENDING, 2 RUNNING, 17 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:17:38 (running for 00:03:41.08)\n",
      "Using AsyncHyperBand: num_stopped=17\n",
      "Bracket: Iter 40.000: -0.002854230701449029 | Iter 20.000: -0.004243346497682835 | Iter 10.000: -0.010167745614658228 | Iter 5.000: -0.6726121984977873\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (61 PENDING, 2 RUNNING, 17 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:17:43 (running for 00:03:46.18)\n",
      "Using AsyncHyperBand: num_stopped=18\n",
      "Bracket: Iter 40.000: -0.002854230701449029 | Iter 20.000: -0.004243346497682835 | Iter 10.000: -0.008997394654652668 | Iter 5.000: -0.6726121984977873\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (60 PENDING, 2 RUNNING, 18 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:17:48 (running for 00:03:51.25)\n",
      "Using AsyncHyperBand: num_stopped=18\n",
      "Bracket: Iter 40.000: -0.002854230701449029 | Iter 20.000: -0.004212586898143876 | Iter 10.000: -0.008997394654652668 | Iter 5.000: -0.6364113988037623\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (60 PENDING, 2 RUNNING, 18 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:17:53 (running for 00:03:56.27)\n",
      "Using AsyncHyperBand: num_stopped=19\n",
      "Bracket: Iter 40.000: -0.002854230701449029 | Iter 20.000: -0.004212586898143876 | Iter 10.000: -0.010167745614658228 | Iter 5.000: -0.6364113988037623\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (59 PENDING, 2 RUNNING, 19 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:17:58 (running for 00:04:01.28)\n",
      "Using AsyncHyperBand: num_stopped=19\n",
      "Bracket: Iter 40.000: -0.002854230701449029 | Iter 20.000: -0.004212586898143876 | Iter 10.000: -0.010167745614658228 | Iter 5.000: -0.6002105991097374\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (59 PENDING, 2 RUNNING, 19 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:18:03 (running for 00:04:06.31)\n",
      "Using AsyncHyperBand: num_stopped=19\n",
      "Bracket: Iter 40.000: -0.002821594519630475 | Iter 20.000: -0.004212586898143876 | Iter 10.000: -0.008997394654652668 | Iter 5.000: -0.6002105991097374\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (59 PENDING, 2 RUNNING, 19 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:18:08 (running for 00:04:11.36)\n",
      "Using AsyncHyperBand: num_stopped=19\n",
      "Bracket: Iter 40.000: -0.002821594519630475 | Iter 20.000: -0.004181827298604917 | Iter 10.000: -0.008997394654652668 | Iter 5.000: -0.6002105991097374\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (59 PENDING, 2 RUNNING, 19 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:18:13 (running for 00:04:16.39)\n",
      "Using AsyncHyperBand: num_stopped=19\n",
      "Bracket: Iter 40.000: -0.002821594519630475 | Iter 20.000: -0.004181827298604917 | Iter 10.000: -0.008997394654652668 | Iter 5.000: -0.6002105991097374\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (59 PENDING, 2 RUNNING, 19 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:18:18 (running for 00:04:21.42)\n",
      "Using AsyncHyperBand: num_stopped=20\n",
      "Bracket: Iter 40.000: -0.002821594519630475 | Iter 20.000: -0.004181827298604917 | Iter 10.000: -0.008997394654652668 | Iter 5.000: -0.6002105991097374\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (58 PENDING, 2 RUNNING, 20 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:18:23 (running for 00:04:26.46)\n",
      "Using AsyncHyperBand: num_stopped=20\n",
      "Bracket: Iter 40.000: -0.0025570467910871197 | Iter 20.000: -0.004181827298604917 | Iter 10.000: -0.008997394654652668 | Iter 5.000: -0.3203522539676476\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (58 PENDING, 2 RUNNING, 20 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:18:28 (running for 00:04:31.48)\n",
      "Using AsyncHyperBand: num_stopped=20\n",
      "Bracket: Iter 40.000: -0.0025570467910871197 | Iter 20.000: -0.004181827298604917 | Iter 10.000: -0.007827043694647106 | Iter 5.000: -0.3203522539676476\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (58 PENDING, 2 RUNNING, 20 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:18:33 (running for 00:04:36.49)\n",
      "Using AsyncHyperBand: num_stopped=20\n",
      "Bracket: Iter 40.000: -0.0025570467910871197 | Iter 20.000: -0.004108571562060993 | Iter 10.000: -0.007827043694647106 | Iter 5.000: -0.3203522539676476\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (58 PENDING, 2 RUNNING, 20 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:18:38 (running for 00:04:41.49)\n",
      "Using AsyncHyperBand: num_stopped=21\n",
      "Bracket: Iter 40.000: -0.0025570467910871197 | Iter 20.000: -0.004108571562060993 | Iter 10.000: -0.007827043694647106 | Iter 5.000: -0.3203522539676476\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (58 PENDING, 1 RUNNING, 21 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:18:43 (running for 00:04:46.55)\n",
      "Using AsyncHyperBand: num_stopped=21\n",
      "Bracket: Iter 40.000: -0.0025570467910871197 | Iter 20.000: -0.004108571562060993 | Iter 10.000: -0.007827043694647106 | Iter 5.000: -0.3203522539676476\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (57 PENDING, 2 RUNNING, 21 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:18:49 (running for 00:04:51.61)\n",
      "Using AsyncHyperBand: num_stopped=22\n",
      "Bracket: Iter 40.000: -0.002292499062543765 | Iter 20.000: -0.004108571562060993 | Iter 10.000: -0.008122486225133237 | Iter 5.000: -0.040493908825557756\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (57 PENDING, 1 RUNNING, 22 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:18:54 (running for 00:04:56.67)\n",
      "Using AsyncHyperBand: num_stopped=22\n",
      "Bracket: Iter 40.000: -0.002292499062543765 | Iter 20.000: -0.004108571562060993 | Iter 10.000: -0.008122486225133237 | Iter 5.000: -0.040493908825557756\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (56 PENDING, 2 RUNNING, 22 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:18:59 (running for 00:05:01.67)\n",
      "Using AsyncHyperBand: num_stopped=22\n",
      "Bracket: Iter 40.000: -0.002292499062543765 | Iter 20.000: -0.004108571562060993 | Iter 10.000: -0.008122486225133237 | Iter 5.000: -0.03939334467826873\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (56 PENDING, 2 RUNNING, 22 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:19:04 (running for 00:05:06.69)\n",
      "Using AsyncHyperBand: num_stopped=23\n",
      "Bracket: Iter 40.000: -0.002292499062543765 | Iter 20.000: -0.004108571562060993 | Iter 10.000: -0.007827043694647106 | Iter 5.000: -0.03939334467826873\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (56 PENDING, 1 RUNNING, 23 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:19:09 (running for 00:05:11.76)\n",
      "Using AsyncHyperBand: num_stopped=23\n",
      "Bracket: Iter 40.000: -0.002292499062543765 | Iter 20.000: -0.004035315825517069 | Iter 10.000: -0.007827043694647106 | Iter 5.000: -0.03939334467826873\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (55 PENDING, 2 RUNNING, 23 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:19:14 (running for 00:05:16.82)\n",
      "Using AsyncHyperBand: num_stopped=24\n",
      "Bracket: Iter 40.000: -0.002292499062543765 | Iter 20.000: -0.004035315825517069 | Iter 10.000: -0.007827043694647106 | Iter 5.000: -0.040493908825557756\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (54 PENDING, 2 RUNNING, 24 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:19:19 (running for 00:05:21.92)\n",
      "Using AsyncHyperBand: num_stopped=25\n",
      "Bracket: Iter 40.000: -0.002292499062543765 | Iter 20.000: -0.004035315825517069 | Iter 10.000: -0.007827043694647106 | Iter 5.000: -0.3203522539676476\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (53 PENDING, 2 RUNNING, 25 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:19:24 (running for 00:05:26.94)\n",
      "Using AsyncHyperBand: num_stopped=26\n",
      "Bracket: Iter 40.000: -0.0022152828211599884 | Iter 20.000: -0.004035315825517069 | Iter 10.000: -0.007827043694647106 | Iter 5.000: -0.6002105991097374\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (53 PENDING, 1 RUNNING, 26 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:19:29 (running for 00:05:31.97)\n",
      "Using AsyncHyperBand: num_stopped=26\n",
      "Bracket: Iter 40.000: -0.0022152828211599884 | Iter 20.000: -0.004035315825517069 | Iter 10.000: -0.007827043694647106 | Iter 5.000: -0.6002105991097374\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (52 PENDING, 2 RUNNING, 26 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:19:34 (running for 00:05:37.04)\n",
      "Using AsyncHyperBand: num_stopped=27\n",
      "Bracket: Iter 40.000: -0.0022152828211599884 | Iter 20.000: -0.004035315825517069 | Iter 10.000: -0.007827043694647106 | Iter 5.000: -0.6364113988037623\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (51 PENDING, 2 RUNNING, 27 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:19:39 (running for 00:05:42.14)\n",
      "Using AsyncHyperBand: num_stopped=29\n",
      "Bracket: Iter 40.000: -0.0022152828211599884 | Iter 20.000: -0.004035315825517069 | Iter 10.000: -0.007827043694647106 | Iter 5.000: -0.6726121984977873\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (50 PENDING, 1 RUNNING, 29 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:19:44 (running for 00:05:47.20)\n",
      "Using AsyncHyperBand: num_stopped=31\n",
      "Bracket: Iter 40.000: -0.0022152828211599884 | Iter 20.000: -0.004035315825517069 | Iter 10.000: -0.007827043694647106 | Iter 5.000: -0.674024940542317\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (48 PENDING, 1 RUNNING, 31 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:19:49 (running for 00:05:52.22)\n",
      "Using AsyncHyperBand: num_stopped=31\n",
      "Bracket: Iter 40.000: -0.0022152828211599884 | Iter 20.000: -0.004035315825517069 | Iter 10.000: -0.007827043694647106 | Iter 5.000: -0.6733185695200521\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (47 PENDING, 2 RUNNING, 31 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:19:54 (running for 00:05:57.30)\n",
      "Using AsyncHyperBand: num_stopped=33\n",
      "Bracket: Iter 40.000: -0.0022152828211599884 | Iter 20.000: -0.004035315825517069 | Iter 10.000: -0.008122486225133237 | Iter 5.000: -0.674024940542317\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (46 PENDING, 1 RUNNING, 33 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:19:59 (running for 00:06:02.32)\n",
      "Using AsyncHyperBand: num_stopped=35\n",
      "Bracket: Iter 40.000: -0.0022152828211599884 | Iter 20.000: -0.004035315825517069 | Iter 10.000: -0.008122486225133237 | Iter 5.000: -0.8753220028122605\n",
      "Logical resource usage: 0/64 CPUs, 0.5/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (45 PENDING, 35 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:20:04 (running for 00:06:07.36)\n",
      "Using AsyncHyperBand: num_stopped=35\n",
      "Bracket: Iter 40.000: -0.0022152828211599884 | Iter 20.000: -0.004035315825517069 | Iter 10.000: -0.008122486225133237 | Iter 5.000: -0.7746734716772887\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (43 PENDING, 2 RUNNING, 35 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:20:09 (running for 00:06:12.39)\n",
      "Using AsyncHyperBand: num_stopped=37\n",
      "Bracket: Iter 40.000: -0.0022152828211599884 | Iter 20.000: -0.004035315825517069 | Iter 10.000: -0.008417928755619367 | Iter 5.000: -0.8753220028122605\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (42 PENDING, 1 RUNNING, 37 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:20:14 (running for 00:06:17.43)\n",
      "Using AsyncHyperBand: num_stopped=37\n",
      "Bracket: Iter 40.000: -0.0022152828211599884 | Iter 20.000: -0.004035315825517069 | Iter 10.000: -0.008417928755619367 | Iter 5.000: -0.7746734716772887\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (41 PENDING, 2 RUNNING, 37 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:20:19 (running for 00:06:22.49)\n",
      "Using AsyncHyperBand: num_stopped=38\n",
      "Bracket: Iter 40.000: -0.0022152828211599884 | Iter 20.000: -0.004035315825517069 | Iter 10.000: -0.008417928755619367 | Iter 5.000: -0.674024940542317\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (40 PENDING, 2 RUNNING, 38 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:20:24 (running for 00:06:27.52)\n",
      "Using AsyncHyperBand: num_stopped=39\n",
      "Bracket: Iter 40.000: -0.0022152828211599884 | Iter 20.000: -0.004035315825517069 | Iter 10.000: -0.008417928755619367 | Iter 5.000: -0.7485994591370875\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (40 PENDING, 1 RUNNING, 39 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:20:30 (running for 00:06:32.61)\n",
      "Using AsyncHyperBand: num_stopped=39\n",
      "Bracket: Iter 40.000: -0.0022152828211599884 | Iter 20.000: -0.004020130163415077 | Iter 10.000: -0.008417928755619367 | Iter 5.000: -0.7485994591370875\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (39 PENDING, 2 RUNNING, 39 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:20:35 (running for 00:06:37.62)\n",
      "Using AsyncHyperBand: num_stopped=40\n",
      "Bracket: Iter 40.000: -0.0022152828211599884 | Iter 20.000: -0.004020130163415077 | Iter 10.000: -0.008417928755619367 | Iter 5.000: -0.823173977731858\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (38 PENDING, 2 RUNNING, 40 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:20:40 (running for 00:06:42.68)\n",
      "Using AsyncHyperBand: num_stopped=41\n",
      "Bracket: Iter 40.000: -0.002138066579776212 | Iter 20.000: -0.004020130163415077 | Iter 10.000: -0.008417928755619367 | Iter 5.000: -0.8492479902720592\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (38 PENDING, 1 RUNNING, 41 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:20:45 (running for 00:06:47.69)\n",
      "Using AsyncHyperBand: num_stopped=41\n",
      "Bracket: Iter 40.000: -0.002138066579776212 | Iter 20.000: -0.004020130163415077 | Iter 10.000: -0.008417928755619367 | Iter 5.000: -0.823173977731858\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (37 PENDING, 2 RUNNING, 41 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:20:50 (running for 00:06:52.70)\n",
      "Using AsyncHyperBand: num_stopped=41\n",
      "Bracket: Iter 40.000: -0.002138066579776212 | Iter 20.000: -0.004020130163415077 | Iter 10.000: -0.008122486225133237 | Iter 5.000: -0.823173977731858\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (37 PENDING, 2 RUNNING, 41 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:20:55 (running for 00:06:57.71)\n",
      "Using AsyncHyperBand: num_stopped=42\n",
      "Bracket: Iter 40.000: -0.002138066579776212 | Iter 20.000: -0.004020130163415077 | Iter 10.000: -0.008122486225133237 | Iter 5.000: -0.823173977731858\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (37 PENDING, 1 RUNNING, 42 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:21:00 (running for 00:07:02.78)\n",
      "Using AsyncHyperBand: num_stopped=42\n",
      "Bracket: Iter 40.000: -0.002138066579776212 | Iter 20.000: -0.004004944501313084 | Iter 10.000: -0.008122486225133237 | Iter 5.000: -0.823173977731858\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (36 PENDING, 2 RUNNING, 42 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:21:05 (running for 00:07:07.80)\n",
      "Using AsyncHyperBand: num_stopped=43\n",
      "Bracket: Iter 40.000: -0.002138066579776212 | Iter 20.000: -0.004004944501313084 | Iter 10.000: -0.008122486225133237 | Iter 5.000: -0.8492479902720592\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (35 PENDING, 2 RUNNING, 43 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:21:10 (running for 00:07:12.81)\n",
      "Using AsyncHyperBand: num_stopped=44\n",
      "Bracket: Iter 40.000: -0.0019935065073105043 | Iter 20.000: -0.004004944501313084 | Iter 10.000: -0.008122486225133237 | Iter 5.000: -0.8753220028122605\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (34 PENDING, 2 RUNNING, 44 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:21:15 (running for 00:07:17.82)\n",
      "Using AsyncHyperBand: num_stopped=44\n",
      "Bracket: Iter 40.000: -0.0019935065073105043 | Iter 20.000: -0.004004944501313084 | Iter 10.000: -0.008122486225133237 | Iter 5.000: -0.8492479902720592\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (34 PENDING, 2 RUNNING, 44 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:21:20 (running for 00:07:22.87)\n",
      "Using AsyncHyperBand: num_stopped=45\n",
      "Bracket: Iter 40.000: -0.0019935065073105043 | Iter 20.000: -0.004004944501313084 | Iter 10.000: -0.008417928755619367 | Iter 5.000: -0.8492479902720592\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (33 PENDING, 2 RUNNING, 45 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:21:25 (running for 00:07:27.88)\n",
      "Using AsyncHyperBand: num_stopped=47\n",
      "Bracket: Iter 40.000: -0.0019935065073105043 | Iter 20.000: -0.004004944501313084 | Iter 10.000: -0.008417928755619367 | Iter 5.000: -0.8753220028122605\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (33 PENDING, 47 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:21:30 (running for 00:07:32.89)\n",
      "Using AsyncHyperBand: num_stopped=47\n",
      "Bracket: Iter 40.000: -0.0019935065073105043 | Iter 20.000: -0.004004944501313084 | Iter 10.000: -0.008417928755619367 | Iter 5.000: -0.8753220028122605\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (31 PENDING, 2 RUNNING, 47 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:21:35 (running for 00:07:37.89)\n",
      "Using AsyncHyperBand: num_stopped=48\n",
      "Bracket: Iter 40.000: -0.0019935065073105043 | Iter 20.000: -0.004004944501313084 | Iter 10.000: -0.008122486225133237 | Iter 5.000: -0.8753220028122605\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (30 PENDING, 2 RUNNING, 48 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:21:40 (running for 00:07:42.99)\n",
      "Using AsyncHyperBand: num_stopped=48\n",
      "Bracket: Iter 40.000: -0.0019935065073105043 | Iter 20.000: -0.004004944501313084 | Iter 10.000: -0.008122486225133237 | Iter 5.000: -0.8492479902720592\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (30 PENDING, 2 RUNNING, 48 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:21:45 (running for 00:07:48.04)\n",
      "Using AsyncHyperBand: num_stopped=48\n",
      "Bracket: Iter 40.000: -0.0019935065073105043 | Iter 20.000: -0.003979693484712488 | Iter 10.000: -0.007827043694647106 | Iter 5.000: -0.8492479902720592\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (30 PENDING, 2 RUNNING, 48 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:21:50 (running for 00:07:53.07)\n",
      "Using AsyncHyperBand: num_stopped=48\n",
      "Bracket: Iter 40.000: -0.0019935065073105043 | Iter 20.000: -0.003954442468111893 | Iter 10.000: -0.007827043694647106 | Iter 5.000: -0.8492479902720592\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (30 PENDING, 2 RUNNING, 48 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:21:55 (running for 00:07:58.12)\n",
      "Using AsyncHyperBand: num_stopped=48\n",
      "Bracket: Iter 40.000: -0.0019935065073105043 | Iter 20.000: -0.003954442468111893 | Iter 10.000: -0.007827043694647106 | Iter 5.000: -0.8492479902720592\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (30 PENDING, 2 RUNNING, 48 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:22:00 (running for 00:08:03.13)\n",
      "Using AsyncHyperBand: num_stopped=49\n",
      "Bracket: Iter 40.000: -0.002138066579776212 | Iter 20.000: -0.003954442468111893 | Iter 10.000: -0.007827043694647106 | Iter 5.000: -0.8492479902720592\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (29 PENDING, 2 RUNNING, 49 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:22:05 (running for 00:08:08.20)\n",
      "Using AsyncHyperBand: num_stopped=51\n",
      "Bracket: Iter 40.000: -0.0021594060319159152 | Iter 20.000: -0.003954442468111893 | Iter 10.000: -0.007827043694647106 | Iter 5.000: -0.8753220028122605\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (29 PENDING, 51 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:22:10 (running for 00:08:13.20)\n",
      "Using AsyncHyperBand: num_stopped=51\n",
      "Bracket: Iter 40.000: -0.0021594060319159152 | Iter 20.000: -0.003954442468111893 | Iter 10.000: -0.007827043694647106 | Iter 5.000: -0.823173977731858\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (27 PENDING, 2 RUNNING, 51 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:22:15 (running for 00:08:18.23)\n",
      "Using AsyncHyperBand: num_stopped=51\n",
      "Bracket: Iter 40.000: -0.0021594060319159152 | Iter 20.000: -0.003954442468111893 | Iter 10.000: -0.007296141518074993 | Iter 5.000: -0.823173977731858\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (27 PENDING, 2 RUNNING, 51 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:22:20 (running for 00:08:23.24)\n",
      "Using AsyncHyperBand: num_stopped=51\n",
      "Bracket: Iter 40.000: -0.0021594060319159152 | Iter 20.000: -0.003954442468111893 | Iter 10.000: -0.007296141518074993 | Iter 5.000: -0.823173977731858\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (27 PENDING, 2 RUNNING, 51 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:22:25 (running for 00:08:28.30)\n",
      "Using AsyncHyperBand: num_stopped=52\n",
      "Bracket: Iter 40.000: -0.0021594060319159152 | Iter 20.000: -0.003954442468111893 | Iter 10.000: -0.007296141518074993 | Iter 5.000: -0.823173977731858\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (26 PENDING, 2 RUNNING, 52 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:22:30 (running for 00:08:33.37)\n",
      "Using AsyncHyperBand: num_stopped=53\n",
      "Bracket: Iter 40.000: -0.0021594060319159152 | Iter 20.000: -0.003954442468111893 | Iter 10.000: -0.007296141518074993 | Iter 5.000: -0.8492479902720592\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (26 PENDING, 1 RUNNING, 53 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:22:35 (running for 00:08:38.47)\n",
      "Using AsyncHyperBand: num_stopped=54\n",
      "Bracket: Iter 40.000: -0.002138066579776212 | Iter 20.000: -0.003954442468111893 | Iter 10.000: -0.007296141518074993 | Iter 5.000: -0.8753220028122605\n",
      "Logical resource usage: 0/64 CPUs, 0.5/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (25 PENDING, 1 RUNNING, 54 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:22:40 (running for 00:08:43.51)\n",
      "Using AsyncHyperBand: num_stopped=54\n",
      "Bracket: Iter 40.000: -0.002138066579776212 | Iter 20.000: -0.003954442468111893 | Iter 10.000: -0.007296141518074993 | Iter 5.000: -0.8753220028122605\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (24 PENDING, 2 RUNNING, 54 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:22:46 (running for 00:08:48.60)\n",
      "Using AsyncHyperBand: num_stopped=55\n",
      "Bracket: Iter 40.000: -0.002138066579776212 | Iter 20.000: -0.003954442468111893 | Iter 10.000: -0.007296141518074993 | Iter 5.000: -0.8780665922821387\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (23 PENDING, 2 RUNNING, 55 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:22:51 (running for 00:08:53.68)\n",
      "Using AsyncHyperBand: num_stopped=56\n",
      "Bracket: Iter 40.000: -0.002138066579776212 | Iter 20.000: -0.003954442468111893 | Iter 10.000: -0.007296141518074993 | Iter 5.000: -0.8753220028122605\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (23 PENDING, 1 RUNNING, 56 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:22:56 (running for 00:08:58.72)\n",
      "Using AsyncHyperBand: num_stopped=57\n",
      "Bracket: Iter 40.000: -0.002138066579776212 | Iter 20.000: -0.003954442468111893 | Iter 10.000: -0.00756159260636105 | Iter 5.000: -0.8492479902720592\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (21 PENDING, 2 RUNNING, 57 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:23:01 (running for 00:09:03.75)\n",
      "Using AsyncHyperBand: num_stopped=58\n",
      "Bracket: Iter 40.000: -0.002138066579776212 | Iter 20.000: -0.003954442468111893 | Iter 10.000: -0.007827043694647106 | Iter 5.000: -0.823173977731858\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (21 PENDING, 1 RUNNING, 58 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:23:06 (running for 00:09:08.85)\n",
      "Using AsyncHyperBand: num_stopped=58\n",
      "Bracket: Iter 40.000: -0.002138066579776212 | Iter 20.000: -0.003954442468111893 | Iter 10.000: -0.00756159260636105 | Iter 5.000: -0.823173977731858\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (20 PENDING, 2 RUNNING, 58 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:23:11 (running for 00:09:13.94)\n",
      "Using AsyncHyperBand: num_stopped=60\n",
      "Bracket: Iter 40.000: -0.002138066579776212 | Iter 20.000: -0.003979693484712488 | Iter 10.000: -0.00756159260636105 | Iter 5.000: -0.8492479902720592\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (19 PENDING, 1 RUNNING, 60 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:23:16 (running for 00:09:19.01)\n",
      "Using AsyncHyperBand: num_stopped=60\n",
      "Bracket: Iter 40.000: -0.002138066579776212 | Iter 20.000: -0.003979693484712488 | Iter 10.000: -0.00756159260636105 | Iter 5.000: -0.7485994591370875\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (18 PENDING, 2 RUNNING, 60 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:23:21 (running for 00:09:24.04)\n",
      "Using AsyncHyperBand: num_stopped=61\n",
      "Bracket: Iter 40.000: -0.002138066579776212 | Iter 20.000: -0.003979693484712488 | Iter 10.000: -0.00756159260636105 | Iter 5.000: -0.7485994591370875\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (18 PENDING, 1 RUNNING, 61 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:23:26 (running for 00:09:29.10)\n",
      "Using AsyncHyperBand: num_stopped=61\n",
      "Bracket: Iter 40.000: -0.002138066579776212 | Iter 20.000: -0.003954442468111893 | Iter 10.000: -0.00756159260636105 | Iter 5.000: -0.674024940542317\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (17 PENDING, 2 RUNNING, 61 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:23:31 (running for 00:09:34.19)\n",
      "Using AsyncHyperBand: num_stopped=62\n",
      "Bracket: Iter 40.000: -0.002138066579776212 | Iter 20.000: -0.003954442468111893 | Iter 10.000: -0.007827043694647106 | Iter 5.000: -0.674024940542317\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (17 PENDING, 1 RUNNING, 62 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:23:36 (running for 00:09:39.24)\n",
      "Using AsyncHyperBand: num_stopped=63\n",
      "Bracket: Iter 40.000: -0.002138066579776212 | Iter 20.000: -0.003954442468111893 | Iter 10.000: -0.007827043694647106 | Iter 5.000: -0.6744199050145301\n",
      "Logical resource usage: 0/64 CPUs, 0.5/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (16 PENDING, 1 RUNNING, 63 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:23:41 (running for 00:09:44.28)\n",
      "Using AsyncHyperBand: num_stopped=63\n",
      "Bracket: Iter 40.000: -0.0019935065073105043 | Iter 20.000: -0.003954442468111893 | Iter 10.000: -0.007827043694647106 | Iter 5.000: -0.6744199050145301\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (15 PENDING, 2 RUNNING, 63 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:23:46 (running for 00:09:49.31)\n",
      "Using AsyncHyperBand: num_stopped=63\n",
      "Bracket: Iter 40.000: -0.0019935065073105043 | Iter 20.000: -0.003954442468111893 | Iter 10.000: -0.007827043694647106 | Iter 5.000: -0.674024940542317\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (15 PENDING, 2 RUNNING, 63 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:23:51 (running for 00:09:54.37)\n",
      "Using AsyncHyperBand: num_stopped=64\n",
      "Bracket: Iter 40.000: -0.0019935065073105043 | Iter 20.000: -0.003954442468111893 | Iter 10.000: -0.008122486225133237 | Iter 5.000: -0.674024940542317\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (14 PENDING, 2 RUNNING, 64 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:23:56 (running for 00:09:59.37)\n",
      "Using AsyncHyperBand: num_stopped=65\n",
      "Bracket: Iter 40.000: -0.0019935065073105043 | Iter 20.000: -0.003954442468111893 | Iter 10.000: -0.008122486225133237 | Iter 5.000: -0.6733185695200521\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (13 PENDING, 2 RUNNING, 65 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:24:01 (running for 00:10:04.38)\n",
      "Using AsyncHyperBand: num_stopped=66\n",
      "Bracket: Iter 40.000: -0.0019935065073105043 | Iter 20.000: -0.003954442468111893 | Iter 10.000: -0.008417928755619367 | Iter 5.000: -0.6726121984977873\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (12 PENDING, 2 RUNNING, 66 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:24:06 (running for 00:10:09.41)\n",
      "Using AsyncHyperBand: num_stopped=67\n",
      "Bracket: Iter 40.000: -0.0019935065073105043 | Iter 20.000: -0.003954442468111893 | Iter 10.000: -0.008671010661216545 | Iter 5.000: -0.6364113988037623\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (11 PENDING, 2 RUNNING, 67 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:24:11 (running for 00:10:14.45)\n",
      "Using AsyncHyperBand: num_stopped=68\n",
      "Bracket: Iter 40.000: -0.0019935065073105043 | Iter 20.000: -0.003954442468111893 | Iter 10.000: -0.008417928755619367 | Iter 5.000: -0.6726121984977873\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (11 PENDING, 1 RUNNING, 68 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:24:16 (running for 00:10:19.54)\n",
      "Using AsyncHyperBand: num_stopped=69\n",
      "Bracket: Iter 40.000: -0.0019935065073105043 | Iter 20.000: -0.003941807176187783 | Iter 10.000: -0.008417928755619367 | Iter 5.000: -0.6733185695200521\n",
      "Logical resource usage: 0/64 CPUs, 0.5/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (10 PENDING, 1 RUNNING, 69 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:24:21 (running for 00:10:24.54)\n",
      "Using AsyncHyperBand: num_stopped=69\n",
      "Bracket: Iter 40.000: -0.0019935065073105043 | Iter 20.000: -0.003941807176187783 | Iter 10.000: -0.008417928755619367 | Iter 5.000: -0.6733185695200521\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (9 PENDING, 2 RUNNING, 69 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:24:27 (running for 00:10:29.60)\n",
      "Using AsyncHyperBand: num_stopped=69\n",
      "Bracket: Iter 40.000: -0.0019935065073105043 | Iter 20.000: -0.003941807176187783 | Iter 10.000: -0.008417928755619367 | Iter 5.000: -0.6726121984977873\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (9 PENDING, 2 RUNNING, 69 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:24:32 (running for 00:10:34.70)\n",
      "Using AsyncHyperBand: num_stopped=69\n",
      "Bracket: Iter 40.000: -0.0018489464348447966 | Iter 20.000: -0.003941807176187783 | Iter 10.000: -0.008122486225133237 | Iter 5.000: -0.6726121984977873\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (9 PENDING, 2 RUNNING, 69 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:24:37 (running for 00:10:39.79)\n",
      "Using AsyncHyperBand: num_stopped=69\n",
      "Bracket: Iter 40.000: -0.0018489464348447966 | Iter 20.000: -0.003929171884263674 | Iter 10.000: -0.008122486225133237 | Iter 5.000: -0.6726121984977873\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (9 PENDING, 2 RUNNING, 69 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:24:42 (running for 00:10:44.83)\n",
      "Using AsyncHyperBand: num_stopped=69\n",
      "Bracket: Iter 40.000: -0.0018489464348447966 | Iter 20.000: -0.003929171884263674 | Iter 10.000: -0.008122486225133237 | Iter 5.000: -0.6726121984977873\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (9 PENDING, 2 RUNNING, 69 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:24:47 (running for 00:10:49.87)\n",
      "Using AsyncHyperBand: num_stopped=70\n",
      "Bracket: Iter 40.000: -0.0018489464348447966 | Iter 20.000: -0.003929171884263674 | Iter 10.000: -0.008122486225133237 | Iter 5.000: -0.6726121984977873\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (8 PENDING, 2 RUNNING, 70 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:24:52 (running for 00:10:54.88)\n",
      "Using AsyncHyperBand: num_stopped=71\n",
      "Bracket: Iter 40.000: -0.0018283209650871832 | Iter 20.000: -0.003929171884263674 | Iter 10.000: -0.008122486225133237 | Iter 5.000: -0.6733185695200521\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (8 PENDING, 1 RUNNING, 71 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:24:57 (running for 00:10:59.91)\n",
      "Using AsyncHyperBand: num_stopped=71\n",
      "Bracket: Iter 40.000: -0.0018283209650871832 | Iter 20.000: -0.003929171884263674 | Iter 10.000: -0.008122486225133237 | Iter 5.000: -0.6733185695200521\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (7 PENDING, 2 RUNNING, 71 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:25:02 (running for 00:11:04.99)\n",
      "Using AsyncHyperBand: num_stopped=72\n",
      "Bracket: Iter 40.000: -0.0018283209650871832 | Iter 20.000: -0.003929171884263674 | Iter 10.000: -0.008417928755619367 | Iter 5.000: -0.6726121984977873\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (7 PENDING, 1 RUNNING, 72 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:25:07 (running for 00:11:10.00)\n",
      "Using AsyncHyperBand: num_stopped=73\n",
      "Bracket: Iter 40.000: -0.0018283209650871832 | Iter 20.000: -0.003929171884263674 | Iter 10.000: -0.008417928755619367 | Iter 5.000: -0.6726121984977873\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (5 PENDING, 2 RUNNING, 73 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:25:12 (running for 00:11:15.10)\n",
      "Using AsyncHyperBand: num_stopped=75\n",
      "Bracket: Iter 40.000: -0.0018283209650871832 | Iter 20.000: -0.003929171884263674 | Iter 10.000: -0.008417928755619367 | Iter 5.000: -0.674024940542317\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (4 PENDING, 1 RUNNING, 75 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:25:17 (running for 00:11:20.12)\n",
      "Using AsyncHyperBand: num_stopped=77\n",
      "Bracket: Iter 40.000: -0.0018283209650871832 | Iter 20.000: -0.003929171884263674 | Iter 10.000: -0.008417928755619367 | Iter 5.000: -0.6748148694867432\n",
      "Logical resource usage: 0/64 CPUs, 0.5/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (3 PENDING, 77 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:25:22 (running for 00:11:25.19)\n",
      "Using AsyncHyperBand: num_stopped=77\n",
      "Bracket: Iter 40.000: -0.0018283209650871832 | Iter 20.000: -0.003929171884263674 | Iter 10.000: -0.008417928755619367 | Iter 5.000: -0.6744199050145301\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (1 PENDING, 2 RUNNING, 77 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:25:27 (running for 00:11:30.26)\n",
      "Using AsyncHyperBand: num_stopped=77\n",
      "Bracket: Iter 40.000: -0.0018283209650871832 | Iter 20.000: -0.003929171884263674 | Iter 10.000: -0.008122486225133237 | Iter 5.000: -0.674024940542317\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (1 PENDING, 2 RUNNING, 77 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:25:32 (running for 00:11:35.28)\n",
      "Using AsyncHyperBand: num_stopped=77\n",
      "Bracket: Iter 40.000: -0.0018283209650871832 | Iter 20.000: -0.003929171884263674 | Iter 10.000: -0.007827043694647106 | Iter 5.000: -0.674024940542317\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (1 PENDING, 2 RUNNING, 77 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:25:37 (running for 00:11:40.33)\n",
      "Using AsyncHyperBand: num_stopped=77\n",
      "Bracket: Iter 40.000: -0.0018283209650871832 | Iter 20.000: -0.003795123658505842 | Iter 10.000: -0.007827043694647106 | Iter 5.000: -0.674024940542317\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (1 PENDING, 2 RUNNING, 77 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:25:42 (running for 00:11:45.37)\n",
      "Using AsyncHyperBand: num_stopped=77\n",
      "Bracket: Iter 40.000: -0.0018283209650871832 | Iter 20.000: -0.003795123658505842 | Iter 10.000: -0.007827043694647106 | Iter 5.000: -0.674024940542317\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (1 PENDING, 2 RUNNING, 77 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:25:47 (running for 00:11:50.39)\n",
      "Using AsyncHyperBand: num_stopped=77\n",
      "Bracket: Iter 40.000: -0.0018283209650871832 | Iter 20.000: -0.003795123658505842 | Iter 10.000: -0.007827043694647106 | Iter 5.000: -0.674024940542317\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (1 PENDING, 2 RUNNING, 77 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:25:52 (running for 00:11:55.43)\n",
      "Using AsyncHyperBand: num_stopped=78\n",
      "Bracket: Iter 40.000: -0.0018283209650871832 | Iter 20.000: -0.003795123658505842 | Iter 10.000: -0.007827043694647106 | Iter 5.000: -0.674024940542317\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (2 RUNNING, 78 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:25:57 (running for 00:12:00.48)\n",
      "Using AsyncHyperBand: num_stopped=78\n",
      "Bracket: Iter 40.000: -0.0018283209650871832 | Iter 20.000: -0.003795123658505842 | Iter 10.000: -0.007827043694647106 | Iter 5.000: -0.6733185695200521\n",
      "Logical resource usage: 0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (2 RUNNING, 78 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 16:26:02 (running for 00:12:05.55)\n",
      "Using AsyncHyperBand: num_stopped=79\n",
      "Bracket: Iter 40.000: -0.0018283209650871832 | Iter 20.000: -0.003795123658505842 | Iter 10.000: -0.008122486225133237 | Iter 5.000: -0.6733185695200521\n",
      "Logical resource usage: 0/64 CPUs, 0.5/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (1 RUNNING, 79 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-02 16:26:03,655\tINFO tune.py:1143 -- Total run time: 726.27 seconds (726.23 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-11-02 16:26:03 (running for 00:12:06.24)\n",
      "Using AsyncHyperBand: num_stopped=80\n",
      "Bracket: Iter 40.000: -0.0018283209650871832 | Iter 20.000: -0.003795123658505842 | Iter 10.000: -0.008122486225133237 | Iter 5.000: -0.6733185695200521\n",
      "Logical resource usage: 0/64 CPUs, 0.5/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_16-13-57\n",
      "Number of trials: 80/80 (80 TERMINATED)\n",
      "+-------------------------------+------------+-----------------------+-------------+------------+--------------+------------+-----------------+----------------------+\n",
      "| Trial name                    | status     | loc                   |          lr |   momentum |   train_loss |   val_loss |   combined_loss |   training_iteration |\n",
      "|-------------------------------+------------+-----------------------+-------------+------------+--------------+------------+-----------------+----------------------|\n",
      "| train_with_tuning_7fcaa_00000 | TERMINATED | 169.237.32.34:1780848 | 0.000125161 |   0.93146  |   0.0593873  |  0.0724027 |     0.0042998   |                   60 |\n",
      "| train_with_tuning_7fcaa_00001 | TERMINATED | 169.237.32.34:1780849 | 2.80892e-05 |   0.935314 |   1.00633    |  0.781322  |     0.78627     |                   20 |\n",
      "| train_with_tuning_7fcaa_00002 | TERMINATED | 169.237.32.34:1791871 | 4.47507e-05 |   0.941833 |   1.08623    |  0.843608  |     0.916355    |                    5 |\n",
      "| train_with_tuning_7fcaa_00003 | TERMINATED | 169.237.32.34:1796061 | 0.000499398 |   0.924946 |   0.0250048  |  0.0314111 |     0.000785426 |                   60 |\n",
      "| train_with_tuning_7fcaa_00004 | TERMINATED | 169.237.32.34:1810445 | 1.53939e-05 |   0.869866 |   1.19612    |  0.88063   |     1.05334     |                    5 |\n",
      "| train_with_tuning_7fcaa_00005 | TERMINATED | 169.237.32.34:1814569 | 3.07595e-05 |   0.984872 |   0.0705591  |  0.071295  |     0.00503051  |                   40 |\n",
      "| train_with_tuning_7fcaa_00006 | TERMINATED | 169.237.32.34:1826763 | 0.000608265 |   0.919916 |   0.0237362  |  0.0327086 |     0.000776379 |                   60 |\n",
      "| train_with_tuning_7fcaa_00007 | TERMINATED | 169.237.32.34:1835846 | 0.000101222 |   0.909612 |   1.05849    |  0.826952  |     0.875322    |                    5 |\n",
      "| train_with_tuning_7fcaa_00008 | TERMINATED | 169.237.32.34:1839907 | 2.45746e-05 |   0.937266 |   1.12874    |  0.854004  |     0.96395     |                    5 |\n",
      "| train_with_tuning_7fcaa_00009 | TERMINATED | 169.237.32.34:1843966 | 1.11849e-05 |   0.92264  |   1.1864     |  0.875525  |     1.03872     |                    5 |\n",
      "| train_with_tuning_7fcaa_00010 | TERMINATED | 169.237.32.34:1848031 | 0.000760181 |   0.981246 |   0.00192802 |  0.0142582 |     2.749e-05   |                   60 |\n",
      "| train_with_tuning_7fcaa_00011 | TERMINATED | 169.237.32.34:1855756 | 5.49943e-05 |   0.802937 |   1.14923    |  0.86014   |     0.9885      |                    5 |\n",
      "| train_with_tuning_7fcaa_00012 | TERMINATED | 169.237.32.34:1859814 | 7.18403e-05 |   0.983664 |   0.051156   |  0.0689953 |     0.00352952  |                   40 |\n",
      "| train_with_tuning_7fcaa_00013 | TERMINATED | 169.237.32.34:1879347 | 0.000508182 |   0.855945 |   0.159146   |  0.0721131 |     0.0114765   |                   10 |\n",
      "| train_with_tuning_7fcaa_00014 | TERMINATED | 169.237.32.34:1881290 | 0.000503818 |   0.860215 |   0.155933   |  0.0722189 |     0.0112613   |                   10 |\n",
      "| train_with_tuning_7fcaa_00015 | TERMINATED | 169.237.32.34:1884700 | 0.000129898 |   0.977869 |   0.0310353  |  0.0378534 |     0.00117479  |                   60 |\n",
      "| train_with_tuning_7fcaa_00016 | TERMINATED | 169.237.32.34:1886838 | 0.000138077 |   0.818464 |   1.08664    |  0.843436  |     0.91651     |                    5 |\n",
      "| train_with_tuning_7fcaa_00017 | TERMINATED | 169.237.32.34:1890836 | 0.000955229 |   0.826616 |   0.0303273  |  0.0368042 |     0.00111617  |                   60 |\n",
      "| train_with_tuning_7fcaa_00018 | TERMINATED | 169.237.32.34:1915659 | 0.000568521 |   0.940746 |   0.0160555  |  0.0251284 |     0.00040345  |                   60 |\n",
      "| train_with_tuning_7fcaa_00019 | TERMINATED | 169.237.32.34:1922769 | 0.000254079 |   0.868303 |   0.429848   |  0.0782808 |     0.0336488   |                   10 |\n",
      "| train_with_tuning_7fcaa_00020 | TERMINATED | 169.237.32.34:1929115 | 0.000415645 |   0.953922 |   0.0177826  |  0.0272079 |     0.000483827 |                   60 |\n",
      "| train_with_tuning_7fcaa_00021 | TERMINATED | 169.237.32.34:1946359 | 0.000670627 |   0.897155 |   0.025054   |  0.0313837 |     0.000786289 |                   60 |\n",
      "| train_with_tuning_7fcaa_00022 | TERMINATED | 169.237.32.34:1961290 | 0.000394994 |   0.923493 |   0.114264   |  0.0736707 |     0.00841793  |                   10 |\n",
      "| train_with_tuning_7fcaa_00023 | TERMINATED | 169.237.32.34:1968264 | 0.000390468 |   0.969101 |   0.0108813  |  0.0211929 |     0.000230605 |                   60 |\n",
      "| train_with_tuning_7fcaa_00024 | TERMINATED | 169.237.32.34:1977080 | 5.63853e-05 |   0.817857 |   1.14297    |  0.858111  |     0.980791    |                    5 |\n",
      "| train_with_tuning_7fcaa_00025 | TERMINATED | 169.237.32.34:1981075 | 1.18001e-05 |   0.888464 |   1.20141    |  0.883517  |     1.06147     |                    5 |\n",
      "| train_with_tuning_7fcaa_00026 | TERMINATED | 169.237.32.34:1985071 | 3.74182e-05 |   0.912258 |   1.12339    |  0.85268   |     0.957889    |                    5 |\n",
      "| train_with_tuning_7fcaa_00027 | TERMINATED | 169.237.32.34:1989003 | 1.18767e-05 |   0.956294 |   1.15137    |  0.860712  |     0.991001    |                    5 |\n",
      "| train_with_tuning_7fcaa_00028 | TERMINATED | 169.237.32.34:1993061 | 1.79523e-05 |   0.899226 |   1.17526    |  0.870268  |     1.02279     |                    5 |\n",
      "| train_with_tuning_7fcaa_00029 | TERMINATED | 169.237.32.34:1995139 | 2.70173e-05 |   0.918349 |   1.13907    |  0.856873  |     0.976035    |                    5 |\n",
      "| train_with_tuning_7fcaa_00030 | TERMINATED | 169.237.32.34:1996154 | 1.26871e-05 |   0.900957 |   1.19235    |  0.878594  |     1.04759     |                    5 |\n",
      "| train_with_tuning_7fcaa_00031 | TERMINATED | 169.237.32.34:1998115 | 0.000188304 |   0.937957 |   0.193154   |  0.0721945 |     0.0139447   |                   10 |\n",
      "| train_with_tuning_7fcaa_00032 | TERMINATED | 169.237.32.34:1998847 | 0.000107796 |   0.861362 |   1.08524    |  0.842992  |     0.914845    |                    5 |\n",
      "| train_with_tuning_7fcaa_00033 | TERMINATED | 169.237.32.34:2002667 | 3.48068e-05 |   0.883405 |   1.14527    |  0.85881   |     0.983569    |                    5 |\n",
      "| train_with_tuning_7fcaa_00034 | TERMINATED | 169.237.32.34:2003003 | 1.12383e-05 |   0.982903 |   1.0974     |  0.84717   |     0.929685    |                    5 |\n",
      "| train_with_tuning_7fcaa_00035 | TERMINATED | 169.237.32.34:2005374 | 0.000246575 |   0.877701 |   0.403719   |  0.0758263 |     0.0306125   |                   10 |\n",
      "| train_with_tuning_7fcaa_00036 | TERMINATED | 169.237.32.34:2005862 | 2.05529e-05 |   0.847546 |   1.18972    |  0.87725   |     1.04368     |                    5 |\n",
      "| train_with_tuning_7fcaa_00037 | TERMINATED | 169.237.32.34:2009531 | 0.000268653 |   0.925438 |   0.157304   |  0.0718758 |     0.0113063   |                   10 |\n",
      "| train_with_tuning_7fcaa_00038 | TERMINATED | 169.237.32.34:2010000 | 0.000812326 |   0.9402   |   0.00981792 |  0.0199336 |     0.000195706 |                   60 |\n",
      "| train_with_tuning_7fcaa_00039 | TERMINATED | 169.237.32.34:2014749 | 0.000167279 |   0.879724 |   1.03467    |  0.795594  |     0.823174    |                    5 |\n",
      "| train_with_tuning_7fcaa_00040 | TERMINATED | 169.237.32.34:2018810 | 5.15164e-05 |   0.943991 |   1.07409    |  0.838616  |     0.900753    |                    5 |\n",
      "| train_with_tuning_7fcaa_00041 | TERMINATED | 169.237.32.34:2023003 | 1.70665e-05 |   0.808741 |   1.20891    |  0.887786  |     1.07325     |                    5 |\n",
      "| train_with_tuning_7fcaa_00042 | TERMINATED | 169.237.32.34:2027192 | 0.00051395  |   0.933695 |   0.0230197  |  0.0321429 |     0.000739922 |                   60 |\n",
      "| train_with_tuning_7fcaa_00043 | TERMINATED | 169.237.32.34:2037873 | 1.56916e-05 |   0.893407 |   1.18536    |  0.875038  |     1.03723     |                    5 |\n",
      "| train_with_tuning_7fcaa_00044 | TERMINATED | 169.237.32.34:2041709 | 2.22026e-05 |   0.882432 |   1.172      |  0.868847  |     1.01829     |                    5 |\n",
      "| train_with_tuning_7fcaa_00045 | TERMINATED | 169.237.32.34:2045735 | 0.000170491 |   0.920668 |   0.367145   |  0.0743277 |     0.027289    |                   10 |\n",
      "| train_with_tuning_7fcaa_00046 | TERMINATED | 169.237.32.34:2052175 | 5.61339e-05 |   0.918913 |   1.09294    |  0.845489  |     0.924066    |                    5 |\n",
      "| train_with_tuning_7fcaa_00047 | TERMINATED | 169.237.32.34:2055840 | 0.000516392 |   0.925152 |   0.0420688  |  0.0518377 |     0.00218075  |                   40 |\n",
      "| train_with_tuning_7fcaa_00048 | TERMINATED | 169.237.32.34:2055841 | 1.384e-05   |   0.92206  |   1.17553    |  0.870363  |     1.02314     |                    5 |\n",
      "| train_with_tuning_7fcaa_00049 | TERMINATED | 169.237.32.34:2058937 | 0.00014844  |   0.978644 |   0.0428676  |  0.0535932 |     0.00229741  |                   40 |\n",
      "| train_with_tuning_7fcaa_00050 | TERMINATED | 169.237.32.34:2076087 | 5.97503e-05 |   0.922225 |   1.0862     |  0.843472  |     0.916178    |                    5 |\n",
      "| train_with_tuning_7fcaa_00051 | TERMINATED | 169.237.32.34:2080013 | 0.000123377 |   0.978878 |   0.0593064  |  0.0705849 |     0.00418614  |                   20 |\n",
      "| train_with_tuning_7fcaa_00052 | TERMINATED | 169.237.32.34:2080014 | 0.000836337 |   0.972017 |   0.0035141  |  0.0165309 |     5.8091e-05  |                   60 |\n",
      "| train_with_tuning_7fcaa_00053 | TERMINATED | 169.237.32.34:2090914 | 1.37633e-05 |   0.819148 |   1.21552    |  0.891737  |     1.08392     |                    5 |\n",
      "| train_with_tuning_7fcaa_00054 | TERMINATED | 169.237.32.34:2094972 | 1.54485e-05 |   0.929771 |   1.16353    |  0.865295  |     1.0068      |                    5 |\n",
      "| train_with_tuning_7fcaa_00055 | TERMINATED | 169.237.32.34:2099037 | 4.34461e-05 |   0.960526 |   1.06092    |  0.830232  |     0.880811    |                    5 |\n",
      "| train_with_tuning_7fcaa_00056 | TERMINATED | 169.237.32.34:2103235 | 0.000425537 |   0.853552 |   0.202495   |  0.0725193 |     0.0146848   |                   10 |\n",
      "| train_with_tuning_7fcaa_00057 | TERMINATED | 169.237.32.34:2107427 | 0.000247443 |   0.919499 |   0.188082   |  0.0720795 |     0.0135569   |                   10 |\n",
      "| train_with_tuning_7fcaa_00058 | TERMINATED | 169.237.32.34:2108578 | 0.000295217 |   0.952661 |   0.0579233  |  0.0703226 |     0.00407332  |                   20 |\n",
      "| train_with_tuning_7fcaa_00059 | TERMINATED | 169.237.32.34:2112834 | 2.26401e-05 |   0.942617 |   1.12833    |  0.853891  |     0.963473    |                    5 |\n",
      "| train_with_tuning_7fcaa_00060 | TERMINATED | 169.237.32.34:2116833 | 0.000957217 |   0.878397 |   0.0226249  |  0.0320314 |     0.000724706 |                   60 |\n",
      "| train_with_tuning_7fcaa_00061 | TERMINATED | 169.237.32.34:2118114 | 0.00035713  |   0.864753 |   0.240769   |  0.0731495 |     0.0176121   |                   10 |\n",
      "| train_with_tuning_7fcaa_00062 | TERMINATED | 169.237.32.34:2124555 | 0.000520985 |   0.881509 |   0.131933   |  0.0740074 |     0.00976401  |                   10 |\n",
      "| train_with_tuning_7fcaa_00063 | TERMINATED | 169.237.32.34:2130995 | 0.000322913 |   0.819594 |   0.97985    |  0.688692  |     0.674815    |                    5 |\n",
      "| train_with_tuning_7fcaa_00064 | TERMINATED | 169.237.32.34:2134990 | 0.000102448 |   0.957027 |   0.311104   |  0.0740925 |     0.0230505   |                   10 |\n",
      "| train_with_tuning_7fcaa_00065 | TERMINATED | 169.237.32.34:2141634 | 0.000618083 |   0.873948 |   0.119674   |  0.07457   |     0.00892409  |                   10 |\n",
      "| train_with_tuning_7fcaa_00066 | TERMINATED | 169.237.32.34:2144501 | 0.000646791 |   0.817344 |   0.158253   |  0.0722343 |     0.0114313   |                   10 |\n",
      "| train_with_tuning_7fcaa_00067 | TERMINATED | 169.237.32.34:2147236 | 0.000794555 |   0.980615 |   0.00192101 |  0.0141649 |     2.72109e-05 |                   60 |\n",
      "| train_with_tuning_7fcaa_00068 | TERMINATED | 169.237.32.34:2149972 | 0.000183516 |   0.885205 |   1.01112    |  0.753406  |     0.761788    |                    5 |\n",
      "| train_with_tuning_7fcaa_00069 | TERMINATED | 169.237.32.34:2153763 | 4.54286e-05 |   0.927779 |   1.09911    |  0.847088  |     0.931043    |                    5 |\n",
      "| train_with_tuning_7fcaa_00070 | TERMINATED | 169.237.32.34:2157821 | 0.000382964 |   0.950027 |   0.0233467  |  0.0326364 |     0.000761952 |                   60 |\n",
      "| train_with_tuning_7fcaa_00071 | TERMINATED | 169.237.32.34:2176741 | 9.74632e-05 |   0.810936 |   1.11145    |  0.849886  |     0.944603    |                    5 |\n",
      "| train_with_tuning_7fcaa_00072 | TERMINATED | 169.237.32.34:2180736 | 7.63943e-05 |   0.968664 |   0.304845   |  0.0743216 |     0.0226565   |                   10 |\n",
      "| train_with_tuning_7fcaa_00073 | TERMINATED | 169.237.32.34:2187170 | 1.71449e-05 |   0.827168 |   1.20425    |  0.885128  |     1.06592     |                    5 |\n",
      "| train_with_tuning_7fcaa_00074 | TERMINATED | 169.237.32.34:2187899 | 0.00017236  |   0.819213 |   1.071      |  0.836264  |     0.895638    |                    5 |\n",
      "| train_with_tuning_7fcaa_00075 | TERMINATED | 169.237.32.34:2190261 | 0.000252312 |   0.813825 |   1.03762    |  0.799826  |     0.829919    |                    5 |\n",
      "| train_with_tuning_7fcaa_00076 | TERMINATED | 169.237.32.34:2190744 | 0.000258514 |   0.815456 |   1.03313    |  0.79274   |     0.819004    |                    5 |\n",
      "| train_with_tuning_7fcaa_00077 | TERMINATED | 169.237.32.34:2193089 | 0.000940328 |   0.871111 |   0.0413374  |  0.0481315 |     0.00198963  |                   40 |\n",
      "| train_with_tuning_7fcaa_00078 | TERMINATED | 169.237.32.34:2193557 | 0.000422279 |   0.979977 |   0.00703989 |  0.0178725 |     0.000125821 |                   60 |\n",
      "| train_with_tuning_7fcaa_00079 | TERMINATED | 169.237.32.34:2214427 | 0.000321186 |   0.871489 |   0.270004   |  0.0735199 |     0.0198507   |                   10 |\n",
      "+-------------------------------+------------+-----------------------+-------------+------------+--------------+------------+-----------------+----------------------+\n",
      "\n",
      "\n",
      "Best trial config: {'lr': 0.0007945549435775312, 'momentum': 0.9806153579181356}\n",
      "Best trial final validation loss: 0.014164865682167667\n",
      "Best trial final train loss: 0.0019210122112298803\n"
     ]
    }
   ],
   "source": [
    "# Hyper Parameter Search \n",
    "iteration_config = {\n",
    "    \"lr\" : tune.loguniform(1e-5, 1e-3),\n",
    "    # \"batch_size\": tune.choice([128, 256]),\n",
    "    \"momentum\": tune.uniform(0.8, 0.99),\n",
    "}\n",
    "scheduler = ASHAScheduler(metric=\"combined_loss\", mode=\"min\", max_t=60, grace_period=5, reduction_factor=2)\n",
    "reporter = CLIReporter(metric_columns=[\"train_loss\", \"val_loss\", \"combined_loss\", \"training_iteration\"])\n",
    "result = tune.run(train_with_tuning, config=iteration_config, scheduler=scheduler, progress_reporter=reporter,\n",
    "                  num_samples=80, resources_per_trial={\"cpu\": 0, \"gpu\": 0.5},)\n",
    "\n",
    "best_trial = result.get_best_trial(\"val_loss\", \"min\", \"last\")\n",
    "# best_trial = result.get_best_trial(\"combined_loss\", \"min\", \"last\")\n",
    "print(\"Best trial config: {}\".format(best_trial.config))\n",
    "print(\"Best trial final validation loss: {}\".format(best_trial.last_result[\"val_loss\"]))\n",
    "print(\"Best trial final train loss: {}\".format(best_trial.last_result[\"train_loss\"]))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Best trial config: {'lr': 0.0010630834634709364, 'b1': 0.4282116859842134, 'b2': 0.3089991262211405, 'batch_size': 8, 'model': [20, 16, 8, 4, 2, 1]}\n",
    "Best trial final validation loss: 0.09234625198878348\n",
    "Best trial final train loss: 0.22368373312056064 -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_trial.config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "trainer = trainer_factory.create()\n",
    "# trainer.change_batch_size(16)\n",
    "# trainer.set_optimizer(SGD, {'lr': best_trial.config['lr'], 'momentum': best_trial.config['lr'][\"momentum\"]})\n",
    "trainer.set_optimizer(SGD, {'lr': 4e-3, 'momentum': 0.90})\n",
    "trainer.epochs = 100\n",
    "trainer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.epochs = 50\n",
    "# trainer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f693150f8b0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(trainer.train_loss, label='Training Loss', marker='x')\n",
    "plt.plot(trainer.validation_loss, label='Validation Loss', marker='x')\n",
    "# plt.yscale('log')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Model Properties:\n",
      "        PerceptronBD(\n",
      "  (model): Sequential(\n",
      "    (0): Linear(in_features=5, out_features=4, bias=True)\n",
      "    (1): BatchNorm1d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): Dropout1d(p=0.01, inplace=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=4, out_features=8, bias=True)\n",
      "    (5): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): Dropout1d(p=0.01, inplace=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=8, out_features=16, bias=True)\n",
      "    (9): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): Dropout1d(p=0.01, inplace=False)\n",
      "    (11): ReLU()\n",
      "    (12): Linear(in_features=16, out_features=40, bias=True)\n",
      "    (13): Flatten(start_dim=1, end_dim=-1)\n",
      "  )\n",
      ")\n",
      "        Optimizer Properties\"\n",
      "        SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    differentiable: False\n",
      "    foreach: None\n",
      "    lr: 0.004\n",
      "    maximize: False\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "        DataLoader Params: \n",
      "            Batch Size: 64\n",
      "            Validation Method: Holds out fMaternal Wall Thickness columns 0.8783100656536799 for validation. The rest are used             for training\n",
      "        Loss:\n",
      "            Train Loss: 0.007403857354074716\n",
      "            Val. Loss: 0.020472510394697288\n"
     ]
    }
   ],
   "source": [
    "print(trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get predictions\n",
    "with torch.no_grad():\n",
    "    x_data = torch.tensor(data[x_columns].values, dtype=torch.float).cuda()\n",
    "    predictions = trainer.model(x_data)\n",
    "    # predictions = fwd_model(x_data)\n",
    "    predictions = predictions.cpu().numpy()\n",
    "    predictions = y_scaler.inverse_transform(predictions).flatten()\n",
    "    y_data = data[y_columns].to_numpy()\n",
    "    y_data = y_scaler.inverse_transform(y_data).flatten()\n",
    "    absolute_error = np.abs(y_data - predictions)\n",
    "    # error_df = pd.DataFrame({'Truth': y_data, \"Predicted\": predictions, \"Absolute Error\": absolute_error, \"%tage\": absolute_error/y_data * 100})\n",
    "    error_df = pd.DataFrame({'Truth': y_data, \"Predicted\": predictions, \"Absolute Error\": absolute_error, \"%tage\": absolute_error})\n",
    "plt.figure()\n",
    "# error_df['%tage'].plot.hist(bins=100)\n",
    "error_df['Absolute Error'].plot.hist(bins=100)\n",
    "# plt.xlabel('(%) Error')\n",
    "plt.xlabel('Mean LogI Error')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error(non-normalized): [8.39314260e-05 1.88993238e-03 1.00660011e-02 2.42890153e-02\n",
      " 4.24435009e-02 5.61370689e-02 6.13275892e-02 6.17266001e-02\n",
      " 6.09416392e-02 6.20454818e-02 6.41816928e-02 6.39128195e-02\n",
      " 6.84131161e-02 6.71821743e-02 6.53808131e-02 6.54548384e-02\n",
      " 7.60660773e-02 7.75352391e-02 7.57835951e-02 7.31218923e-02\n",
      " 2.67175348e-05 4.74914067e-04 9.77547677e-03 3.45419008e-02\n",
      " 8.80766446e-02 1.37580221e-01 1.66376831e-01 1.53818139e-01\n",
      " 1.82089026e-01 1.83838288e-01 1.74357632e-01 1.78124999e-01\n",
      " 1.78893924e-01 1.87990596e-01 2.04475955e-01 1.69213397e-01\n",
      " 2.03202455e-01 2.09381026e-01 1.94896616e-01 2.54906294e-01]\n",
      "Validation Error(non-normalized): [2.32079970e-04 5.22587868e-03 2.78336415e-02 6.71618987e-02\n",
      " 1.17361123e-01 1.55225401e-01 1.69577782e-01 1.70681093e-01\n",
      " 1.68510586e-01 1.71562837e-01 1.77469704e-01 1.76726239e-01\n",
      " 1.89170072e-01 1.85766378e-01 1.80785409e-01 1.80990097e-01\n",
      " 2.10331383e-01 2.14393783e-01 2.09550288e-01 2.02190376e-01\n",
      " 7.38770322e-05 1.31319159e-03 2.70303087e-02 9.55122971e-02\n",
      " 2.43541972e-01 3.80425009e-01 4.60050922e-01 4.25324707e-01\n",
      " 5.03496933e-01 5.08333844e-01 4.82118747e-01 4.92535947e-01\n",
      " 4.94662113e-01 5.19815449e-01 5.65399348e-01 4.67894352e-01\n",
      " 5.61877974e-01 5.78962427e-01 5.38911382e-01 7.04844989e-01]\n"
     ]
    }
   ],
   "source": [
    "# Rough MSE's in percentage\n",
    "print(f'Train Error(non-normalized): {trainer.train_loss[-1] * y_scaler.var_ }')\n",
    "print(f'Validation Error(non-normalized): {trainer.validation_loss[-1] * y_scaler.var_ }')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "PerceptronBD                             --\n",
       "â”œâ”€Sequential: 1-1                        --\n",
       "â”‚    â””â”€Linear: 2-1                       48\n",
       "â”‚    â””â”€BatchNorm1d: 2-2                  16\n",
       "â”‚    â””â”€Dropout1d: 2-3                    --\n",
       "â”‚    â””â”€ReLU: 2-4                         --\n",
       "â”‚    â””â”€Linear: 2-5                       108\n",
       "â”‚    â””â”€BatchNorm1d: 2-6                  24\n",
       "â”‚    â””â”€Dropout1d: 2-7                    --\n",
       "â”‚    â””â”€ReLU: 2-8                         --\n",
       "â”‚    â””â”€Linear: 2-9                       208\n",
       "â”‚    â””â”€BatchNorm1d: 2-10                 32\n",
       "â”‚    â””â”€Dropout1d: 2-11                   --\n",
       "â”‚    â””â”€ReLU: 2-12                        --\n",
       "â”‚    â””â”€Linear: 2-13                      680\n",
       "â”‚    â””â”€Flatten: 2-14                     --\n",
       "=================================================================\n",
       "Total params: 1,116\n",
       "Trainable params: 1,116\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model Info\n",
    "torchinfo.summary(trainer.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/forward_curve_fit_paramv2_yscaler']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = 'forward_curve_fit_paramv2'\n",
    "import joblib\n",
    "# Save Model\n",
    "torch.save(trainer.model.state_dict(), rf'../models/{model_name}')\n",
    "# Save the Scalers for Later Use\n",
    "joblib.dump(x_scaler, rf'../models/{model_name}_xscaler')\n",
    "joblib.dump(y_scaler, rf'../models/{model_name}_yscaler')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load Model Code\n",
    "# import joblib\n",
    "# model_name = 'forward_curve_fit_paramv1'\n",
    "# fwd_model = PerceptronBD([5, 6, 8, 8], dropout_rates = [0.2, 0.2])\n",
    "# fwd_model.load_state_dict(torch.load(rf'../models/{model_name}'))\n",
    "# fwd_model = fwd_model.cuda()\n",
    "# fwd_model = fwd_model.eval()\n",
    "# # The input TMPs will already be scaled. No need to further use an x_scaler\n",
    "# y_scaler_fwd = joblib.load(rf'../models/{model_name}_yscaler')\n",
    "# x_scaler_fwd = joblib.load(rf'../models/{model_name}_xscaler')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cybercat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
