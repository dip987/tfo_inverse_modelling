{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting Saturation-based Simulation Data\n",
    "In this notebook, we try to fit intensity data generated using a saturation based method. The mu_a for each of the maternal and fetal layer are based on a set oxygen saturation and HB concentration. The impact of all other pigments on mu_a are ignored. The goal for this experiment is to see if we can train a model to determine these hidden variables - the Hb conc. and the saturation just by looking at the intensity values!\n",
    "\n",
    "# Instructions\n",
    "I have the parameter search in one of the cells. Run eveerything above it to be able to run that cell.\n",
    "If you don't want to search, ignore that cell and run everything above and below. \n",
    "\n",
    "# Issues\n",
    "1. Only the mu_a's are changed, not any of the other properties! \n",
    "2. Fetal performance is not nearly as good as maternal. This could be due to the noise in the far ends of the plots. Maybe interpolation would help?\n",
    "3. Fetal errors: Sat: ~3% Sat., Conc: ~1.9\n",
    "\n",
    "\n",
    "# Notes\n",
    "1. Using interpolated values seems to make the fitting more stable. Not better however.\n",
    "2. Maternal is very good.\n",
    "3. Fetal just estimates a mean!\n",
    "\n",
    "# Things to Try\n",
    "1. Fetal | Maternal = known"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam, SGD\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn import preprocessing\n",
    "from inverse_modelling_tfo.data import generate_data_loaders, equidistance_detector_normalization, constant_detector_count_normalization\n",
    "from inverse_modelling_tfo.data.intensity_interpolation import get_interpolate_fit_params_custom, interpolate_exp\n",
    "from inverse_modelling_tfo.data.interpolation_function_zoo import *\n",
    "from inverse_modelling_tfo.models import RandomSplit, ValidationMethod, HoldOneOut, CVSplit\n",
    "from inverse_modelling_tfo.models.custom_models import SplitChannelCNN, PerceptronReLU, PerceptronBN, PerceptronDO, PerceptronBD\n",
    "from inverse_modelling_tfo.features.build_features import create_ratio, create_spatial_intensity, create_ratio_and_intensity, create_row_combos\n",
    "from ray import tune\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "import torchinfo\n",
    "from inverse_modelling_tfo.misc.misc_training import set_seed\n",
    "# Set my GPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_pickle(r'/home/rraiyan/personal_projects/tfo_inverse_modelling/data/intensity/s_based_intensity.pkl')\n",
    "# data = pd.read_pickle(r'/home/rraiyan/personal_projects/tfo_inverse_modelling/data/intensity/s_based_intensity_low_conc.pkl')\n",
    "# data = pd.read_pickle(r'/home/rraiyan/personal_projects/tfo_inverse_modelling/data/intensity/s_based_intensity_low_conc2.pkl')\n",
    "RAW_DATA_PATH_NEW = r'/home/rraiyan/personal_projects/tfo_inverse_modelling/inverse_modelling_tfo/s_based_intensity_low_conc3.pkl'\n",
    "RAW_DATA_PATH_OLD = r'/home/rraiyan/personal_projects/tfo_inverse_modelling/data/intensity/s_based_intensity_low_conc2.pkl'\n",
    "\n",
    "data = pd.concat([pd.read_pickle(RAW_DATA_PATH_OLD), pd.read_pickle(RAW_DATA_PATH_NEW)], axis=0, ignore_index=True)\n",
    "# Drop Thickness values which I did not calculate the close concnetration points\n",
    "equidistance_detector_normalization(data)\n",
    "\n",
    "# Drop Uterus Thickness for now\n",
    "data = data.drop(columns='Uterus Thickness')\n",
    "\n",
    "# Interpolate intensity to remove noise\n",
    "data = interpolate_exp(data, weights=(1, 0.7))\n",
    "data['Intensity'] = data['Interpolated Intensity']\n",
    "data = data.drop(columns='Interpolated Intensity')\n",
    "\n",
    "# Manual log(intensity) normalization\n",
    "data['Intensity'] = np.log10(data['Intensity'])        # Far values wayy to small to affect anything. Take log\n",
    "\n",
    "\n",
    "# data = create_ratio_and_intensity(data, True)\n",
    "# data, x_columns, labels = create_ratio(data, True)\n",
    "data, x_columns, labels = create_spatial_intensity(data)\n",
    "\n",
    "# data.head()\n",
    "# NOTE: Have only 1 on at the same time!\n",
    "\n",
    "# Cleanup\n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Combination Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Maternal Wall Thickness', 'Maternal Hb Concentration', 'Maternal Saturation', 'Fetal Saturation', 'FconcCenters', 'Fetal Hb Concentration 0', 'Fetal Hb Concentration 1']\n"
     ]
    }
   ],
   "source": [
    "# Add new columns to group close concentrations\n",
    "# data['MconcCenters'] = np.round(data['Maternal Hb Concentration']).astype(int)\n",
    "data['FconcCenters'] = np.round(data['Fetal Hb Concentration'] * 20, 0)\n",
    "fixed_columns = ['Maternal Wall Thickness', \"Maternal Hb Concentration\", \"Maternal Saturation\", \"Fetal Saturation\", \"FconcCenters\"]\n",
    "data, x_columns, labels = create_row_combos(data, x_columns, fixed_columns, [\"Fetal Hb Concentration\"], combo_count=2)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column Cleanup\n",
    "# data.drop(columns=['FconcCenters', 'Fetal Hb Concentration 0', 'Fetal Hb Concentration 1', 'Fetal Hb Concentration 2'] , inplace=True)\n",
    "# data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create RoR\n",
    "# # With combo_count = 2, we have 80 features named x_0 upto x_79. The first 40 belong to one conc and the next 40 belong to the other\n",
    "# # For each pair of columns (One from the first group, the corresponding one from the second group), subtract the smaller \n",
    "# # from the bigger and divide by the smaller\n",
    "# SINGLE_ROW_FEATURE_COUNT = 40\n",
    "# DETECTOR_COUNT = 20\n",
    "\n",
    "# for i in range(SINGLE_ROW_FEATURE_COUNT):\n",
    "#     feature_name1 = 'x_' + str(i)\n",
    "#     feature_name2 = 'x_' + str(i + SINGLE_ROW_FEATURE_COUNT)\n",
    "#     new_feature_name = 'AC_' + str(i)\n",
    "    \n",
    "#     # Remember the features should be in log10 form -> Convert back\n",
    "#     feature1 = np.power(data[feature_name1], 10)\n",
    "#     feature2 = np.power(data[feature_name2], 10)\n",
    "\n",
    "#     # The formula for AC changes depending on which one is larger\n",
    "#     column_feature1_is_greater =  (feature1 - feature2) / feature2\n",
    "#     column_feature2_is_greater =  (feature2 - feature1) / feature1\n",
    "#     data[new_feature_name] = column_feature1_is_greater * (feature1 > feature2) + \\\n",
    "#         column_feature2_is_greater * (feature2 >= feature2)\n",
    "\n",
    "# # Cleanup intensity features    \n",
    "# data.drop(columns=x_columns, inplace=True)\n",
    "\n",
    "# for i in range(DETECTOR_COUNT):\n",
    "#     ac1 = 'AC_' + str(i)\n",
    "#     ac2 = 'AC_' + str(i + DETECTOR_COUNT)\n",
    "#     ror_feature_name = 'RoR_' + str(i)\n",
    "#     data[ror_feature_name] = data[ac1] / data[ac2]\n",
    "\n",
    "# # Cleanup - Remove the old feature columns & Set the RoR's as the new feature columns\n",
    "# x_columns = ['RoR_' + str(i) for i in range(DETECTOR_COUNT)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Data will have a bunch of infinity/NaN values. Drop them\n",
    "# data.replace(np.inf, np.nan, inplace=True)\n",
    "# data.dropna(inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing Features\n",
    "x_columns will be the input features and y_columns are the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Y -> Target\n",
    "# y_columns = ['Maternal Wall Thickness', \"Maternal Hb Concentration\", \"Maternal Saturation\", \"Fetal Hb Concentration\", \"Fetal Saturation\"]\n",
    "# y_columns = ['Maternal Wall Thickness']\n",
    "# y_columns = ['Fetal Saturation']\n",
    "# y_columns = ['Maternal Saturation']\n",
    "# y_columns = ['Maternal Hb Concentration']\n",
    "y_columns = ['Fetal Saturation']\n",
    "# y_columns = ['Fetal Hb Concentration']\n",
    "\n",
    "## Pass in maternal info\n",
    "# x_columns += [\"Maternal Hb Concentration\", \"Maternal Saturation\"]\n",
    "\n",
    "## Scale y\n",
    "y_scaler = preprocessing.StandardScaler()\n",
    "data[y_columns] = y_scaler.fit_transform(data[y_columns])\n",
    "\n",
    "## Scale x\n",
    "x_scaler = preprocessing.StandardScaler()\n",
    "data[x_columns] = x_scaler.fit_transform(data[x_columns])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "IN_FEATURES = len(x_columns)\n",
    "OUT_FEATURES = len(y_columns)\n",
    "\n",
    "from inverse_modelling_tfo.models.train_model import ModelTrainerFactory\n",
    "datagen_kw = {\n",
    "    'table' : data,\n",
    "    'data_loader_params' : \n",
    "        {\n",
    "            'batch_size': 64, 'shuffle': True, 'num_workers': 2\n",
    "        }, \n",
    "    'x_columns': x_columns,\n",
    "    'y_columns': y_columns,\n",
    "    'validation_method' : HoldOneOut('Maternal Wall Thickness', data['Maternal Wall Thickness'].unique()[3])\n",
    "    # 'validation_method' : HoldOneOut('Maternal Hb Concentration', 13.0)\n",
    "    # 'validation_method' : HoldOneOut('Maternal Saturation', 1.0)\n",
    "}\n",
    "trainer_factory = ModelTrainerFactory(PerceptronBD, {'node_counts' : [IN_FEATURES, 20, 10, 5, OUT_FEATURES], 'dropout_rates': [0.5, 0.5, 0.5]}, generate_data_loaders, datagen_kw, 100, nn.MSELoss())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Train Function \n",
    "def train_with_tuning(iteration_config):\n",
    "    set_seed(42)\n",
    "    trainer_tuning = trainer_factory.create()\n",
    "    trainer_tuning.reporting = True     # Report at each epoch to Ray Tune\n",
    "    if 'batch_size' in iteration_config:\n",
    "        trainer_tuning.change_batch_size(iteration_config['batch_size'])    # If batch_size needs tuning\n",
    "    trainer_tuning.set_optimizer(SGD, {'lr': iteration_config[\"lr\"], 'momentum': iteration_config[\"momentum\"]})\n",
    "    trainer_tuning.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-02 15:13:14,056\tINFO tune.py:645 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-02 15:13:31,628\tWARNING worker.py:2058 -- Warning: The actor ImplicitFunc is very large (59 MiB). Check that its definition is not implicitly capturing a large array or other object in scope. Tip: use ray.put() to put large objects in the Ray object store.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-11-02 15:13:31 (running for 00:00:17.78)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: None | Iter 5.000: None\n",
      "Logical resource usage: 0/64 CPUs, 1.0000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 70/80 (70 PENDING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th style=\"text-align: right;\">  combined_loss</th><th style=\"text-align: right;\">  train_loss</th><th style=\"text-align: right;\">  val_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_with_tuning_043b2_00000</td><td style=\"text-align: right;\">   nan         </td><td style=\"text-align: right;\">nan         </td><td style=\"text-align: right;\">nan       </td></tr>\n",
       "<tr><td>train_with_tuning_043b2_00001</td><td style=\"text-align: right;\">     0.508398  </td><td style=\"text-align: right;\">  0.575367  </td><td style=\"text-align: right;\">  0.883606</td></tr>\n",
       "<tr><td>train_with_tuning_043b2_00002</td><td style=\"text-align: right;\">     0.00327905</td><td style=\"text-align: right;\">  0.00658183</td><td style=\"text-align: right;\">  0.498197</td></tr>\n",
       "<tr><td>train_with_tuning_043b2_00003</td><td style=\"text-align: right;\">     0.00823242</td><td style=\"text-align: right;\">  0.00725607</td><td style=\"text-align: right;\">  1.13456 </td></tr>\n",
       "<tr><td>train_with_tuning_043b2_00004</td><td style=\"text-align: right;\">     0.00886003</td><td style=\"text-align: right;\">  0.00757098</td><td style=\"text-align: right;\">  1.17026 </td></tr>\n",
       "<tr><td>train_with_tuning_043b2_00005</td><td style=\"text-align: right;\">     0.00705593</td><td style=\"text-align: right;\">  0.00517695</td><td style=\"text-align: right;\">  1.36295 </td></tr>\n",
       "<tr><td>train_with_tuning_043b2_00006</td><td style=\"text-align: right;\">     0.0983673 </td><td style=\"text-align: right;\">  0.0650029 </td><td style=\"text-align: right;\">  1.51328 </td></tr>\n",
       "<tr><td>train_with_tuning_043b2_00007</td><td style=\"text-align: right;\">     0.00743277</td><td style=\"text-align: right;\">  0.00716983</td><td style=\"text-align: right;\">  1.03667 </td></tr>\n",
       "<tr><td>train_with_tuning_043b2_00008</td><td style=\"text-align: right;\">   nan         </td><td style=\"text-align: right;\">nan         </td><td style=\"text-align: right;\">nan       </td></tr>\n",
       "<tr><td>train_with_tuning_043b2_00009</td><td style=\"text-align: right;\">     0.00550853</td><td style=\"text-align: right;\">  0.0099373 </td><td style=\"text-align: right;\">  0.554329</td></tr>\n",
       "<tr><td>train_with_tuning_043b2_00010</td><td style=\"text-align: right;\">   nan         </td><td style=\"text-align: right;\">nan         </td><td style=\"text-align: right;\">nan       </td></tr>\n",
       "<tr><td>train_with_tuning_043b2_00011</td><td style=\"text-align: right;\">     3.96769   </td><td style=\"text-align: right;\">  0.0316799 </td><td style=\"text-align: right;\">125.243   </td></tr>\n",
       "<tr><td>train_with_tuning_043b2_00012</td><td style=\"text-align: right;\">     0.00952741</td><td style=\"text-align: right;\">  0.00646997</td><td style=\"text-align: right;\">  1.47256 </td></tr>\n",
       "<tr><td>train_with_tuning_043b2_00013</td><td style=\"text-align: right;\">     0.0202781 </td><td style=\"text-align: right;\">  0.00651261</td><td style=\"text-align: right;\">  3.11367 </td></tr>\n",
       "<tr><td>train_with_tuning_043b2_00014</td><td style=\"text-align: right;\">     0.470858  </td><td style=\"text-align: right;\">  0.53078   </td><td style=\"text-align: right;\">  0.887106</td></tr>\n",
       "<tr><td>train_with_tuning_043b2_00015</td><td style=\"text-align: right;\">     0.0918399 </td><td style=\"text-align: right;\">  0.0728794 </td><td style=\"text-align: right;\">  1.26016 </td></tr>\n",
       "<tr><td>train_with_tuning_043b2_00016</td><td style=\"text-align: right;\">     0.391567  </td><td style=\"text-align: right;\">  0.407045  </td><td style=\"text-align: right;\">  0.961975</td></tr>\n",
       "<tr><td>train_with_tuning_043b2_00017</td><td style=\"text-align: right;\">     0.528207  </td><td style=\"text-align: right;\">  0.597103  </td><td style=\"text-align: right;\">  0.884617</td></tr>\n",
       "<tr><td>train_with_tuning_043b2_00018</td><td style=\"text-align: right;\">     0.675304  </td><td style=\"text-align: right;\">  0.740191  </td><td style=\"text-align: right;\">  0.912339</td></tr>\n",
       "<tr><td>train_with_tuning_043b2_00019</td><td style=\"text-align: right;\">     0.454866  </td><td style=\"text-align: right;\">  0.508756  </td><td style=\"text-align: right;\">  0.894076</td></tr>\n",
       "<tr><td>train_with_tuning_043b2_00020</td><td style=\"text-align: right;\">     0.759314  </td><td style=\"text-align: right;\">  0.818408  </td><td style=\"text-align: right;\">  0.927794</td></tr>\n",
       "<tr><td>train_with_tuning_043b2_00021</td><td style=\"text-align: right;\">     0.00469804</td><td style=\"text-align: right;\">  0.00837475</td><td style=\"text-align: right;\">  0.560977</td></tr>\n",
       "<tr><td>train_with_tuning_043b2_00022</td><td style=\"text-align: right;\">     0.0970432 </td><td style=\"text-align: right;\">  0.0643891 </td><td style=\"text-align: right;\">  1.50714 </td></tr>\n",
       "<tr><td>train_with_tuning_043b2_00023</td><td style=\"text-align: right;\">     0.487098  </td><td style=\"text-align: right;\">  0.549275  </td><td style=\"text-align: right;\">  0.886803</td></tr>\n",
       "<tr><td>train_with_tuning_043b2_00024</td><td style=\"text-align: right;\">     0.333953  </td><td style=\"text-align: right;\">  0.302413  </td><td style=\"text-align: right;\">  1.10429 </td></tr>\n",
       "<tr><td>train_with_tuning_043b2_00025</td><td style=\"text-align: right;\">     0.00431452</td><td style=\"text-align: right;\">  0.00952175</td><td style=\"text-align: right;\">  0.453123</td></tr>\n",
       "<tr><td>train_with_tuning_043b2_00026</td><td style=\"text-align: right;\">     0.748536  </td><td style=\"text-align: right;\">  0.808103  </td><td style=\"text-align: right;\">  0.926287</td></tr>\n",
       "<tr><td>train_with_tuning_043b2_00027</td><td style=\"text-align: right;\">     0.00400444</td><td style=\"text-align: right;\">  0.00734701</td><td style=\"text-align: right;\">  0.545044</td></tr>\n",
       "<tr><td>train_with_tuning_043b2_00028</td><td style=\"text-align: right;\">   nan         </td><td style=\"text-align: right;\">nan         </td><td style=\"text-align: right;\">nan       </td></tr>\n",
       "<tr><td>train_with_tuning_043b2_00029</td><td style=\"text-align: right;\">     0.0559072 </td><td style=\"text-align: right;\">  0.0377007 </td><td style=\"text-align: right;\">  1.48292 </td></tr>\n",
       "<tr><td>train_with_tuning_043b2_00030</td><td style=\"text-align: right;\">     0.0822334 </td><td style=\"text-align: right;\">  0.0535067 </td><td style=\"text-align: right;\">  1.53688 </td></tr>\n",
       "<tr><td>train_with_tuning_043b2_00031</td><td style=\"text-align: right;\">     0.815118  </td><td style=\"text-align: right;\">  0.872489  </td><td style=\"text-align: right;\">  0.934244</td></tr>\n",
       "<tr><td>train_with_tuning_043b2_00032</td><td style=\"text-align: right;\">   nan         </td><td style=\"text-align: right;\">nan         </td><td style=\"text-align: right;\">nan       </td></tr>\n",
       "<tr><td>train_with_tuning_043b2_00033</td><td style=\"text-align: right;\">     0.729147  </td><td style=\"text-align: right;\">  0.789764  </td><td style=\"text-align: right;\">  0.923247</td></tr>\n",
       "<tr><td>train_with_tuning_043b2_00034</td><td style=\"text-align: right;\">     0.655781  </td><td style=\"text-align: right;\">  0.722377  </td><td style=\"text-align: right;\">  0.907811</td></tr>\n",
       "<tr><td>train_with_tuning_043b2_00035</td><td style=\"text-align: right;\">     0.00410135</td><td style=\"text-align: right;\">  0.00922677</td><td style=\"text-align: right;\">  0.444506</td></tr>\n",
       "<tr><td>train_with_tuning_043b2_00036</td><td style=\"text-align: right;\">     0.304028  </td><td style=\"text-align: right;\">  0.252431  </td><td style=\"text-align: right;\">  1.2044  </td></tr>\n",
       "<tr><td>train_with_tuning_043b2_00037</td><td style=\"text-align: right;\">     1.00041   </td><td style=\"text-align: right;\">  1.00001   </td><td style=\"text-align: right;\">  1.00039 </td></tr>\n",
       "<tr><td>train_with_tuning_043b2_00038</td><td style=\"text-align: right;\">     0.6775    </td><td style=\"text-align: right;\">  0.742129  </td><td style=\"text-align: right;\">  0.912914</td></tr>\n",
       "<tr><td>train_with_tuning_043b2_00039</td><td style=\"text-align: right;\">     0.0482526 </td><td style=\"text-align: right;\">  0.0185365 </td><td style=\"text-align: right;\">  2.60311 </td></tr>\n",
       "<tr><td>train_with_tuning_043b2_00040</td><td style=\"text-align: right;\">     0.0972548 </td><td style=\"text-align: right;\">  0.0652301 </td><td style=\"text-align: right;\">  1.49095 </td></tr>\n",
       "<tr><td>train_with_tuning_043b2_00041</td><td style=\"text-align: right;\">     0.00362438</td><td style=\"text-align: right;\">  0.00556015</td><td style=\"text-align: right;\">  0.65185 </td></tr>\n",
       "<tr><td>train_with_tuning_043b2_00042</td><td style=\"text-align: right;\">   nan         </td><td style=\"text-align: right;\">nan         </td><td style=\"text-align: right;\">nan       </td></tr>\n",
       "<tr><td>train_with_tuning_043b2_00043</td><td style=\"text-align: right;\">     0.833898  </td><td style=\"text-align: right;\">  0.89099   </td><td style=\"text-align: right;\">  0.935923</td></tr>\n",
       "<tr><td>train_with_tuning_043b2_00044</td><td style=\"text-align: right;\">     0.602427  </td><td style=\"text-align: right;\">  0.673352  </td><td style=\"text-align: right;\">  0.894669</td></tr>\n",
       "<tr><td>train_with_tuning_043b2_00045</td><td style=\"text-align: right;\">     0.0720194 </td><td style=\"text-align: right;\">  0.0472371 </td><td style=\"text-align: right;\">  1.52464 </td></tr>\n",
       "<tr><td>train_with_tuning_043b2_00046</td><td style=\"text-align: right;\">     0.00457516</td><td style=\"text-align: right;\">  0.00865898</td><td style=\"text-align: right;\">  0.528371</td></tr>\n",
       "<tr><td>train_with_tuning_043b2_00047</td><td style=\"text-align: right;\">     0.00480698</td><td style=\"text-align: right;\">  0.00800896</td><td style=\"text-align: right;\">  0.600201</td></tr>\n",
       "<tr><td>train_with_tuning_043b2_00048</td><td style=\"text-align: right;\">     0.0625608 </td><td style=\"text-align: right;\">  0.0246502 </td><td style=\"text-align: right;\">  2.53795 </td></tr>\n",
       "<tr><td>train_with_tuning_043b2_00049</td><td style=\"text-align: right;\">     0.411172  </td><td style=\"text-align: right;\">  0.441436  </td><td style=\"text-align: right;\">  0.931443</td></tr>\n",
       "<tr><td>train_with_tuning_043b2_00050</td><td style=\"text-align: right;\">   nan         </td><td style=\"text-align: right;\">nan         </td><td style=\"text-align: right;\">nan       </td></tr>\n",
       "<tr><td>train_with_tuning_043b2_00051</td><td style=\"text-align: right;\">     0.00753268</td><td style=\"text-align: right;\">  0.0115627 </td><td style=\"text-align: right;\">  0.651465</td></tr>\n",
       "<tr><td>train_with_tuning_043b2_00052</td><td style=\"text-align: right;\">     0.0184862 </td><td style=\"text-align: right;\">  0.0141508 </td><td style=\"text-align: right;\">  1.30637 </td></tr>\n",
       "<tr><td>train_with_tuning_043b2_00053</td><td style=\"text-align: right;\">     0.044697  </td><td style=\"text-align: right;\">  0.0325554 </td><td style=\"text-align: right;\">  1.37295 </td></tr>\n",
       "<tr><td>train_with_tuning_043b2_00054</td><td style=\"text-align: right;\">     0.0044179 </td><td style=\"text-align: right;\">  0.00960444</td><td style=\"text-align: right;\">  0.459985</td></tr>\n",
       "<tr><td>train_with_tuning_043b2_00055</td><td style=\"text-align: right;\">     0.0660306 </td><td style=\"text-align: right;\">  0.030746  </td><td style=\"text-align: right;\">  2.14761 </td></tr>\n",
       "<tr><td>train_with_tuning_043b2_00056</td><td style=\"text-align: right;\">     0.00442465</td><td style=\"text-align: right;\">  0.00742381</td><td style=\"text-align: right;\">  0.596008</td></tr>\n",
       "<tr><td>train_with_tuning_043b2_00057</td><td style=\"text-align: right;\">     0.0189764 </td><td style=\"text-align: right;\">  0.00829516</td><td style=\"text-align: right;\">  2.28764 </td></tr>\n",
       "<tr><td>train_with_tuning_043b2_00058</td><td style=\"text-align: right;\">     0.0493779 </td><td style=\"text-align: right;\">  0.0355553 </td><td style=\"text-align: right;\">  1.38877 </td></tr>\n",
       "<tr><td>train_with_tuning_043b2_00059</td><td style=\"text-align: right;\">     0.322051  </td><td style=\"text-align: right;\">  0.282199  </td><td style=\"text-align: right;\">  1.14122 </td></tr>\n",
       "<tr><td>train_with_tuning_043b2_00060</td><td style=\"text-align: right;\">     0.293041  </td><td style=\"text-align: right;\">  0.458702  </td><td style=\"text-align: right;\">  0.638848</td></tr>\n",
       "<tr><td>train_with_tuning_043b2_00061</td><td style=\"text-align: right;\">     0.355311  </td><td style=\"text-align: right;\">  0.333913  </td><td style=\"text-align: right;\">  1.06408 </td></tr>\n",
       "<tr><td>train_with_tuning_043b2_00062</td><td style=\"text-align: right;\">     0.00427995</td><td style=\"text-align: right;\">  0.00985507</td><td style=\"text-align: right;\">  0.434289</td></tr>\n",
       "<tr><td>train_with_tuning_043b2_00063</td><td style=\"text-align: right;\">     0.801489  </td><td style=\"text-align: right;\">  0.859012  </td><td style=\"text-align: right;\">  0.933036</td></tr>\n",
       "<tr><td>train_with_tuning_043b2_00064</td><td style=\"text-align: right;\">     0.210461  </td><td style=\"text-align: right;\">  0.153098  </td><td style=\"text-align: right;\">  1.37468 </td></tr>\n",
       "<tr><td>train_with_tuning_043b2_00065</td><td style=\"text-align: right;\">     0.059481  </td><td style=\"text-align: right;\">  0.0390472 </td><td style=\"text-align: right;\">  1.52331 </td></tr>\n",
       "<tr><td>train_with_tuning_043b2_00066</td><td style=\"text-align: right;\">     0.0578653 </td><td style=\"text-align: right;\">  0.0385234 </td><td style=\"text-align: right;\">  1.50208 </td></tr>\n",
       "<tr><td>train_with_tuning_043b2_00067</td><td style=\"text-align: right;\">   nan         </td><td style=\"text-align: right;\">nan         </td><td style=\"text-align: right;\">nan       </td></tr>\n",
       "<tr><td>train_with_tuning_043b2_00068</td><td style=\"text-align: right;\">     0.00993631</td><td style=\"text-align: right;\">  0.00621311</td><td style=\"text-align: right;\">  1.59925 </td></tr>\n",
       "<tr><td>train_with_tuning_043b2_00069</td><td style=\"text-align: right;\">     0.00406217</td><td style=\"text-align: right;\">  0.00905366</td><td style=\"text-align: right;\">  0.448677</td></tr>\n",
       "<tr><td>train_with_tuning_043b2_00070</td><td style=\"text-align: right;\">     0.00344945</td><td style=\"text-align: right;\">  0.00729384</td><td style=\"text-align: right;\">  0.472927</td></tr>\n",
       "<tr><td>train_with_tuning_043b2_00071</td><td style=\"text-align: right;\">     0.00397139</td><td style=\"text-align: right;\">  0.00714928</td><td style=\"text-align: right;\">  0.555496</td></tr>\n",
       "<tr><td>train_with_tuning_043b2_00072</td><td style=\"text-align: right;\">     0.807568  </td><td style=\"text-align: right;\">  0.865004  </td><td style=\"text-align: right;\">  0.9336  </td></tr>\n",
       "<tr><td>train_with_tuning_043b2_00073</td><td style=\"text-align: right;\">     0.804029  </td><td style=\"text-align: right;\">  0.861514  </td><td style=\"text-align: right;\">  0.933274</td></tr>\n",
       "<tr><td>train_with_tuning_043b2_00074</td><td style=\"text-align: right;\">     0.00432424</td><td style=\"text-align: right;\">  0.00739981</td><td style=\"text-align: right;\">  0.584372</td></tr>\n",
       "<tr><td>train_with_tuning_043b2_00075</td><td style=\"text-align: right;\">     0.411429  </td><td style=\"text-align: right;\">  0.442079  </td><td style=\"text-align: right;\">  0.930668</td></tr>\n",
       "<tr><td>train_with_tuning_043b2_00076</td><td style=\"text-align: right;\">     0.044733  </td><td style=\"text-align: right;\">  0.0374371 </td><td style=\"text-align: right;\">  1.19488 </td></tr>\n",
       "<tr><td>train_with_tuning_043b2_00077</td><td style=\"text-align: right;\">     0.132968  </td><td style=\"text-align: right;\">  0.0554306 </td><td style=\"text-align: right;\">  2.39882 </td></tr>\n",
       "<tr><td>train_with_tuning_043b2_00078</td><td style=\"text-align: right;\">     0.00313042</td><td style=\"text-align: right;\">  0.00405052</td><td style=\"text-align: right;\">  0.772844</td></tr>\n",
       "<tr><td>train_with_tuning_043b2_00079</td><td style=\"text-align: right;\">     0.00613354</td><td style=\"text-align: right;\">  0.00572267</td><td style=\"text-align: right;\">  1.0718  </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-11-02 15:13:36 (running for 00:00:22.84)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: None | Iter 5.000: None\n",
      "Logical resource usage: 0/64 CPUs, 1.0000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (60 PENDING, 20 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:13:41 (running for 00:00:27.84)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: None | Iter 5.000: None\n",
      "Logical resource usage: 0/64 CPUs, 1.0000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (60 PENDING, 20 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:13:47 (running for 00:00:32.91)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: None | Iter 5.000: None\n",
      "Logical resource usage: 0/64 CPUs, 1.0000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (60 PENDING, 20 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:13:52 (running for 00:00:37.92)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: None | Iter 5.000: None\n",
      "Logical resource usage: 0/64 CPUs, 1.0000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (60 PENDING, 20 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rraiyan/cybercat/lib/python3.8/site-packages/numpy/lib/nanfunctions.py:1556: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-11-02 15:13:57 (running for 00:00:42.98)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: None | Iter 5.000: -0.12526161692973498\n",
      "Logical resource usage: 0/64 CPUs, 1.0000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (60 PENDING, 20 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:14:02 (running for 00:00:48.02)\n",
      "Using AsyncHyperBand: num_stopped=7\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: None | Iter 5.000: -0.27210434987754545\n",
      "Logical resource usage: 0/64 CPUs, 0.8500000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (58 PENDING, 15 RUNNING, 7 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:14:07 (running for 00:00:53.06)\n",
      "Using AsyncHyperBand: num_stopped=7\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: None | Iter 5.000: -0.27210434987754545\n",
      "Logical resource usage: 0/64 CPUs, 1.0000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (53 PENDING, 20 RUNNING, 7 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:14:12 (running for 00:00:58.12)\n",
      "Using AsyncHyperBand: num_stopped=7\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: None | Iter 5.000: -0.27210434987754545\n",
      "Logical resource usage: 0/64 CPUs, 1.0000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (53 PENDING, 20 RUNNING, 7 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:14:17 (running for 00:01:03.16)\n",
      "Using AsyncHyperBand: num_stopped=7\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: -0.3045084489845847 | Iter 5.000: -0.27210434987754545\n",
      "Logical resource usage: 0/64 CPUs, 1.0000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (53 PENDING, 20 RUNNING, 7 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:14:22 (running for 00:01:08.20)\n",
      "Using AsyncHyperBand: num_stopped=8\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: -0.04233102938834756 | Iter 5.000: -0.27210434987754545\n",
      "Logical resource usage: 0/64 CPUs, 0.9500000000000003/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (53 PENDING, 19 RUNNING, 8 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:14:27 (running for 00:01:13.30)\n",
      "Using AsyncHyperBand: num_stopped=10\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: -0.04117912603838089 | Iter 5.000: -0.27210434987754545\n",
      "Logical resource usage: 0/64 CPUs, 1.0000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (51 PENDING, 19 RUNNING, 10 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:14:32 (running for 00:01:18.32)\n",
      "Using AsyncHyperBand: num_stopped=12\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: -0.04117912603838089 | Iter 5.000: -0.3030284254130995\n",
      "Logical resource usage: 0/64 CPUs, 1.0000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (49 PENDING, 19 RUNNING, 12 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:14:37 (running for 00:01:23.39)\n",
      "Using AsyncHyperBand: num_stopped=12\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: -0.04117912603838089 | Iter 5.000: -0.3030284254130995\n",
      "Logical resource usage: 0/64 CPUs, 1.0000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (48 PENDING, 20 RUNNING, 12 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:14:42 (running for 00:01:28.43)\n",
      "Using AsyncHyperBand: num_stopped=12\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: -0.04117912603838089 | Iter 5.000: -0.3030284254130995\n",
      "Logical resource usage: 0/64 CPUs, 1.0000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (48 PENDING, 20 RUNNING, 12 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:14:47 (running for 00:01:33.52)\n",
      "Using AsyncHyperBand: num_stopped=12\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: -0.040027222688414216 | Iter 5.000: -0.3030284254130995\n",
      "Logical resource usage: 0/64 CPUs, 1.0000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (48 PENDING, 20 RUNNING, 12 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:14:52 (running for 00:01:38.61)\n",
      "Using AsyncHyperBand: num_stopped=13\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: -0.040027222688414216 | Iter 5.000: -0.27015406452063684\n",
      "Logical resource usage: 0/64 CPUs, 1.0000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (47 PENDING, 20 RUNNING, 13 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:14:57 (running for 00:01:43.65)\n",
      "Using AsyncHyperBand: num_stopped=14\n",
      "Bracket: Iter 40.000: None | Iter 20.000: None | Iter 10.000: -0.040027222688414216 | Iter 5.000: -0.27015406452063684\n",
      "Logical resource usage: 0/64 CPUs, 1.0000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (47 PENDING, 19 RUNNING, 14 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:15:02 (running for 00:01:48.72)\n",
      "Using AsyncHyperBand: num_stopped=14\n",
      "Bracket: Iter 40.000: None | Iter 20.000: -0.037863005860201034 | Iter 10.000: -0.040027222688414216 | Iter 5.000: -0.27015406452063684\n",
      "Logical resource usage: 0/64 CPUs, 1.0000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (46 PENDING, 20 RUNNING, 14 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:15:07 (running for 00:01:53.75)\n",
      "Using AsyncHyperBand: num_stopped=14\n",
      "Bracket: Iter 40.000: None | Iter 20.000: -0.02022363255623572 | Iter 10.000: -0.040027222688414216 | Iter 5.000: -0.27015406452063684\n",
      "Logical resource usage: 0/64 CPUs, 1.0000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (46 PENDING, 20 RUNNING, 14 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:15:12 (running for 00:01:58.77)\n",
      "Using AsyncHyperBand: num_stopped=14\n",
      "Bracket: Iter 40.000: None | Iter 20.000: -0.02022363255623572 | Iter 10.000: -0.03941143399810712 | Iter 5.000: -0.27015406452063684\n",
      "Logical resource usage: 0/64 CPUs, 1.0000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (46 PENDING, 20 RUNNING, 14 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:15:17 (running for 00:02:03.81)\n",
      "Using AsyncHyperBand: num_stopped=16\n",
      "Bracket: Iter 40.000: None | Iter 20.000: -0.02022363255623572 | Iter 10.000: -0.04117912603838089 | Iter 5.000: -0.27015406452063684\n",
      "Logical resource usage: 0/64 CPUs, 1.0000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (46 PENDING, 18 RUNNING, 16 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:15:22 (running for 00:02:08.85)\n",
      "Using AsyncHyperBand: num_stopped=17\n",
      "Bracket: Iter 40.000: None | Iter 20.000: -0.02022363255623572 | Iter 10.000: -0.04117912603838089 | Iter 5.000: -0.27210434987754545\n",
      "Logical resource usage: 0/64 CPUs, 0.9500000000000003/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (44 PENDING, 19 RUNNING, 17 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:15:28 (running for 00:02:13.88)\n",
      "Using AsyncHyperBand: num_stopped=17\n",
      "Bracket: Iter 40.000: None | Iter 20.000: -0.02022363255623572 | Iter 10.000: -0.04117912603838089 | Iter 5.000: -0.27210434987754545\n",
      "Logical resource usage: 0/64 CPUs, 1.0000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (43 PENDING, 20 RUNNING, 17 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:15:33 (running for 00:02:18.89)\n",
      "Using AsyncHyperBand: num_stopped=17\n",
      "Bracket: Iter 40.000: None | Iter 20.000: -0.01998135711533404 | Iter 10.000: -0.04117912603838089 | Iter 5.000: -0.27210434987754545\n",
      "Logical resource usage: 0/64 CPUs, 1.0000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (43 PENDING, 20 RUNNING, 17 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:15:38 (running for 00:02:23.93)\n",
      "Using AsyncHyperBand: num_stopped=17\n",
      "Bracket: Iter 40.000: None | Iter 20.000: -0.01973908167443236 | Iter 10.000: -0.04117912603838089 | Iter 5.000: -0.27210434987754545\n",
      "Logical resource usage: 0/64 CPUs, 1.0000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (43 PENDING, 20 RUNNING, 17 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:15:43 (running for 00:02:29.02)\n",
      "Using AsyncHyperBand: num_stopped=18\n",
      "Bracket: Iter 40.000: None | Iter 20.000: -0.01973908167443236 | Iter 10.000: -0.04117912603838089 | Iter 5.000: -0.3030284254130995\n",
      "Logical resource usage: 0/64 CPUs, 1.0000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (43 PENDING, 19 RUNNING, 18 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:15:48 (running for 00:02:34.06)\n",
      "Using AsyncHyperBand: num_stopped=18\n",
      "Bracket: Iter 40.000: None | Iter 20.000: -0.01973908167443236 | Iter 10.000: -0.04117912603838089 | Iter 5.000: -0.27210434987754545\n",
      "Logical resource usage: 0/64 CPUs, 1.0000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (42 PENDING, 20 RUNNING, 18 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:15:53 (running for 00:02:39.08)\n",
      "Using AsyncHyperBand: num_stopped=19\n",
      "Bracket: Iter 40.000: None | Iter 20.000: -0.01973908167443236 | Iter 10.000: -0.04117912603838089 | Iter 5.000: -0.28806604002806846\n",
      "Logical resource usage: 0/64 CPUs, 1.0000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (41 PENDING, 20 RUNNING, 19 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:15:58 (running for 00:02:44.16)\n",
      "Using AsyncHyperBand: num_stopped=19\n",
      "Bracket: Iter 40.000: None | Iter 20.000: -0.019061023464832363 | Iter 10.000: -0.04117912603838089 | Iter 5.000: -0.28806604002806846\n",
      "Logical resource usage: 0/64 CPUs, 1.0000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (41 PENDING, 20 RUNNING, 19 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:16:03 (running for 00:02:49.18)\n",
      "Using AsyncHyperBand: num_stopped=19\n",
      "Bracket: Iter 40.000: None | Iter 20.000: -0.019061023464832363 | Iter 10.000: -0.04117912603838089 | Iter 5.000: -0.28806604002806846\n",
      "Logical resource usage: 0/64 CPUs, 1.0000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (41 PENDING, 20 RUNNING, 19 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:16:08 (running for 00:02:54.21)\n",
      "Using AsyncHyperBand: num_stopped=19\n",
      "Bracket: Iter 40.000: None | Iter 20.000: -0.019061023464832363 | Iter 10.000: -0.040027222688414216 | Iter 5.000: -0.28806604002806846\n",
      "Logical resource usage: 0/64 CPUs, 1.0000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (41 PENDING, 20 RUNNING, 19 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:16:13 (running for 00:02:59.23)\n",
      "Using AsyncHyperBand: num_stopped=20\n",
      "Bracket: Iter 40.000: None | Iter 20.000: -0.019061023464832363 | Iter 10.000: -0.040027222688414216 | Iter 5.000: -0.3040277301785914\n",
      "Logical resource usage: 0/64 CPUs, 1.0000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (40 PENDING, 20 RUNNING, 20 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:16:18 (running for 00:03:04.29)\n",
      "Using AsyncHyperBand: num_stopped=21\n",
      "Bracket: Iter 40.000: None | Iter 20.000: -0.019061023464832363 | Iter 10.000: -0.040027222688414216 | Iter 5.000: -0.3189901155636225\n",
      "Logical resource usage: 0/64 CPUs, 1.0000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (40 PENDING, 19 RUNNING, 21 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:16:23 (running for 00:03:09.35)\n",
      "Using AsyncHyperBand: num_stopped=21\n",
      "Bracket: Iter 40.000: None | Iter 20.000: -0.019061023464832363 | Iter 10.000: -0.040027222688414216 | Iter 5.000: -0.3189901155636225\n",
      "Logical resource usage: 0/64 CPUs, 1.0000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (39 PENDING, 20 RUNNING, 21 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:16:28 (running for 00:03:14.45)\n",
      "Using AsyncHyperBand: num_stopped=21\n",
      "Bracket: Iter 40.000: None | Iter 20.000: -0.019061023464832363 | Iter 10.000: -0.040027222688414216 | Iter 5.000: -0.3189901155636225\n",
      "Logical resource usage: 0/64 CPUs, 1.0000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (39 PENDING, 20 RUNNING, 21 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:16:33 (running for 00:03:19.54)\n",
      "Using AsyncHyperBand: num_stopped=21\n",
      "Bracket: Iter 40.000: -0.03224794770217211 | Iter 20.000: -0.019061023464832363 | Iter 10.000: -0.040027222688414216 | Iter 5.000: -0.3189901155636225\n",
      "Logical resource usage: 0/64 CPUs, 1.0000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (39 PENDING, 20 RUNNING, 21 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:16:38 (running for 00:03:24.56)\n",
      "Using AsyncHyperBand: num_stopped=21\n",
      "Bracket: Iter 40.000: -0.010583084032987784 | Iter 20.000: -0.019061023464832363 | Iter 10.000: -0.040027222688414216 | Iter 5.000: -0.3040277301785914\n",
      "Logical resource usage: 0/64 CPUs, 1.0000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (39 PENDING, 20 RUNNING, 21 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:16:43 (running for 00:03:29.65)\n",
      "Using AsyncHyperBand: num_stopped=21\n",
      "Bracket: Iter 40.000: -0.010583084032987784 | Iter 20.000: -0.019061023464832363 | Iter 10.000: -0.040027222688414216 | Iter 5.000: -0.3040277301785914\n",
      "Logical resource usage: 0/64 CPUs, 1.0000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (39 PENDING, 20 RUNNING, 21 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:16:48 (running for 00:03:34.72)\n",
      "Using AsyncHyperBand: num_stopped=21\n",
      "Bracket: Iter 40.000: -0.010583084032987784 | Iter 20.000: -0.019061023464832363 | Iter 10.000: -0.040027222688414216 | Iter 5.000: -0.28973415205601927\n",
      "Logical resource usage: 0/64 CPUs, 1.0000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (39 PENDING, 20 RUNNING, 21 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:16:53 (running for 00:03:39.81)\n",
      "Using AsyncHyperBand: num_stopped=21\n",
      "Bracket: Iter 40.000: -0.010583084032987784 | Iter 20.000: -0.018382965255232364 | Iter 10.000: -0.040027222688414216 | Iter 5.000: -0.28973415205601927\n",
      "Logical resource usage: 0/64 CPUs, 1.0000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (39 PENDING, 20 RUNNING, 21 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:16:58 (running for 00:03:44.82)\n",
      "Using AsyncHyperBand: num_stopped=21\n",
      "Bracket: Iter 40.000: -0.010583084032987784 | Iter 20.000: -0.018382965255232364 | Iter 10.000: -0.040027222688414216 | Iter 5.000: -0.28973415205601927\n",
      "Logical resource usage: 0/64 CPUs, 1.0000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (39 PENDING, 20 RUNNING, 21 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:17:04 (running for 00:03:49.87)\n",
      "Using AsyncHyperBand: num_stopped=22\n",
      "Bracket: Iter 40.000: -0.010520223741324058 | Iter 20.000: -0.018382965255232364 | Iter 10.000: -0.04117912603838089 | Iter 5.000: -0.28973415205601927\n",
      "Logical resource usage: 0/64 CPUs, 1.0000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (38 PENDING, 20 RUNNING, 22 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:17:09 (running for 00:03:54.95)\n",
      "Using AsyncHyperBand: num_stopped=23\n",
      "Bracket: Iter 40.000: -0.010457363449660332 | Iter 20.000: -0.018382965255232364 | Iter 10.000: -0.04233102938834756 | Iter 5.000: -0.28973415205601927\n",
      "Logical resource usage: 0/64 CPUs, 1.0000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (38 PENDING, 19 RUNNING, 23 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:17:14 (running for 00:04:00.03)\n",
      "Using AsyncHyperBand: num_stopped=23\n",
      "Bracket: Iter 40.000: -0.010457363449660332 | Iter 20.000: -0.018382965255232364 | Iter 10.000: -0.04233102938834756 | Iter 5.000: -0.28973415205601927\n",
      "Logical resource usage: 0/64 CPUs, 1.0000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (37 PENDING, 20 RUNNING, 23 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:17:19 (running for 00:04:05.04)\n",
      "Using AsyncHyperBand: num_stopped=23\n",
      "Bracket: Iter 40.000: -0.010457363449660332 | Iter 20.000: -0.018382965255232364 | Iter 10.000: -0.04233102938834756 | Iter 5.000: -0.28973415205601927\n",
      "Logical resource usage: 0/64 CPUs, 1.0000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (37 PENDING, 20 RUNNING, 23 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:17:24 (running for 00:04:10.05)\n",
      "Using AsyncHyperBand: num_stopped=23\n",
      "Bracket: Iter 40.000: -0.010457363449660332 | Iter 20.000: -0.018382965255232364 | Iter 10.000: -0.04233102938834756 | Iter 5.000: -0.28973415205601927\n",
      "Logical resource usage: 0/64 CPUs, 1.0000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (37 PENDING, 20 RUNNING, 23 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:17:29 (running for 00:04:15.13)\n",
      "Using AsyncHyperBand: num_stopped=23\n",
      "Bracket: Iter 40.000: -0.009631588329709093 | Iter 20.000: -0.018382965255232364 | Iter 10.000: -0.04233102938834756 | Iter 5.000: -0.27544057393344706\n",
      "Logical resource usage: 0/64 CPUs, 1.0000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (37 PENDING, 20 RUNNING, 23 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:17:34 (running for 00:04:20.15)\n",
      "Using AsyncHyperBand: num_stopped=23\n",
      "Bracket: Iter 40.000: -0.009631588329709093 | Iter 20.000: -0.018382965255232364 | Iter 10.000: -0.04233102938834756 | Iter 5.000: -0.27544057393344706\n",
      "Logical resource usage: 0/64 CPUs, 1.0000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (37 PENDING, 20 RUNNING, 23 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:17:39 (running for 00:04:25.25)\n",
      "Using AsyncHyperBand: num_stopped=23\n",
      "Bracket: Iter 40.000: -0.009631588329709093 | Iter 20.000: -0.018382965255232364 | Iter 10.000: -0.04233102938834756 | Iter 5.000: -0.27544057393344706\n",
      "Logical resource usage: 0/64 CPUs, 1.0000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (37 PENDING, 20 RUNNING, 23 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:17:44 (running for 00:04:30.31)\n",
      "Using AsyncHyperBand: num_stopped=23\n",
      "Bracket: Iter 40.000: -0.009631588329709093 | Iter 20.000: -0.018382965255232364 | Iter 10.000: -0.04233102938834756 | Iter 5.000: -0.27544057393344706\n",
      "Logical resource usage: 0/64 CPUs, 1.0000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (37 PENDING, 20 RUNNING, 23 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:17:49 (running for 00:04:35.35)\n",
      "Using AsyncHyperBand: num_stopped=23\n",
      "Bracket: Iter 40.000: -0.009631588329709093 | Iter 20.000: -0.018382965255232364 | Iter 10.000: -0.04233102938834756 | Iter 5.000: -0.27544057393344706\n",
      "Logical resource usage: 0/64 CPUs, 1.0000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (37 PENDING, 20 RUNNING, 23 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:17:54 (running for 00:04:40.37)\n",
      "Using AsyncHyperBand: num_stopped=23\n",
      "Bracket: Iter 40.000: -0.009631588329709093 | Iter 20.000: -0.018382965255232364 | Iter 10.000: -0.04117912603838089 | Iter 5.000: -0.27544057393344706\n",
      "Logical resource usage: 0/64 CPUs, 1.0000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (37 PENDING, 20 RUNNING, 23 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:17:59 (running for 00:04:45.42)\n",
      "Using AsyncHyperBand: num_stopped=23\n",
      "Bracket: Iter 40.000: -0.009631588329709093 | Iter 20.000: -0.018382965255232364 | Iter 10.000: -0.04117912603838089 | Iter 5.000: -0.27544057393344706\n",
      "Logical resource usage: 0/64 CPUs, 1.0000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (37 PENDING, 20 RUNNING, 23 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:18:04 (running for 00:04:50.46)\n",
      "Using AsyncHyperBand: num_stopped=28\n",
      "Bracket: Iter 40.000: -0.009631588329709093 | Iter 20.000: -0.018382965255232364 | Iter 10.000: -0.04117912603838089 | Iter 5.000: -0.27544057393344706\n",
      "Logical resource usage: 0/64 CPUs, 1.0000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (37 PENDING, 15 RUNNING, 28 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:18:09 (running for 00:04:55.52)\n",
      "Using AsyncHyperBand: num_stopped=35\n",
      "Bracket: Iter 40.000: -0.009631588329709093 | Iter 20.000: -0.018382965255232364 | Iter 10.000: -0.04117912603838089 | Iter 5.000: -0.27544057393344706\n",
      "Logical resource usage: 0/64 CPUs, 1.0000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (31 PENDING, 14 RUNNING, 35 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:18:14 (running for 00:05:00.57)\n",
      "Using AsyncHyperBand: num_stopped=35\n",
      "Bracket: Iter 40.000: -0.009631588329709093 | Iter 20.000: -0.018382965255232364 | Iter 10.000: -0.04117912603838089 | Iter 5.000: -0.27544057393344706\n",
      "Logical resource usage: 0/64 CPUs, 1.0000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (25 PENDING, 20 RUNNING, 35 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:18:19 (running for 00:05:05.58)\n",
      "Using AsyncHyperBand: num_stopped=35\n",
      "Bracket: Iter 40.000: -0.009631588329709093 | Iter 20.000: -0.018382965255232364 | Iter 10.000: -0.04117912603838089 | Iter 5.000: -0.27544057393344706\n",
      "Logical resource usage: 0/64 CPUs, 1.0000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (25 PENDING, 20 RUNNING, 35 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:18:24 (running for 00:05:10.66)\n",
      "Using AsyncHyperBand: num_stopped=35\n",
      "Bracket: Iter 40.000: -0.008805813209757854 | Iter 20.000: -0.018382965255232364 | Iter 10.000: -0.04117912603838089 | Iter 5.000: -0.27544057393344706\n",
      "Logical resource usage: 0/64 CPUs, 1.0000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (25 PENDING, 20 RUNNING, 35 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:18:29 (running for 00:05:15.71)\n",
      "Using AsyncHyperBand: num_stopped=37\n",
      "Bracket: Iter 40.000: -0.008805813209757854 | Iter 20.000: -0.018382965255232364 | Iter 10.000: -0.04117912603838089 | Iter 5.000: -0.27377246190549626\n",
      "Logical resource usage: 0/64 CPUs, 1.0000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (25 PENDING, 18 RUNNING, 37 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:18:34 (running for 00:05:20.78)\n",
      "Using AsyncHyperBand: num_stopped=40\n",
      "Bracket: Iter 40.000: -0.008805813209757854 | Iter 20.000: -0.018371162906671956 | Iter 10.000: -0.04117912603838089 | Iter 5.000: -0.24716634878974297\n",
      "Logical resource usage: 0/64 CPUs, 0.9500000000000003/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (23 PENDING, 17 RUNNING, 40 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:18:39 (running for 00:05:25.82)\n",
      "Using AsyncHyperBand: num_stopped=40\n",
      "Bracket: Iter 40.000: -0.008805813209757854 | Iter 20.000: -0.018371162906671956 | Iter 10.000: -0.04117912603838089 | Iter 5.000: -0.24716634878974297\n",
      "Logical resource usage: 0/64 CPUs, 1.0000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (20 PENDING, 20 RUNNING, 40 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:18:44 (running for 00:05:30.85)\n",
      "Using AsyncHyperBand: num_stopped=40\n",
      "Bracket: Iter 40.000: -0.008805813209757854 | Iter 20.000: -0.018371162906671956 | Iter 10.000: -0.04117912603838089 | Iter 5.000: -0.24716634878974297\n",
      "Logical resource usage: 0/64 CPUs, 1.0000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (20 PENDING, 20 RUNNING, 40 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:18:50 (running for 00:05:35.93)\n",
      "Using AsyncHyperBand: num_stopped=41\n",
      "Bracket: Iter 40.000: -0.008805813209757854 | Iter 20.000: -0.018371162906671956 | Iter 10.000: -0.04233102938834756 | Iter 5.000: -0.24716634878974297\n",
      "Logical resource usage: 0/64 CPUs, 0.9500000000000003/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (20 PENDING, 19 RUNNING, 41 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:18:55 (running for 00:05:41.02)\n",
      "Using AsyncHyperBand: num_stopped=42\n",
      "Bracket: Iter 40.000: -0.008805813209757854 | Iter 20.000: -0.018371162906671956 | Iter 10.000: -0.04117912603838089 | Iter 5.000: -0.2051864521959822\n",
      "Logical resource usage: 0/64 CPUs, 1.0000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (19 PENDING, 19 RUNNING, 42 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:19:00 (running for 00:05:46.02)\n",
      "Using AsyncHyperBand: num_stopped=45\n",
      "Bracket: Iter 40.000: -0.008805813209757854 | Iter 20.000: -0.018371162906671956 | Iter 10.000: -0.03941143399810712 | Iter 5.000: -0.15476576272359666\n",
      "Logical resource usage: 0/64 CPUs, 1.0000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (17 PENDING, 18 RUNNING, 45 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:19:05 (running for 00:05:51.07)\n",
      "Using AsyncHyperBand: num_stopped=46\n",
      "Bracket: Iter 40.000: -0.008805813209757854 | Iter 20.000: -0.018371162906671956 | Iter 10.000: -0.03941143399810712 | Iter 5.000: -0.1842439859762066\n",
      "Logical resource usage: 0/64 CPUs, 1.0000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (15 PENDING, 19 RUNNING, 46 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:19:10 (running for 00:05:56.13)\n",
      "Using AsyncHyperBand: num_stopped=46\n",
      "Bracket: Iter 40.000: -0.008805813209757854 | Iter 20.000: -0.018371162906671956 | Iter 10.000: -0.03941143399810712 | Iter 5.000: -0.1842439859762066\n",
      "Logical resource usage: 0/64 CPUs, 1.0000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (14 PENDING, 20 RUNNING, 46 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:19:15 (running for 00:06:01.16)\n",
      "Using AsyncHyperBand: num_stopped=46\n",
      "Bracket: Iter 40.000: -0.008805813209757854 | Iter 20.000: -0.018371162906671956 | Iter 10.000: -0.03941143399810712 | Iter 5.000: -0.1842439859762066\n",
      "Logical resource usage: 0/64 CPUs, 1.0000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (14 PENDING, 20 RUNNING, 46 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:19:20 (running for 00:06:06.19)\n",
      "Using AsyncHyperBand: num_stopped=47\n",
      "Bracket: Iter 40.000: -0.008805813209757854 | Iter 20.000: -0.018371162906671956 | Iter 10.000: -0.03941143399810712 | Iter 5.000: -0.15476576272359666\n",
      "Logical resource usage: 0/64 CPUs, 1.0000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (13 PENDING, 20 RUNNING, 47 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:19:25 (running for 00:06:11.26)\n",
      "Using AsyncHyperBand: num_stopped=52\n",
      "Bracket: Iter 40.000: -0.008805813209757854 | Iter 20.000: -0.018371162906671956 | Iter 10.000: -0.03941143399810712 | Iter 5.000: -0.19735266392416403\n",
      "Logical resource usage: 0/64 CPUs, 0.9000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (12 PENDING, 16 RUNNING, 52 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:19:30 (running for 00:06:16.28)\n",
      "Using AsyncHyperBand: num_stopped=52\n",
      "Bracket: Iter 40.000: -0.008805813209757854 | Iter 20.000: -0.018371162906671956 | Iter 10.000: -0.03941143399810712 | Iter 5.000: -0.1842439859762066\n",
      "Logical resource usage: 0/64 CPUs, 1.0000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (8 PENDING, 20 RUNNING, 52 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:19:35 (running for 00:06:21.34)\n",
      "Using AsyncHyperBand: num_stopped=52\n",
      "Bracket: Iter 40.000: -0.008805813209757854 | Iter 20.000: -0.017946382948714302 | Iter 10.000: -0.03941143399810712 | Iter 5.000: -0.1842439859762066\n",
      "Logical resource usage: 0/64 CPUs, 1.0000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (8 PENDING, 20 RUNNING, 52 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:19:40 (running for 00:06:26.36)\n",
      "Using AsyncHyperBand: num_stopped=53\n",
      "Bracket: Iter 40.000: -0.008805813209757854 | Iter 20.000: -0.018359360558111548 | Iter 10.000: -0.03879564530780002 | Iter 5.000: -0.1842439859762066\n",
      "Logical resource usage: 0/64 CPUs, 1.0000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (8 PENDING, 19 RUNNING, 53 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:19:45 (running for 00:06:31.37)\n",
      "Using AsyncHyperBand: num_stopped=53\n",
      "Bracket: Iter 40.000: -0.008805813209757854 | Iter 20.000: -0.017533405339317056 | Iter 10.000: -0.03819760840610978 | Iter 5.000: -0.15591602645414046\n",
      "Logical resource usage: 0/64 CPUs, 1.0000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (7 PENDING, 20 RUNNING, 53 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:19:50 (running for 00:06:36.42)\n",
      "Using AsyncHyperBand: num_stopped=55\n",
      "Bracket: Iter 40.000: -0.008805813209757854 | Iter 20.000: -0.017533405339317056 | Iter 10.000: -0.03879564530780002 | Iter 5.000: -0.12643780320153053\n",
      "Logical resource usage: 0/64 CPUs, 0.9500000000000003/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (7 PENDING, 18 RUNNING, 55 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:19:55 (running for 00:06:41.51)\n",
      "Using AsyncHyperBand: num_stopped=55\n",
      "Bracket: Iter 40.000: -0.008805813209757854 | Iter 20.000: -0.017533405339317056 | Iter 10.000: -0.03879564530780002 | Iter 5.000: -0.12527457820036084\n",
      "Logical resource usage: 0/64 CPUs, 1.0000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (5 PENDING, 20 RUNNING, 55 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:20:00 (running for 00:06:46.55)\n",
      "Using AsyncHyperBand: num_stopped=55\n",
      "Bracket: Iter 40.000: -0.008805813209757854 | Iter 20.000: -0.017533405339317056 | Iter 10.000: -0.03879564530780002 | Iter 5.000: -0.12527457820036084\n",
      "Logical resource usage: 0/64 CPUs, 1.0000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (5 PENDING, 20 RUNNING, 55 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:20:05 (running for 00:06:51.59)\n",
      "Using AsyncHyperBand: num_stopped=57\n",
      "Bracket: Iter 40.000: -0.008580510333108474 | Iter 20.000: -0.017533405339317056 | Iter 10.000: -0.03879564530780002 | Iter 5.000: -0.1252875394709867\n",
      "Logical resource usage: 0/64 CPUs, 0.9500000000000003/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (5 PENDING, 18 RUNNING, 57 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:20:10 (running for 00:06:56.63)\n",
      "Using AsyncHyperBand: num_stopped=58\n",
      "Bracket: Iter 40.000: -0.008580510333108474 | Iter 20.000: -0.017533405339317056 | Iter 10.000: -0.03941143399810712 | Iter 5.000: -0.1252875394709867\n",
      "Logical resource usage: 0/64 CPUs, 1.0000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (2 PENDING, 20 RUNNING, 58 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:20:15 (running for 00:07:01.70)\n",
      "Using AsyncHyperBand: num_stopped=59\n",
      "Bracket: Iter 40.000: -0.008580510333108474 | Iter 20.000: -0.017533405339317056 | Iter 10.000: -0.03739651187021165 | Iter 5.000: -0.12643780320153053\n",
      "Logical resource usage: 0/64 CPUs, 0.9500000000000003/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (2 PENDING, 19 RUNNING, 59 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:20:20 (running for 00:07:06.72)\n",
      "Using AsyncHyperBand: num_stopped=59\n",
      "Bracket: Iter 40.000: -0.008580510333108474 | Iter 20.000: -0.017533405339317056 | Iter 10.000: -0.03739651187021165 | Iter 5.000: -0.1252875394709867\n",
      "Logical resource usage: 0/64 CPUs, 1.0000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (1 PENDING, 20 RUNNING, 59 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:20:25 (running for 00:07:11.72)\n",
      "Using AsyncHyperBand: num_stopped=59\n",
      "Bracket: Iter 40.000: -0.008580510333108474 | Iter 20.000: -0.016879260837419897 | Iter 10.000: -0.03739651187021165 | Iter 5.000: -0.1252875394709867\n",
      "Logical resource usage: 0/64 CPUs, 1.0000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (1 PENDING, 20 RUNNING, 59 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:20:30 (running for 00:07:16.80)\n",
      "Using AsyncHyperBand: num_stopped=60\n",
      "Bracket: Iter 40.000: -0.008580510333108474 | Iter 20.000: -0.01622511633552274 | Iter 10.000: -0.03739651187021165 | Iter 5.000: -0.12643780320153053\n",
      "Logical resource usage: 0/64 CPUs, 0.9500000000000003/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (1 PENDING, 19 RUNNING, 60 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:20:36 (running for 00:07:21.88)\n",
      "Using AsyncHyperBand: num_stopped=61\n",
      "Bracket: Iter 40.000: -0.008580510333108474 | Iter 20.000: -0.01622511633552274 | Iter 10.000: -0.03739651187021165 | Iter 5.000: -0.12643780320153053\n",
      "Logical resource usage: 0/64 CPUs, 0.9500000000000003/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (19 RUNNING, 61 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:20:41 (running for 00:07:26.91)\n",
      "Using AsyncHyperBand: num_stopped=61\n",
      "Bracket: Iter 40.000: -0.008580510333108474 | Iter 20.000: -0.01622511633552274 | Iter 10.000: -0.037193452236003774 | Iter 5.000: -0.12643780320153053\n",
      "Logical resource usage: 0/64 CPUs, 0.9500000000000003/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (19 RUNNING, 61 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:20:46 (running for 00:07:31.97)\n",
      "Using AsyncHyperBand: num_stopped=61\n",
      "Bracket: Iter 40.000: -0.008580510333108474 | Iter 20.000: -0.01622511633552274 | Iter 10.000: -0.037193452236003774 | Iter 5.000: -0.1252875394709867\n",
      "Logical resource usage: 0/64 CPUs, 0.9500000000000003/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (19 RUNNING, 61 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:20:51 (running for 00:07:36.99)\n",
      "Using AsyncHyperBand: num_stopped=61\n",
      "Bracket: Iter 40.000: -0.008580510333108474 | Iter 20.000: -0.01622511633552274 | Iter 10.000: -0.037193452236003774 | Iter 5.000: -0.1252875394709867\n",
      "Logical resource usage: 0/64 CPUs, 0.9500000000000003/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (19 RUNNING, 61 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:20:56 (running for 00:07:42.00)\n",
      "Using AsyncHyperBand: num_stopped=62\n",
      "Bracket: Iter 40.000: -0.008580510333108474 | Iter 20.000: -0.015977999287290635 | Iter 10.000: -0.03739651187021165 | Iter 5.000: -0.1252875394709867\n",
      "Logical resource usage: 0/64 CPUs, 0.9000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (18 RUNNING, 62 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:21:01 (running for 00:07:47.08)\n",
      "Using AsyncHyperBand: num_stopped=62\n",
      "Bracket: Iter 40.000: -0.008580510333108474 | Iter 20.000: -0.01573088223905853 | Iter 10.000: -0.03739651187021165 | Iter 5.000: -0.12527457820036084\n",
      "Logical resource usage: 0/64 CPUs, 0.9000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (18 RUNNING, 62 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:21:06 (running for 00:07:52.11)\n",
      "Using AsyncHyperBand: num_stopped=62\n",
      "Bracket: Iter 40.000: -0.00740372696023066 | Iter 20.000: -0.01573088223905853 | Iter 10.000: -0.037193452236003774 | Iter 5.000: -0.12527457820036084\n",
      "Logical resource usage: 0/64 CPUs, 0.9000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (18 RUNNING, 62 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:21:11 (running for 00:07:57.14)\n",
      "Using AsyncHyperBand: num_stopped=63\n",
      "Bracket: Iter 40.000: -0.006992464011471135 | Iter 20.000: -0.01573088223905853 | Iter 10.000: -0.037193452236003774 | Iter 5.000: -0.12527457820036084\n",
      "Logical resource usage: 0/64 CPUs, 0.8500000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (17 RUNNING, 63 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:21:16 (running for 00:08:02.15)\n",
      "Using AsyncHyperBand: num_stopped=63\n",
      "Bracket: Iter 40.000: -0.006992464011471135 | Iter 20.000: -0.01573088223905853 | Iter 10.000: -0.037193452236003774 | Iter 5.000: -0.12527457820036084\n",
      "Logical resource usage: 0/64 CPUs, 0.8500000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (17 RUNNING, 63 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:21:21 (running for 00:08:07.24)\n",
      "Using AsyncHyperBand: num_stopped=63\n",
      "Bracket: Iter 40.000: -0.006992464011471135 | Iter 20.000: -0.015610776264618903 | Iter 10.000: -0.03618860485689683 | Iter 5.000: -0.12527457820036084\n",
      "Logical resource usage: 0/64 CPUs, 0.8500000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (17 RUNNING, 63 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:21:26 (running for 00:08:12.26)\n",
      "Using AsyncHyperBand: num_stopped=63\n",
      "Bracket: Iter 40.000: -0.006489584419164397 | Iter 20.000: -0.015610776264618903 | Iter 10.000: -0.03618860485689683 | Iter 5.000: -0.12527457820036084\n",
      "Logical resource usage: 0/64 CPUs, 0.8500000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (17 RUNNING, 63 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:21:31 (running for 00:08:17.34)\n",
      "Using AsyncHyperBand: num_stopped=64\n",
      "Bracket: Iter 40.000: -0.006489584419164397 | Iter 20.000: -0.015610776264618903 | Iter 10.000: -0.03618860485689683 | Iter 5.000: -0.12527457820036084\n",
      "Logical resource usage: 0/64 CPUs, 0.8000000000000002/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (16 RUNNING, 64 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:21:36 (running for 00:08:22.36)\n",
      "Using AsyncHyperBand: num_stopped=65\n",
      "Bracket: Iter 40.000: -0.006489584419164397 | Iter 20.000: -0.015610776264618903 | Iter 10.000: -0.03618860485689683 | Iter 5.000: -0.12527457820036084\n",
      "Logical resource usage: 0/64 CPUs, 0.7500000000000001/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (15 RUNNING, 65 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:21:41 (running for 00:08:27.36)\n",
      "Using AsyncHyperBand: num_stopped=65\n",
      "Bracket: Iter 40.000: -0.006489584419164397 | Iter 20.000: -0.015610776264618903 | Iter 10.000: -0.03618860485689683 | Iter 5.000: -0.12527457820036084\n",
      "Logical resource usage: 0/64 CPUs, 0.7500000000000001/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (15 RUNNING, 65 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:21:46 (running for 00:08:32.40)\n",
      "Using AsyncHyperBand: num_stopped=65\n",
      "Bracket: Iter 40.000: -0.0064709154415833105 | Iter 20.000: -0.015490670290179274 | Iter 10.000: -0.03618860485689683 | Iter 5.000: -0.12527457820036084\n",
      "Logical resource usage: 0/64 CPUs, 0.7500000000000001/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (15 RUNNING, 65 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:21:51 (running for 00:08:37.44)\n",
      "Using AsyncHyperBand: num_stopped=65\n",
      "Bracket: Iter 40.000: -0.006452246464002224 | Iter 20.000: -0.015490670290179274 | Iter 10.000: -0.03618860485689683 | Iter 5.000: -0.12527457820036084\n",
      "Logical resource usage: 0/64 CPUs, 0.7500000000000001/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (15 RUNNING, 65 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:21:56 (running for 00:08:42.45)\n",
      "Using AsyncHyperBand: num_stopped=65\n",
      "Bracket: Iter 40.000: -0.006452246464002224 | Iter 20.000: -0.015418565092017122 | Iter 10.000: -0.03618860485689683 | Iter 5.000: -0.12527457820036084\n",
      "Logical resource usage: 0/64 CPUs, 0.7500000000000001/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (15 RUNNING, 65 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:22:01 (running for 00:08:47.47)\n",
      "Using AsyncHyperBand: num_stopped=65\n",
      "Bracket: Iter 40.000: -0.006452246464002224 | Iter 20.000: -0.015418565092017122 | Iter 10.000: -0.03618860485689683 | Iter 5.000: -0.12527457820036084\n",
      "Logical resource usage: 0/64 CPUs, 0.7500000000000001/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (15 RUNNING, 65 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:22:06 (running for 00:08:52.48)\n",
      "Using AsyncHyperBand: num_stopped=65\n",
      "Bracket: Iter 40.000: -0.006452246464002224 | Iter 20.000: -0.015418565092017122 | Iter 10.000: -0.03618860485689683 | Iter 5.000: -0.12527457820036084\n",
      "Logical resource usage: 0/64 CPUs, 0.7500000000000001/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (15 RUNNING, 65 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:22:11 (running for 00:08:57.52)\n",
      "Using AsyncHyperBand: num_stopped=65\n",
      "Bracket: Iter 40.000: -0.006452246464002224 | Iter 20.000: -0.015418565092017122 | Iter 10.000: -0.03618860485689683 | Iter 5.000: -0.12527457820036084\n",
      "Logical resource usage: 0/64 CPUs, 0.7500000000000001/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (15 RUNNING, 65 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:22:16 (running for 00:09:02.54)\n",
      "Using AsyncHyperBand: num_stopped=66\n",
      "Bracket: Iter 40.000: -0.006284731524982826 | Iter 20.000: -0.015418565092017122 | Iter 10.000: -0.03618860485689683 | Iter 5.000: -0.12527457820036084\n",
      "Logical resource usage: 0/64 CPUs, 0.7000000000000001/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (14 RUNNING, 66 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:22:21 (running for 00:09:07.58)\n",
      "Using AsyncHyperBand: num_stopped=70\n",
      "Bracket: Iter 40.000: -0.006284731524982826 | Iter 20.000: -0.015418565092017122 | Iter 10.000: -0.03618860485689683 | Iter 5.000: -0.12527457820036084\n",
      "Logical resource usage: 0/64 CPUs, 0.49999999999999994/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (10 RUNNING, 70 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:22:26 (running for 00:09:12.65)\n",
      "Using AsyncHyperBand: num_stopped=70\n",
      "Bracket: Iter 40.000: -0.006284731524982826 | Iter 20.000: -0.015418565092017122 | Iter 10.000: -0.03618860485689683 | Iter 5.000: -0.12527457820036084\n",
      "Logical resource usage: 0/64 CPUs, 0.49999999999999994/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (10 RUNNING, 70 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:22:31 (running for 00:09:17.68)\n",
      "Using AsyncHyperBand: num_stopped=70\n",
      "Bracket: Iter 40.000: -0.006205337235526225 | Iter 20.000: -0.015418565092017122 | Iter 10.000: -0.03618860485689683 | Iter 5.000: -0.12527457820036084\n",
      "Logical resource usage: 0/64 CPUs, 0.49999999999999994/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (10 RUNNING, 70 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:22:36 (running for 00:09:22.75)\n",
      "Using AsyncHyperBand: num_stopped=71\n",
      "Bracket: Iter 40.000: -0.006205337235526225 | Iter 20.000: -0.015418565092017122 | Iter 10.000: -0.03618860485689683 | Iter 5.000: -0.12527457820036084\n",
      "Logical resource usage: 0/64 CPUs, 0.44999999999999996/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (9 RUNNING, 71 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:22:41 (running for 00:09:27.77)\n",
      "Using AsyncHyperBand: num_stopped=71\n",
      "Bracket: Iter 40.000: -0.006205337235526225 | Iter 20.000: -0.015418565092017122 | Iter 10.000: -0.03618860485689683 | Iter 5.000: -0.12527457820036084\n",
      "Logical resource usage: 0/64 CPUs, 0.44999999999999996/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (9 RUNNING, 71 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:22:46 (running for 00:09:32.81)\n",
      "Using AsyncHyperBand: num_stopped=72\n",
      "Bracket: Iter 40.000: -0.006125942946069625 | Iter 20.000: -0.015418565092017122 | Iter 10.000: -0.03618860485689683 | Iter 5.000: -0.12527457820036084\n",
      "Logical resource usage: 0/64 CPUs, 0.39999999999999997/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (8 RUNNING, 72 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:22:51 (running for 00:09:37.83)\n",
      "Using AsyncHyperBand: num_stopped=73\n",
      "Bracket: Iter 40.000: -0.006125942946069625 | Iter 20.000: -0.015418565092017122 | Iter 10.000: -0.03618860485689683 | Iter 5.000: -0.12527457820036084\n",
      "Logical resource usage: 0/64 CPUs, 0.35/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (7 RUNNING, 73 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:22:56 (running for 00:09:42.86)\n",
      "Using AsyncHyperBand: num_stopped=74\n",
      "Bracket: Iter 40.000: -0.006129743704112958 | Iter 20.000: -0.015418565092017122 | Iter 10.000: -0.03618860485689683 | Iter 5.000: -0.12527457820036084\n",
      "Logical resource usage: 0/64 CPUs, 0.3/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (6 RUNNING, 74 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:23:02 (running for 00:09:47.95)\n",
      "Using AsyncHyperBand: num_stopped=78\n",
      "Bracket: Iter 40.000: -0.006129743704112958 | Iter 20.000: -0.015418565092017122 | Iter 10.000: -0.03618860485689683 | Iter 5.000: -0.12527457820036084\n",
      "Logical resource usage: 0/64 CPUs, 0.1/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (2 RUNNING, 78 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:23:07 (running for 00:09:53.05)\n",
      "Using AsyncHyperBand: num_stopped=78\n",
      "Bracket: Iter 40.000: -0.006129743704112958 | Iter 20.000: -0.015418565092017122 | Iter 10.000: -0.03618860485689683 | Iter 5.000: -0.12527457820036084\n",
      "Logical resource usage: 0/64 CPUs, 0.1/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (2 RUNNING, 78 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-11-02 15:23:12 (running for 00:09:58.10)\n",
      "Using AsyncHyperBand: num_stopped=79\n",
      "Bracket: Iter 40.000: -0.006129743704112958 | Iter 20.000: -0.015418565092017122 | Iter 10.000: -0.03618860485689683 | Iter 5.000: -0.12527457820036084\n",
      "Logical resource usage: 0/64 CPUs, 0.05/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (1 RUNNING, 79 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-02 15:23:16,688\tINFO tune.py:1143 -- Total run time: 602.63 seconds (602.54 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-11-02 15:23:16 (running for 00:10:02.55)\n",
      "Using AsyncHyperBand: num_stopped=80\n",
      "Bracket: Iter 40.000: -0.006129743704112958 | Iter 20.000: -0.015418565092017122 | Iter 10.000: -0.03618860485689683 | Iter 5.000: -0.12527457820036084\n",
      "Logical resource usage: 0/64 CPUs, 0.05/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /home/rraiyan/ray_results/train_with_tuning_2023-11-02_15-13-14\n",
      "Number of trials: 80/80 (80 TERMINATED)\n",
      "+-------------------------------+------------+-----------------------+-------------+------------+--------------+------------+-----------------+\n",
      "| Trial name                    | status     | loc                   |          lr |   momentum |   train_loss |   val_loss |   combined_loss |\n",
      "|-------------------------------+------------+-----------------------+-------------+------------+--------------+------------+-----------------|\n",
      "| train_with_tuning_043b2_00000 | TERMINATED | 169.237.32.34:1087164 | 0.000760181 |   0.981246 | nan          | nan        |    nan          |\n",
      "| train_with_tuning_043b2_00001 | TERMINATED | 169.237.32.34:1087165 | 5.49943e-05 |   0.802937 |   0.575367   |   0.883606 |      0.508398   |\n",
      "| train_with_tuning_043b2_00002 | TERMINATED | 169.237.32.34:1087166 | 7.18403e-05 |   0.983664 |   0.00658183 |   0.498197 |      0.00327905 |\n",
      "| train_with_tuning_043b2_00003 | TERMINATED | 169.237.32.34:1087167 | 0.000508182 |   0.855945 |   0.00725607 |   1.13456  |      0.00823242 |\n",
      "| train_with_tuning_043b2_00004 | TERMINATED | 169.237.32.34:1087170 | 0.000503818 |   0.860215 |   0.00757098 |   1.17026  |      0.00886003 |\n",
      "| train_with_tuning_043b2_00005 | TERMINATED | 169.237.32.34:1087169 | 0.000129898 |   0.977869 |   0.00517695 |   1.36295  |      0.00705593 |\n",
      "| train_with_tuning_043b2_00006 | TERMINATED | 169.237.32.34:1087168 | 0.000138077 |   0.818464 |   0.0650029  |   1.51328  |      0.0983673  |\n",
      "| train_with_tuning_043b2_00007 | TERMINATED | 169.237.32.34:1087171 | 0.000955229 |   0.826616 |   0.00716983 |   1.03667  |      0.00743277 |\n",
      "| train_with_tuning_043b2_00008 | TERMINATED | 169.237.32.34:1087172 | 0.000568521 |   0.940746 | nan          | nan        |    nan          |\n",
      "| train_with_tuning_043b2_00009 | TERMINATED | 169.237.32.34:1087173 | 0.000254079 |   0.868303 |   0.0099373  |   0.554329 |      0.00550853 |\n",
      "| train_with_tuning_043b2_00010 | TERMINATED | 169.237.32.34:1087174 | 0.000415645 |   0.953922 | nan          | nan        |    nan          |\n",
      "| train_with_tuning_043b2_00011 | TERMINATED | 169.237.32.34:1087175 | 0.000670627 |   0.897155 |   0.0316799  | 125.243    |      3.96769    |\n",
      "| train_with_tuning_043b2_00012 | TERMINATED | 169.237.32.34:1087177 | 0.000394994 |   0.923493 |   0.00646997 |   1.47256  |      0.00952741 |\n",
      "| train_with_tuning_043b2_00013 | TERMINATED | 169.237.32.34:1087178 | 0.000390468 |   0.969101 |   0.00651261 |   3.11367  |      0.0202781  |\n",
      "| train_with_tuning_043b2_00014 | TERMINATED | 169.237.32.34:1087180 | 5.63853e-05 |   0.817857 |   0.53078    |   0.887106 |      0.470858   |\n",
      "| train_with_tuning_043b2_00015 | TERMINATED | 169.237.32.34:1087181 | 1.18001e-05 |   0.888464 |   0.0728794  |   1.26016  |      0.0918399  |\n",
      "| train_with_tuning_043b2_00016 | TERMINATED | 169.237.32.34:1087184 | 3.74182e-05 |   0.912258 |   0.407045   |   0.961975 |      0.391567   |\n",
      "| train_with_tuning_043b2_00017 | TERMINATED | 169.237.32.34:1087185 | 1.18767e-05 |   0.956294 |   0.597103   |   0.884617 |      0.528207   |\n",
      "| train_with_tuning_043b2_00018 | TERMINATED | 169.237.32.34:1087187 | 1.79523e-05 |   0.899226 |   0.740191   |   0.912339 |      0.675304   |\n",
      "| train_with_tuning_043b2_00019 | TERMINATED | 169.237.32.34:1087188 | 2.70173e-05 |   0.918349 |   0.508756   |   0.894076 |      0.454866   |\n",
      "| train_with_tuning_043b2_00020 | TERMINATED | 169.237.32.34:1114932 | 1.26871e-05 |   0.900957 |   0.818408   |   0.927794 |      0.759314   |\n",
      "| train_with_tuning_043b2_00021 | TERMINATED | 169.237.32.34:1114933 | 0.000188304 |   0.937957 |   0.00837475 |   0.560977 |      0.00469804 |\n",
      "| train_with_tuning_043b2_00022 | TERMINATED | 169.237.32.34:1117648 | 0.000107796 |   0.861362 |   0.0643891  |   1.50714  |      0.0970432  |\n",
      "| train_with_tuning_043b2_00023 | TERMINATED | 169.237.32.34:1117650 | 3.48068e-05 |   0.883405 |   0.549275   |   0.886803 |      0.487098   |\n",
      "| train_with_tuning_043b2_00024 | TERMINATED | 169.237.32.34:1119492 | 1.12383e-05 |   0.982903 |   0.302413   |   1.10429  |      0.333953   |\n",
      "| train_with_tuning_043b2_00025 | TERMINATED | 169.237.32.34:1119493 | 0.000246575 |   0.877701 |   0.00952175 |   0.453123 |      0.00431452 |\n",
      "| train_with_tuning_043b2_00026 | TERMINATED | 169.237.32.34:1119494 | 2.05529e-05 |   0.847546 |   0.808103   |   0.926287 |      0.748536   |\n",
      "| train_with_tuning_043b2_00027 | TERMINATED | 169.237.32.34:1143344 | 0.000268653 |   0.925438 |   0.00734701 |   0.545044 |      0.00400444 |\n",
      "| train_with_tuning_043b2_00028 | TERMINATED | 169.237.32.34:1145001 | 0.000812326 |   0.9402   | nan          | nan        |    nan          |\n",
      "| train_with_tuning_043b2_00029 | TERMINATED | 169.237.32.34:1148137 | 0.000167279 |   0.879724 |   0.0377007  |   1.48292  |      0.0559072  |\n",
      "| train_with_tuning_043b2_00030 | TERMINATED | 169.237.32.34:1149567 | 5.15164e-05 |   0.943991 |   0.0535067  |   1.53688  |      0.0822334  |\n",
      "| train_with_tuning_043b2_00031 | TERMINATED | 169.237.32.34:1153006 | 1.70665e-05 |   0.808741 |   0.872489   |   0.934244 |      0.815118   |\n",
      "| train_with_tuning_043b2_00032 | TERMINATED | 169.237.32.34:1174344 | 0.00051395  |   0.933695 | nan          | nan        |    nan          |\n",
      "| train_with_tuning_043b2_00033 | TERMINATED | 169.237.32.34:1182631 | 1.56916e-05 |   0.893407 |   0.789764   |   0.923247 |      0.729147   |\n",
      "| train_with_tuning_043b2_00034 | TERMINATED | 169.237.32.34:1204799 | 2.22026e-05 |   0.882432 |   0.722377   |   0.907811 |      0.655781   |\n",
      "| train_with_tuning_043b2_00035 | TERMINATED | 169.237.32.34:1206716 | 0.000170491 |   0.920668 |   0.00922677 |   0.444506 |      0.00410135 |\n",
      "| train_with_tuning_043b2_00036 | TERMINATED | 169.237.32.34:1213837 | 5.61339e-05 |   0.918913 |   0.252431   |   1.2044   |      0.304028   |\n",
      "| train_with_tuning_043b2_00037 | TERMINATED | 169.237.32.34:1236008 | 0.000516392 |   0.925152 |   1.00001    |   1.00039  |      1.00041    |\n",
      "| train_with_tuning_043b2_00038 | TERMINATED | 169.237.32.34:1245086 | 1.384e-05   |   0.92206  |   0.742129   |   0.912914 |      0.6775     |\n",
      "| train_with_tuning_043b2_00039 | TERMINATED | 169.237.32.34:1266878 | 0.00014844  |   0.978644 |   0.0185365  |   2.60311  |      0.0482526  |\n",
      "| train_with_tuning_043b2_00040 | TERMINATED | 169.237.32.34:1276093 | 5.97503e-05 |   0.922225 |   0.0652301  |   1.49095  |      0.0972548  |\n",
      "| train_with_tuning_043b2_00041 | TERMINATED | 169.237.32.34:1324858 | 0.000123377 |   0.978878 |   0.00556015 |   0.65185  |      0.00362438 |\n",
      "| train_with_tuning_043b2_00042 | TERMINATED | 169.237.32.34:1333932 | 0.000836337 |   0.972017 | nan          | nan        |    nan          |\n",
      "| train_with_tuning_043b2_00043 | TERMINATED | 169.237.32.34:1397358 | 1.37633e-05 |   0.819148 |   0.89099    |   0.935923 |      0.833898   |\n",
      "| train_with_tuning_043b2_00044 | TERMINATED | 169.237.32.34:1397359 | 1.54485e-05 |   0.929771 |   0.673352   |   0.894669 |      0.602427   |\n",
      "| train_with_tuning_043b2_00045 | TERMINATED | 169.237.32.34:1397360 | 4.34461e-05 |   0.960526 |   0.0472371  |   1.52464  |      0.0720194  |\n",
      "| train_with_tuning_043b2_00046 | TERMINATED | 169.237.32.34:1400120 | 0.000425537 |   0.853552 |   0.00865898 |   0.528371 |      0.00457516 |\n",
      "| train_with_tuning_043b2_00047 | TERMINATED | 169.237.32.34:1400121 | 0.000247443 |   0.919499 |   0.00800896 |   0.600201 |      0.00480698 |\n",
      "| train_with_tuning_043b2_00048 | TERMINATED | 169.237.32.34:1402260 | 0.000295217 |   0.952661 |   0.0246502  |   2.53795  |      0.0625608  |\n",
      "| train_with_tuning_043b2_00049 | TERMINATED | 169.237.32.34:1404224 | 2.26401e-05 |   0.942617 |   0.441436   |   0.931443 |      0.411172   |\n",
      "| train_with_tuning_043b2_00050 | TERMINATED | 169.237.32.34:1404225 | 0.000957217 |   0.878397 | nan          | nan        |    nan          |\n",
      "| train_with_tuning_043b2_00051 | TERMINATED | 169.237.32.34:1404226 | 0.00035713  |   0.864753 |   0.0115627  |   0.651465 |      0.00753268 |\n",
      "| train_with_tuning_043b2_00052 | TERMINATED | 169.237.32.34:1404227 | 0.000520985 |   0.881509 |   0.0141508  |   1.30637  |      0.0184862  |\n",
      "| train_with_tuning_043b2_00053 | TERMINATED | 169.237.32.34:1404228 | 0.000322913 |   0.819594 |   0.0325554  |   1.37295  |      0.044697   |\n",
      "| train_with_tuning_043b2_00054 | TERMINATED | 169.237.32.34:1404229 | 0.000102448 |   0.957027 |   0.00960444 |   0.459985 |      0.0044179  |\n",
      "| train_with_tuning_043b2_00055 | TERMINATED | 169.237.32.34:1427182 | 0.000618083 |   0.873948 |   0.030746   |   2.14761  |      0.0660306  |\n",
      "| train_with_tuning_043b2_00056 | TERMINATED | 169.237.32.34:1427183 | 0.000646791 |   0.817344 |   0.00742381 |   0.596008 |      0.00442465 |\n",
      "| train_with_tuning_043b2_00057 | TERMINATED | 169.237.32.34:1431990 | 0.000794555 |   0.980615 |   0.00829516 |   2.28764  |      0.0189764  |\n",
      "| train_with_tuning_043b2_00058 | TERMINATED | 169.237.32.34:1434718 | 0.000183516 |   0.885205 |   0.0355553  |   1.38877  |      0.0493779  |\n",
      "| train_with_tuning_043b2_00059 | TERMINATED | 169.237.32.34:1436641 | 4.54286e-05 |   0.927779 |   0.282199   |   1.14122  |      0.322051   |\n",
      "| train_with_tuning_043b2_00060 | TERMINATED | 169.237.32.34:1452683 | 0.000382964 |   0.950027 |   0.458702   |   0.638848 |      0.293041   |\n",
      "| train_with_tuning_043b2_00061 | TERMINATED | 169.237.32.34:1457463 | 9.74632e-05 |   0.810936 |   0.333913   |   1.06408  |      0.355311   |\n",
      "| train_with_tuning_043b2_00062 | TERMINATED | 169.237.32.34:1460306 | 7.63943e-05 |   0.968664 |   0.00985507 |   0.434289 |      0.00427995 |\n",
      "| train_with_tuning_043b2_00063 | TERMINATED | 169.237.32.34:1462309 | 1.71449e-05 |   0.827168 |   0.859012   |   0.933036 |      0.801489   |\n",
      "| train_with_tuning_043b2_00064 | TERMINATED | 169.237.32.34:1462311 | 0.00017236  |   0.819213 |   0.153098   |   1.37468  |      0.210461   |\n",
      "| train_with_tuning_043b2_00065 | TERMINATED | 169.237.32.34:1466813 | 0.000252312 |   0.813825 |   0.0390472  |   1.52331  |      0.059481   |\n",
      "| train_with_tuning_043b2_00066 | TERMINATED | 169.237.32.34:1484223 | 0.000258514 |   0.815456 |   0.0385234  |   1.50208  |      0.0578653  |\n",
      "| train_with_tuning_043b2_00067 | TERMINATED | 169.237.32.34:1489069 | 0.000940328 |   0.871111 | nan          | nan        |    nan          |\n",
      "| train_with_tuning_043b2_00068 | TERMINATED | 169.237.32.34:1491124 | 0.000422279 |   0.979977 |   0.00621311 |   1.59925  |      0.00993631 |\n",
      "| train_with_tuning_043b2_00069 | TERMINATED | 169.237.32.34:1491125 | 0.000321186 |   0.871489 |   0.00905366 |   0.448677 |      0.00406217 |\n",
      "| train_with_tuning_043b2_00070 | TERMINATED | 169.237.32.34:1493664 | 0.000358339 |   0.906097 |   0.00729384 |   0.472927 |      0.00344945 |\n",
      "| train_with_tuning_043b2_00071 | TERMINATED | 169.237.32.34:1493665 | 0.000649694 |   0.821128 |   0.00714928 |   0.555496 |      0.00397139 |\n",
      "| train_with_tuning_043b2_00072 | TERMINATED | 169.237.32.34:1509760 | 1.05368e-05 |   0.889046 |   0.865004   |   0.9336   |      0.807568   |\n",
      "| train_with_tuning_043b2_00073 | TERMINATED | 169.237.32.34:1521370 | 1.72837e-05 |   0.82233  |   0.861514   |   0.933274 |      0.804029   |\n",
      "| train_with_tuning_043b2_00074 | TERMINATED | 169.237.32.34:1523691 | 0.00031052  |   0.91084  |   0.00739981 |   0.584372 |      0.00432424 |\n",
      "| train_with_tuning_043b2_00075 | TERMINATED | 169.237.32.34:1538749 | 5.62006e-05 |   0.854285 |   0.442079   |   0.930668 |      0.411429   |\n",
      "| train_with_tuning_043b2_00076 | TERMINATED | 169.237.32.34:1541068 | 2.80022e-05 |   0.983012 |   0.0374371  |   1.19488  |      0.044733   |\n",
      "| train_with_tuning_043b2_00077 | TERMINATED | 169.237.32.34:1541069 | 0.000870478 |   0.8082   |   0.0554306  |   2.39882  |      0.132968   |\n",
      "| train_with_tuning_043b2_00078 | TERMINATED | 169.237.32.34:1552623 | 0.000113606 |   0.988663 |   0.00405052 |   0.772844 |      0.00313042 |\n",
      "| train_with_tuning_043b2_00079 | TERMINATED | 169.237.32.34:1569934 | 0.000128147 |   0.984167 |   0.00572267 |   1.0718   |      0.00613354 |\n",
      "+-------------------------------+------------+-----------------------+-------------+------------+--------------+------------+-----------------+\n",
      "\n",
      "\n",
      "Best trial config: {'lr': 7.639430825545346e-05, 'momentum': 0.9686637947240769}\n",
      "Best trial final validation loss: 0.4342890665974728\n",
      "Best trial final train loss: 0.009855073594309866\n"
     ]
    }
   ],
   "source": [
    "# Hyper Parameter Search \n",
    "iteration_config = {\n",
    "    \"lr\" : tune.loguniform(1e-5, 1e-3),\n",
    "    # \"batch_size\": tune.choice([128, 256]),\n",
    "    \"momentum\": tune.uniform(0.8, 0.99),\n",
    "}\n",
    "scheduler = ASHAScheduler(metric=\"combined_loss\", mode=\"min\", max_t=60, grace_period=5, reduction_factor=2)\n",
    "reporter = CLIReporter(metric_columns=[\"train_loss\", \"val_loss\", \"combined_loss\"])\n",
    "result = tune.run(train_with_tuning, config=iteration_config, scheduler=scheduler, progress_reporter=reporter,\n",
    "                  num_samples=80, resources_per_trial={\"cpu\": 0, \"gpu\": 0.05},)\n",
    "\n",
    "# best_trial = result.get_best_trial(\"combined_loss\", \"min\", \"last\")\n",
    "best_trial = result.get_best_trial(\"val_loss\", \"min\", \"last\")\n",
    "print(\"Best trial config: {}\".format(best_trial.config))\n",
    "print(\"Best trial final validation loss: {}\".format(best_trial.last_result[\"val_loss\"]))\n",
    "print(\"Best trial final train loss: {}\".format(best_trial.last_result[\"train_loss\"]))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Best trial config: {'lr': 0.0010630834634709364, 'b1': 0.4282116859842134, 'b2': 0.3089991262211405, 'batch_size': 8, 'model': [20, 16, 8, 4, 2, 1]}\n",
    "Best trial final validation loss: 0.09234625198878348\n",
    "Best trial final train loss: 0.22368373312056064 -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_trial.config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "trainer = trainer_factory.create()\n",
    "# trainer.change_batch_size(16)\n",
    "# trainer.set_optimizer(SGD, {'lr': best_trial.config['lr'], 'momentum': best_trial.config['lr'][\"momentum\"]})\n",
    "trainer.set_optimizer(SGD, {'lr': 7.6e-5, 'momentum': 0.967})\n",
    "trainer.epochs = 50\n",
    "trainer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.epochs = 50\n",
    "# trainer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f15937c5160>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(trainer.train_loss, label='Training Loss', marker='x')\n",
    "plt.plot(trainer.validation_loss, label='Validation Loss', marker='x')\n",
    "# plt.yscale('log')\n",
    "# plt.xlim([0, 10])\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Model Properties:\n",
      "        PerceptronBD(\n",
      "  (model): Sequential(\n",
      "    (0): Linear(in_features=20, out_features=20, bias=True)\n",
      "    (1): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): Dropout1d(p=0.5, inplace=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=20, out_features=10, bias=True)\n",
      "    (5): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): Dropout1d(p=0.5, inplace=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=10, out_features=5, bias=True)\n",
      "    (9): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): Dropout1d(p=0.5, inplace=False)\n",
      "    (11): ReLU()\n",
      "    (12): Linear(in_features=5, out_features=1, bias=True)\n",
      "    (13): Flatten(start_dim=1, end_dim=-1)\n",
      "  )\n",
      ")\n",
      "        Optimizer Properties\"\n",
      "        SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    differentiable: False\n",
      "    foreach: None\n",
      "    lr: 0.0002\n",
      "    maximize: False\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "        DataLoader Params: \n",
      "            Batch Size: 64\n",
      "            Validation Method: Holds out fMaternal Wall Thickness columns 8.0 for validation. The rest are used             for training\n",
      "        Loss:\n",
      "            Train Loss: 0.012880768882546653\n",
      "            Val. Loss: 0.5299061818640362\n"
     ]
    }
   ],
   "source": [
    "print(trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get predictions\n",
    "with torch.no_grad():\n",
    "    x_data = torch.tensor(data[x_columns].values, dtype=torch.float).cuda()\n",
    "    trainer.model = trainer.model.eval()\n",
    "    predictions = trainer.model(x_data)\n",
    "    predictions = predictions.cpu().numpy()\n",
    "    predictions = y_scaler.inverse_transform(predictions).flatten()\n",
    "    y_data = data[y_columns].to_numpy()\n",
    "    y_data = y_scaler.inverse_transform(y_data).flatten()\n",
    "    absolute_error = np.abs(y_data - predictions)\n",
    "    # error_df = pd.DataFrame({'Truth': y_data, \"Predicted\": predictions, \"Absolute Error\": absolute_error, \"%tage\": absolute_error/y_data * 100})\n",
    "    error_df = pd.DataFrame({'Truth': y_data, \"Predicted\": predictions, \"Absolute Error\": absolute_error, \"%tage\": absolute_error})\n",
    "plt.figure()\n",
    "# error_df['%tage'].plot.hist(bins=100)\n",
    "error_df['Absolute Error'].plot.hist(bins=100)\n",
    "# plt.xlabel('(%) Error')\n",
    "plt.xlabel('Abs. Sat. Error')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Maternal Wall Thickness</th>\n",
       "      <th>Maternal Hb Concentration</th>\n",
       "      <th>Maternal Saturation</th>\n",
       "      <th>Fetal Saturation</th>\n",
       "      <th>FconcCenters</th>\n",
       "      <th>Fetal Hb Concentration 0</th>\n",
       "      <th>Fetal Hb Concentration 1</th>\n",
       "      <th>Truth</th>\n",
       "      <th>Predicted</th>\n",
       "      <th>Absolute Error</th>\n",
       "      <th>%tage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51499</th>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51499</th>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51499</th>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51499</th>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51499</th>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51499</th>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51499</th>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51499</th>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51499</th>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51499</th>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51499</th>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51499</th>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51499</th>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51499</th>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51499</th>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51499</th>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51499</th>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51499</th>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51499</th>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51499</th>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51499</th>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51499</th>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51499</th>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51499</th>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51499</th>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51499</th>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51499</th>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51499</th>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51499</th>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51499</th>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51499</th>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51499</th>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51499</th>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51499</th>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51499</th>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51499</th>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51499</th>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51499</th>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51499</th>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51499</th>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51499</th>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51499</th>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51499</th>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51499</th>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51499</th>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51499</th>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51499</th>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51499</th>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51499</th>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51499</th>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Maternal Wall Thickness  Maternal Hb Concentration  \\\n",
       "51499                     16.0                       16.0   \n",
       "51499                     16.0                       16.0   \n",
       "51499                     16.0                       16.0   \n",
       "51499                     16.0                       16.0   \n",
       "51499                     16.0                       16.0   \n",
       "51499                     16.0                       16.0   \n",
       "51499                     16.0                       16.0   \n",
       "51499                     16.0                       16.0   \n",
       "51499                     16.0                       16.0   \n",
       "51499                     16.0                       16.0   \n",
       "51499                     16.0                       16.0   \n",
       "51499                     16.0                       16.0   \n",
       "51499                     16.0                       16.0   \n",
       "51499                     16.0                       16.0   \n",
       "51499                     16.0                       16.0   \n",
       "51499                     16.0                       16.0   \n",
       "51499                     16.0                       16.0   \n",
       "51499                     16.0                       16.0   \n",
       "51499                     16.0                       16.0   \n",
       "51499                     16.0                       16.0   \n",
       "51499                     16.0                       16.0   \n",
       "51499                     16.0                       16.0   \n",
       "51499                     16.0                       16.0   \n",
       "51499                     16.0                       16.0   \n",
       "51499                     16.0                       16.0   \n",
       "51499                     16.0                       16.0   \n",
       "51499                     16.0                       16.0   \n",
       "51499                     16.0                       16.0   \n",
       "51499                     16.0                       16.0   \n",
       "51499                     16.0                       16.0   \n",
       "51499                     16.0                       16.0   \n",
       "51499                     16.0                       16.0   \n",
       "51499                     16.0                       16.0   \n",
       "51499                     16.0                       16.0   \n",
       "51499                     16.0                       16.0   \n",
       "51499                     16.0                       16.0   \n",
       "51499                     16.0                       16.0   \n",
       "51499                     16.0                       16.0   \n",
       "51499                     16.0                       16.0   \n",
       "51499                     16.0                       16.0   \n",
       "51499                     16.0                       16.0   \n",
       "51499                     16.0                       16.0   \n",
       "51499                     16.0                       16.0   \n",
       "51499                     16.0                       16.0   \n",
       "51499                     16.0                       16.0   \n",
       "51499                     16.0                       16.0   \n",
       "51499                     16.0                       16.0   \n",
       "51499                     16.0                       16.0   \n",
       "51499                     16.0                       16.0   \n",
       "51499                     16.0                       16.0   \n",
       "\n",
       "       Maternal Saturation  Fetal Saturation  FconcCenters  \\\n",
       "51499                  1.0          1.414214           3.0   \n",
       "51499                  1.0          1.414214           3.0   \n",
       "51499                  1.0          1.414214           3.0   \n",
       "51499                  1.0          1.414214           3.0   \n",
       "51499                  1.0          1.414214           3.0   \n",
       "51499                  1.0          1.414214           3.0   \n",
       "51499                  1.0          1.414214           3.0   \n",
       "51499                  1.0          1.414214           3.0   \n",
       "51499                  1.0          1.414214           3.0   \n",
       "51499                  1.0          1.414214           3.0   \n",
       "51499                  1.0          1.414214           3.0   \n",
       "51499                  1.0          1.414214           3.0   \n",
       "51499                  1.0          1.414214           3.0   \n",
       "51499                  1.0          1.414214           3.0   \n",
       "51499                  1.0          1.414214           3.0   \n",
       "51499                  1.0          1.414214           3.0   \n",
       "51499                  1.0          1.414214           3.0   \n",
       "51499                  1.0          1.414214           3.0   \n",
       "51499                  1.0          1.414214           3.0   \n",
       "51499                  1.0          1.414214           3.0   \n",
       "51499                  1.0          1.414214           3.0   \n",
       "51499                  1.0          1.414214           3.0   \n",
       "51499                  1.0          1.414214           3.0   \n",
       "51499                  1.0          1.414214           3.0   \n",
       "51499                  1.0          1.414214           3.0   \n",
       "51499                  1.0          1.414214           3.0   \n",
       "51499                  1.0          1.414214           3.0   \n",
       "51499                  1.0          1.414214           3.0   \n",
       "51499                  1.0          1.414214           3.0   \n",
       "51499                  1.0          1.414214           3.0   \n",
       "51499                  1.0          1.414214           3.0   \n",
       "51499                  1.0          1.414214           3.0   \n",
       "51499                  1.0          1.414214           3.0   \n",
       "51499                  1.0          1.414214           3.0   \n",
       "51499                  1.0          1.414214           3.0   \n",
       "51499                  1.0          1.414214           3.0   \n",
       "51499                  1.0          1.414214           3.0   \n",
       "51499                  1.0          1.414214           3.0   \n",
       "51499                  1.0          1.414214           3.0   \n",
       "51499                  1.0          1.414214           3.0   \n",
       "51499                  1.0          1.414214           3.0   \n",
       "51499                  1.0          1.414214           3.0   \n",
       "51499                  1.0          1.414214           3.0   \n",
       "51499                  1.0          1.414214           3.0   \n",
       "51499                  1.0          1.414214           3.0   \n",
       "51499                  1.0          1.414214           3.0   \n",
       "51499                  1.0          1.414214           3.0   \n",
       "51499                  1.0          1.414214           3.0   \n",
       "51499                  1.0          1.414214           3.0   \n",
       "51499                  1.0          1.414214           3.0   \n",
       "\n",
       "       Fetal Hb Concentration 0  Fetal Hb Concentration 1  Truth  Predicted  \\\n",
       "51499                      0.17                     0.155    0.6        NaN   \n",
       "51499                      0.17                     0.155    0.6        NaN   \n",
       "51499                      0.17                     0.155    0.6        NaN   \n",
       "51499                      0.17                     0.155    0.6        NaN   \n",
       "51499                      0.17                     0.155    0.6        NaN   \n",
       "51499                      0.17                     0.155    0.6        NaN   \n",
       "51499                      0.17                     0.155    0.6        NaN   \n",
       "51499                      0.17                     0.155    0.6        NaN   \n",
       "51499                      0.17                     0.155    0.6        NaN   \n",
       "51499                      0.17                     0.155    0.6        NaN   \n",
       "51499                      0.17                     0.155    0.6        NaN   \n",
       "51499                      0.17                     0.155    0.6        NaN   \n",
       "51499                      0.17                     0.155    0.6        NaN   \n",
       "51499                      0.17                     0.155    0.6        NaN   \n",
       "51499                      0.17                     0.155    0.6        NaN   \n",
       "51499                      0.17                     0.155    0.6        NaN   \n",
       "51499                      0.17                     0.155    0.6        NaN   \n",
       "51499                      0.17                     0.155    0.6        NaN   \n",
       "51499                      0.17                     0.155    0.6        NaN   \n",
       "51499                      0.17                     0.155    0.6        NaN   \n",
       "51499                      0.17                     0.155    0.6        NaN   \n",
       "51499                      0.17                     0.155    0.6        NaN   \n",
       "51499                      0.17                     0.155    0.6        NaN   \n",
       "51499                      0.17                     0.155    0.6        NaN   \n",
       "51499                      0.17                     0.155    0.6        NaN   \n",
       "51499                      0.17                     0.155    0.6        NaN   \n",
       "51499                      0.17                     0.155    0.6        NaN   \n",
       "51499                      0.17                     0.155    0.6        NaN   \n",
       "51499                      0.17                     0.155    0.6        NaN   \n",
       "51499                      0.17                     0.155    0.6        NaN   \n",
       "51499                      0.17                     0.155    0.6        NaN   \n",
       "51499                      0.17                     0.155    0.6        NaN   \n",
       "51499                      0.17                     0.155    0.6        NaN   \n",
       "51499                      0.17                     0.155    0.6        NaN   \n",
       "51499                      0.17                     0.155    0.6        NaN   \n",
       "51499                      0.17                     0.155    0.6        NaN   \n",
       "51499                      0.17                     0.155    0.6        NaN   \n",
       "51499                      0.17                     0.155    0.6        NaN   \n",
       "51499                      0.17                     0.155    0.6        NaN   \n",
       "51499                      0.17                     0.155    0.6        NaN   \n",
       "51499                      0.17                     0.155    0.6        NaN   \n",
       "51499                      0.17                     0.155    0.6        NaN   \n",
       "51499                      0.17                     0.155    0.6        NaN   \n",
       "51499                      0.17                     0.155    0.6        NaN   \n",
       "51499                      0.17                     0.155    0.6        NaN   \n",
       "51499                      0.17                     0.155    0.6        NaN   \n",
       "51499                      0.17                     0.155    0.6        NaN   \n",
       "51499                      0.17                     0.155    0.6        NaN   \n",
       "51499                      0.17                     0.155    0.6        NaN   \n",
       "51499                      0.17                     0.155    0.6        NaN   \n",
       "\n",
       "       Absolute Error  %tage  \n",
       "51499             NaN    NaN  \n",
       "51499             NaN    NaN  \n",
       "51499             NaN    NaN  \n",
       "51499             NaN    NaN  \n",
       "51499             NaN    NaN  \n",
       "51499             NaN    NaN  \n",
       "51499             NaN    NaN  \n",
       "51499             NaN    NaN  \n",
       "51499             NaN    NaN  \n",
       "51499             NaN    NaN  \n",
       "51499             NaN    NaN  \n",
       "51499             NaN    NaN  \n",
       "51499             NaN    NaN  \n",
       "51499             NaN    NaN  \n",
       "51499             NaN    NaN  \n",
       "51499             NaN    NaN  \n",
       "51499             NaN    NaN  \n",
       "51499             NaN    NaN  \n",
       "51499             NaN    NaN  \n",
       "51499             NaN    NaN  \n",
       "51499             NaN    NaN  \n",
       "51499             NaN    NaN  \n",
       "51499             NaN    NaN  \n",
       "51499             NaN    NaN  \n",
       "51499             NaN    NaN  \n",
       "51499             NaN    NaN  \n",
       "51499             NaN    NaN  \n",
       "51499             NaN    NaN  \n",
       "51499             NaN    NaN  \n",
       "51499             NaN    NaN  \n",
       "51499             NaN    NaN  \n",
       "51499             NaN    NaN  \n",
       "51499             NaN    NaN  \n",
       "51499             NaN    NaN  \n",
       "51499             NaN    NaN  \n",
       "51499             NaN    NaN  \n",
       "51499             NaN    NaN  \n",
       "51499             NaN    NaN  \n",
       "51499             NaN    NaN  \n",
       "51499             NaN    NaN  \n",
       "51499             NaN    NaN  \n",
       "51499             NaN    NaN  \n",
       "51499             NaN    NaN  \n",
       "51499             NaN    NaN  \n",
       "51499             NaN    NaN  \n",
       "51499             NaN    NaN  \n",
       "51499             NaN    NaN  \n",
       "51499             NaN    NaN  \n",
       "51499             NaN    NaN  \n",
       "51499             NaN    NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Top Bad Samples\n",
    "VIEW_TOP_N = 50\n",
    "worst_errors = error_df['Absolute Error'].argsort()[::-1][:VIEW_TOP_N]  # Worst Results\n",
    "# worst_errors = error_df['Absolute Error'].argsort()[:VIEW_TOP_N]  # Best Results\n",
    "combined_table = data.join(error_df)\n",
    "with pd.option_context(\"display.max_rows\", None):\n",
    "    display(combined_table[labels +  ['Truth', 'Predicted', 'Absolute Error', '%tage']].iloc[worst_errors, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error(non-normalized): [nan]\n",
      "Validation Error(non-normalized): [nan]\n"
     ]
    }
   ],
   "source": [
    "# Rough MSE's in percentage\n",
    "print(f'Train Error(non-normalized): {trainer.train_loss[-1] * y_scaler.var_ }')\n",
    "print(f'Validation Error(non-normalized): {trainer.validation_loss[-1] * y_scaler.var_ }')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "PerceptronBD                             --\n",
       "Sequential: 1-1                        --\n",
       "    Linear: 2-1                       420\n",
       "    BatchNorm1d: 2-2                  40\n",
       "    Dropout1d: 2-3                    --\n",
       "    ReLU: 2-4                         --\n",
       "    Linear: 2-5                       210\n",
       "    BatchNorm1d: 2-6                  20\n",
       "    Dropout1d: 2-7                    --\n",
       "    ReLU: 2-8                         --\n",
       "    Linear: 2-9                       55\n",
       "    BatchNorm1d: 2-10                 10\n",
       "    Dropout1d: 2-11                   --\n",
       "    ReLU: 2-12                        --\n",
       "    Linear: 2-13                      6\n",
       "    Flatten: 2-14                     --\n",
       "=================================================================\n",
       "Total params: 761\n",
       "Trainable params: 761\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model Info\n",
    "torchinfo.summary(trainer.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Truth', 'Predicted', 'Absolute Error', '%tage'], dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = 'msat_percep_irsi'\n",
    "# import joblib\n",
    "# # Save Model\n",
    "# torch.save(model.state_dict(), rf'../models/{model_name}')\n",
    "# # Save the Scalers for Later Use\n",
    "# joblib.dump(x_scaler, rf'../models/{model_name}_xscaler')\n",
    "# joblib.dump(y_scaler, rf'../models/{model_name}_yscaler')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load Model Code\n",
    "# model = PerceptronReLU([20, 10, 4, 2, 1])\n",
    "# model.load_state_dict(torch.load(r'../models/fsat_delta_5det_v1'))\n",
    "# model = model.cuda()\n",
    "# x_scaler = joblib.load(rf'../models/{model_name}_xscaler')\n",
    "# y_scaler = joblib.load(rf'../models/{model_name}_yscaler')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cybercat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
